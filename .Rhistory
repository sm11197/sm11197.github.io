#prop_table <- svytable(~Final_Setting+Final_Accuracy, design = svydesign(ids = ~1, data = subset(judgments_online, !grepl("Consultancy", Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting))
prop_table
print(prop.test(c(prop_table["Human Consultancy","TRUE"],prop_table["Human Debate","TRUE"]),c(prop_table["Human Consultancy", "TRUE"]+prop_table["Human Consultancy", "FALSE"], prop_table["Human Debate", "TRUE"]+prop_table["Human Debate", "FALSE"])))
#judgments_online$Final_Setting <- relevel(judgments_online$Final_Setting, ref = "Human Debate")
model1 <- glm(Final_Accuracy ~ relevel(factor(Final_Setting), 'Human Debate'), family = 'binomial', data = judgments_online)
summary(model1)
table(model1$fitted.values > 0.5)
table(judgments_online$Final_Accuracy)
model2 <- glm(Final_Accuracy ~ relevel(factor(Participant),'Aliyaah Toussaint') + relevel(factor(Final_Setting), 'Human Debate'), family = 'binomial', data = judgments_online)
summary(model2)
random.intercept.model = lmer(`Final probability correct` ~ (1|Final_Setting),
data = judgments, REML = TRUE)
judgments$random.intercept.preds = predict(random.intercept.model)
summary(random.intercept.model)
ranef(random.intercept.model)
ranova(random.intercept.model)
random.intercept.model = lmer(`Final probability correct` ~ (1|Participant) + (1|Final_Setting),
data = judgments, REML = TRUE)
judgments$random.intercept.preds = predict(random.intercept.model)
summary(random.intercept.model)
ranef(random.intercept.model)
ranova(random.intercept.model)
#brm1 <- brm(data = judgments_online,
#             formula = as.numeric(Final_Accuracy) | trials(2) ~ 1 + (1 | Final_Setting),
#             family = binomial("identity"),
#             iter = 2000, warmup = 1000, chains = 4, cores = 4,
#             control = list(adapt_delta = .975, max_treedepth = 20),
#             seed = 190831)
#plot(brm1)
reticulate::repl_python()
characters<- py$characters_agg
characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length >= lower_bound & quote_length <= upper_bound)
filtered_outliers <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length >= lower_bound & quote_length <= upper_bound)
View(filtered_outliers)
View(characters)
span_difference_debate_consultancies<-py$filtered_df
characters<- py$characters_agg
span_difference_debate_consultancies<-py$filtered_df
ggplot(span_difference_debate_consultancies) +
geom_boxplot(aes(x = `Setting 2`, y = `Span Difference Count`))
filtered_outliers <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length >= lower_bound & quote_length <= upper_bound)
ggplot(characters) +
geom_boxplot(aes(x = Final_Setting, y = `Quote length`)) +
labs(y = "Total Quote Length (characters)")+
theme_minimal()
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length >= lower_bound & quote_length <= upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length), outlier.shape = NA) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
pairwise.t.test(filtered$quote_length, filtered$Final_Setting)
filtered %>% group_by(Final_Setting) %>% summarise(avground = mean(quote_length))
filtered %>% group_by(Final_Setting) %>% summarise(avground = mean(quote_length))
characters %>% group_by(Final_Setting) %>% summarise(avground = mean(quote_length))
filtered %>% group_by(Final_Setting) %>% summarise(avground = median(quote_length))
characters %>% group_by(Final_Setting) %>% summarise(avground = median(quote_length))
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length), outlier.shape = NA) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
characters %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length), outlier.shape = NA) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
characters %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > lower_bound & quote_length < upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > lower_bound & quote_length < upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
View(filtered)
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
characters %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
outliers <- characters %>%
group_by(Final_Setting) %>%
identify_outliers(quote_length)
outliers <- characters %>%
group_by(Final_Setting) %>%
rstatix::identify_outliers(quote_length)
install.packages("rstatix")
install.packages("rstatix")
install.packages("rstatix")
install.packages("rstatix")
characters<- py$characters_agg
span_difference_debate_consultancies<-py$filtered_df
ggplot(span_difference_debate_consultancies) +
geom_boxplot(aes(x = `Setting 2`, y = `Span Difference Count`))
filtered_outliers <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length >= lower_bound & quote_length <= upper_bound)
ggplot(characters) +
geom_boxplot(aes(x = Final_Setting, y = `Quote length`)) +
labs(y = "Total Quote Length (characters)")+
theme_minimal()
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > lower_bound & quote_length < upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound) %>%
identify_outliers(quote_length)
outliers <- characters %>%
group_by(Final_Setting) %>%
rstatix::identify_outliers(quote_length)
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > lower_bound & quote_length < upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
outliers <- characters %>%
group_by(Final_Setting) %>%
rstatix::identify_outliers(quote_length)
outliers <- characters %>%
rstatix::identify_outliers(quote_length)
View(characters)
View(outliers)
View(filtered)
View(filtered_outliers)
outliers <- characters %>%
group_by(Final_Setting) %>%
rstatix::identify_outliers(quote_length)
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > lower_bound & quote_length < upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
characters %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
View(filtered)
View(filtered_outliers)
filtered_outliers <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR)
View(filtered_outliers)
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > 0 & quote_length < upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > 0 & quote_length < upper_bound) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
characters %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
characters %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
filtered <- characters %>%
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > 0 & quote_length < 750) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered <- characters %>%
group_by(Final_Setting) %>%
mutate(Q1 = quantile(quote_length, 0.25),
Q3 = quantile(quote_length, 0.75),
IQR = Q3 - Q1,
lower_bound = Q1 - 1.5 * IQR,
upper_bound = Q3 + 1.5 * IQR) %>%
filter(quote_length > 0 & quote_length < 750) %>%
select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
characters %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
labs(y = "Total Quote Length in a Debate/Consultancy (unique tokens)", x = "Setting")+
theme_minimal()
pairwise.t.test(filtered$quote_length, filtered$Final_Setting)
filtered %>% group_by(Final_Setting) %>% summarise(avground = median(quote_length))
characters %>% group_by(Final_Setting) %>% summarise(avground = median(quote_length))
filtered %>% group_by(Final_Setting) %>% summarise(avground = median(quote_length))
characters %>% group_by(Final_Setting) %>% summarise(avground = median(quote_length))
install.packages('sjstats')
consultancy_design <- svydesign(ids = ~1, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)
sjstats::weighted_mannwhitney(~Final_Setting+`Final probability correct`, design = consultancy_design)
sjstats::weighted_mannwhitney(~Final_Setting+`Final probability correct`, design = consultancy_design, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)))
View(judgments_online)
colnames(judgments_online)
sjstats::weighted_mannwhitney(~Final_Setting+`Final probability correct`, design = consultancy_design, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)))
sjstats::weighted_mannwhitney(Final_Setting+`Final probability correct`, design = consultancy_design, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)))
sjstats::weighted_mannwhitney(Final_Setting,`Final probability correct`, design = consultancy_design, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)))
sjstats::weighted_mannwhitney(`Final probability correct`, design = consultancy_design, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)))
sjstats::weighted_mannwhitney(`Final probability correct`, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)))
sjstats::weighted_mannwhitney(Final_Accuracy, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)))
sjstats::weighted_mannwhitney(Final_Accuracy, data = judgments_online)
View(judgments_online)
sjstats::weighted_mannwhitney(`Final probability correct`, data = judgments_online)
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
sjstats::weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
sjstats::weighted_mannwhitney(`Final probability correct`~Final_Setting+~sampled_consultancies_all_debates_weights_grouped_setting, data = judgments_online)
sjstats::weighted_mannwhitney(`Final probability correct`~Final_Setting+sampled_consultancies_all_debates_weights_grouped_setting, data = judgments_online)
sjstats::weighted_mannwhitney(c12hour ~ c161sex + weight, sjstats::efc)
library(sjstats)
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
library(sjstats)
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
library(sjstats)
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
svyranktest(~Final_Setting+Final_Accuracy, design = consultancy_design)
svyranktest(Final_Setting~`Final probability correct`, design = consultancy_design)
svyranktest(~Final_Setting+`Final probability correct`, design = consultancy_design)
svyranktest(~`Final probability correct`, design = consultancy_design)
svyranktest(`Final probability correct`, design = consultancy_design)
svyranktest(~`Final probability correct`, design = consultancy_design)
judgments_online$fpc <- judgments_online$`Final probability correct`
svyranktest(~Final_Setting+fpc, design = consultancy_design)
consultancy_design <- svydesign(ids = ~1, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)
judgments_online$fpc <- judgments_online$`Final probability correct`
svyranktest(~Final_Setting+fpc, design = consultancy_design)
svyranktest(~Final_Setting+fpc, design = consultancy_design, test = "wilcoxon")
svyranktest(~Final_Setting+fpc, design = consultancy_design, test = "median")
data(efc)
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
efc$weight <- abs(rnorm(nrow(efc), 1, .3))
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
efc
weighted_mannwhitney(fpc~Final_Accuracy, weights = sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)
weighted_mannwhitney(fpc~Final_Accuracy, judgments_online)
judgments_online$fpc <- judgments_online$`Final probability correct`
weighted_mannwhitney(fpc~Final_Accuracy, judgments_online)
Final_Accuracy
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
weighted_mannwhitney(fpc~Final_Accuracy_char, judgments_online)
data(efc)
efc
str(efc)
svyranktest(fpc~Final_Setting, consultancy_design)
human_consultancy_design <- svydesign(ids = ~1, data = subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting) & !grepl("AI", Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)
svyranktest(fpc~Final_Setting, human_consultancy_design)
human_consultancy_design <- svydesign(ids = ~1, data = subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting) & !grepl("AI", Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)
svyranktest(fpc~Final_Setting, human_consultancy_design)
svyranktest(fpc~Final_Setting, consultancy_design)
svyranktest(fpc~Final_Setting, human_consultancy_design, test = "median")
svyranktest(fpc~Final_Setting, human_consultancy_design, test = "wilcoxon")
judgments_online %>% group_by(Final_Setting) %>% summarise(fpcmed = median(fpc))
judgments_online$fpc <- judgments_online$`Final probability correct`
judgments_online %>% group_by(Final_Setting) %>% summarise(fpcmed = median(fpc))
judgments_online %>% group_by(Final_Setting) %>% summarise(fpcmed = median(fpc),
fpcmean = mean(fpc))
svyranktest(fpc~Final_Setting, human_consultancy_design, test = "vanderWaerden")
mediant<-svyranktest(fpc~Final_Setting, human_consultancy_design, test = "median")
mediant$parameter
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
library(sjstats)
data(efc)
efc$weight <- abs(rnorm(nrow(efc), 1, .3))
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
mannwhitney(efc,c12hour,c161sex)
library(coins)
wilcox.test(efc,c12hour,c161sex)
wilcox.test(efc$c12hour,efc$c161sex)
weighted_mannwhitney(c12hour ~ c161sex, efc)
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)
weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, efc)
weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)
mediant<-svyranktest(fpc~Final_Setting, human_consultancy_design, test = "median")
svyranktest(fpc~Final_Setting, human_consultancy_design, test = "median")
svyranktest(fpc~Final_Setting, human_consultancy_design, test = "wilcoxon")
svyranktest(fpc~Final_Setting, human_consultancy_design, test = "vanderWaerden")
weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)
svyranktest(fpc~Final_Setting, consultancy_design, test = "median")
svyranktest(fpc~Final_Setting, consultancy_design, test = "wilcoxon")
svyranktest(fpc~Final_Setting, consultancy_design, test = "vanderWaerden")
weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)
mwu<-weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)
mwu$p.value
judgments_online$fpcw <- judgments_online$fpc *judgments_online$sampled_consultancies_all_debates_weights_grouped_setting
wilcox.test(fpw~Final_Setting, subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting) & !grepl("AI", Final_Setting)))
wilcox.test(fpcw~Final_Setting, subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting) & !grepl("AI", Final_Setting)))
svyranktest(fpc~Final_Setting, consultancy_design, test = "median")
svyranktest(fpc~Final_Setting, consultancy_design, test = "wilcoxon")
svyranktest(fpc~Final_Setting, consultancy_design, test = "vanderWaerden")
weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)
svyranktest(fpc~Final_Setting, consultancy_design)
svyranktest(fpc~Final_Setting, human_consultancy_design)
wilcox.test(fpcw~Final_Setting, subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting) & !grepl("AI", Final_Setting)))
wilcox.test(fpcw~Final_Setting, subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl("Consultancy", Final_Setting) & !grepl("AI", Final_Setting)), conf.int=T)
View(judgments_online)
judgments_online %>% group_by(Final_Setting) %>% summarise(fpcmed = median(fpc),
fpcmean = mean(fpc))
87-95
judgments_online %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = fpc)) +
labs(y = "fpc", x = "Setting")+
theme_minimal()
judgments_online %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = Final_Accuracy)) +
labs(y = "acc", x = "Setting")+
theme_minimal()
judgments_online %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = Final_Accuracy)) +
labs(y = "acc", x = "Setting")+
theme_minimal()
judgments_online %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = mean(Final_Accuracy))) +
labs(y = "acc", x = "Setting")+
theme_minimal()
judgments_online %>%
group_by(Final_Setting) %>% summarise(fpcmed = median(fpc),
fpcmean = mean(Final_Accuracy)) %>%
ggplot() +
geom_boxplot(aes(x = Final_Setting, y = fpcmean)) +
labs(y = "acc", x = "Setting")+
theme_minimal()
# Install RMarkdown
install.packages("rmarkdown")
install.packages("rmarkdown")
# Install TinyTex - for PDF output
install.packages("tinytex")
tinytex::install_tinytex()
check_installed("tinytex")
tiny_tex::check_installed("tinytex")
tinytex::check_installed("tinytex")
tinytex::is_tinytex()
tinytex::check_installed("TinyTex")
check_install <- function(package_name) {
if (!require(package_name, character.only = TRUE)) {
install.packages(package_name)
}
}
# Install RMarkdown
check_install("rmarkdown")
# Read the Rmd file
rmd_file <- "debate-2309.Rmd"
rmd_content <- readLines(rmd_file)
# Read the Rmd file
rmd_file <- "debate-2309.Rmd"
rmd_content <- readLines(rmd_file)
# Read the Rmd file
rmd_file <- "/Users/bila/git/sm11197.github.io/sm11197.github.io/debate-2309.Rmd" # change as needed
rmd_content <- readLines(rmd_file)
# Extract the setup chunk
setup_chunk_start <- which(grepl("^```{r setup,", rmd_content))
# Extract the setup chunk
setup_chunk_start <- which(grepl("^```\\{r setup,", rmd_content))
setup_chunk_end <- which(grepl("^```$", rmd_content[seq(setup_chunk_start, length(rmd_content))]))[1] + setup_chunk_start - 1
setup_chunk <- rmd_content[seq(setup_chunk_start + 1, setup_chunk_end - 1)]
setup_chunk
# Extract library calls from the setup chunk
library_calls <- grep("^library\\(", setup_chunk, value = TRUE)
# Extract package names from the library calls
package_names <- gsub("library\\(([^)]+)\\)", "\\1", library_calls)
package_names <- unlist(strsplit(package_names, split = " "))
# Check and install packages
for (pkg in package_names) {
check_install(pkg)
}
lib_path <- "/Users/bila/git/sm11197.github.io/sm11197.github.io/library"
.libPaths(lib_path)
knitr::opts_chunk$set(class.source = "foldable")
lib_path <- "/Users/bila/git/sm11197.github.io/sm11197.github.io/library"
.libPaths(lib_path)
knitr::opts_chunk$set(class.source = "foldable")
lib_path <- "/Users/bila/git/sm11197.github.io/sm11197.github.io/library"
.libPaths(lib_path)
options(scipen = 999)
library(reticulate) #for interop with Python
reticulate::use_virtualenv("/Users/bila/git/sm11197.github.io/sm11197.github.io/.venv")
library(ggplot2) #graphs
library(dplyr) #data manipulation
library(survey) #weighted statistics
library(sjstats) #weighted statistics (2)
library(lme4) #linear mixed models
library(lmerTest) #tests for the above
library(brms) #bayesian regression models
library(boot) #bootstrap resampling for confidence intervals
library(purrr) #data manipulation - efficient loops
reticulate::repl_python()
knitr::opts_chunk$set(class.source = "foldable")
lib_path <- "/Users/bila/git/sm11197.github.io/sm11197.github.io/library"
.libPaths(lib_path)
options(scipen = 999)
library(reticulate) #for interop with Python
reticulate::use_virtualenv("/Users/bila/git/sm11197.github.io/sm11197.github.io/.venv")
library(ggplot2) #graphs
library(dplyr) #data manipulation
library(survey) #weighted statistics
library(sjstats) #weighted statistics (2)
library(lme4) #linear mixed models
library(lmerTest) #tests for the above
library(brms) #bayesian regression models
library(boot) #bootstrap resampling for confidence intervals
library(purrr) #data manipulation - efficient loops
reticulate::repl_python()
