<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Results</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">sm11197</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="analysis.html">Analysis</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Results</h1>

</div>


<blockquote>
<p>Notes:<br />
- Some of this is already in or was based on the blogpost/interface
code. Hit show to see code. I switch between R and Python<br />
- Some of this won’t make it to the paper. You can probably skip
preprocessing unless you want to check certain things, example: did we
make sure to remove judgments based on X condition - If you want to
clarify/comment anything do so at <a
href="https://github.com/sm11197/sm11197.github.io/blob/main/analysis/debate-0923.Rmd"
class="uri">https://github.com/sm11197/sm11197.github.io/blob/main/analysis/debate-0923.Rmd</a>)
or message me elsewhere</p>
</blockquote>
<div id="preprocessing" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Preprocessing</h1>
<div id="importing-filtering-and-adding-columns" class="section level2"
number="1.1">
<h2><span class="header-section-number">1.1</span> Importing, filtering,
and adding columns</h2>
<p>We have 3 sets of data from the interface:</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
pd.options.mode.chained_assignment = None  # default=&#39;warn&#39;

# Load summaries that can be downloaded from the interface
debates = pd.read_csv(&quot;/Users/bila/git/for-debate/debate/save/official/summaries/debates.csv&quot;, keep_default_na=True)
sessions = pd.read_csv(&quot;/Users/bila/git/for-debate/debate/save/official/summaries/sessions.csv&quot;, keep_default_na=True)
turns = pd.read_csv(&quot;/Users/bila/git/for-debate/debate/save/official/summaries/turns.csv&quot;, keep_default_na=True)
print(f&#39; {debates.shape} - Debates&#39;) ;print(f&#39;{sessions.shape} - Sessions, which has multiple rows (of participants) for each debate&#39;) ; print(f&#39;{turns.shape} - and Turns, which has multiple rows (of participant turns) for each debate&#39;)</code></pre>
<pre><code>##  (632, 29) - Debates
## (1863, 46) - Sessions, which has multiple rows (of participants) for each debate
## (6220, 16) - and Turns, which has multiple rows (of participant turns) for each debate</code></pre>
<pre class="python"><code># Only include debates within a given period
debates[&quot;Start time&quot;] = pd.to_datetime(debates[&quot;Start time&quot;], unit=&quot;ms&quot;)
debates[&quot;End time&quot;] = pd.to_datetime(debates[&quot;End time&quot;], unit=&quot;ms&quot;)
debates[&quot;Last modified time&quot;] = pd.to_datetime(debates[&quot;Last modified time&quot;], unit=&quot;ms&quot;)
debates = debates[
    (debates[&quot;Start time&quot;] &gt; pd.to_datetime(&quot;10/02/23&quot;, format=&quot;%d/%m/%y&quot;)) &amp;
    (debates[&quot;End time&quot;] &lt; pd.to_datetime(&quot;01/09/23&quot;, format=&quot;%d/%m/%y&quot;))
]
### for filtering to when we had AI debates: 16/07/23
# Filter sessions &amp; turns to only the selected debates
sessions = sessions.merge(debates[[&quot;Room name&quot;]], how=&quot;inner&quot;, on=&quot;Room name&quot;)
turns = turns.merge(debates[[&quot;Room name&quot;]], how=&quot;inner&quot;, on=&quot;Room name&quot;)
print(f&#39;We have {len(debates)} debates when filtering out the initial pilots last fall&#39;)</code></pre>
<pre><code>## We have 583 debates when filtering out the initial pilots last fall</code></pre>
<pre class="python"><code># Secondary analysis: Question Difficulty
# Create new columns with bin labels
debates[&#39;Untimed annotator context bins&#39;] = pd.cut(debates[&#39;Untimed annotator context&#39;].round(), bins=[0, 1, 2, 3, 4], labels=[&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;], right=True)
debates[&#39;Speed annotator accuracy bins&#39;] = pd.cut(debates[&#39;Speed annotator accuracy&#39;], bins=[-0.999, 0.001, 0.201, 0.401], labels=[&#39;0&#39;, &#39;0.2&#39;, &#39;0.4&#39;])
## respectively, those speed annotator accuracies probably mean 0 right, 1 right, 2 right

debates[&#39;Final_Accuracy&#39;] = debates[&#39;Final probability correct&#39;] &gt; 0.5

print(f&#39;Average accuracy per context required by question:\n{debates.groupby(&quot;Untimed annotator context bins&quot;)[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(),Total_Count=&quot;size&quot;)}&#39;)</code></pre>
<pre><code>## Average accuracy per context required by question:
##                                 Proportion_True  Total_Count
## Untimed annotator context bins                              
## 1                                      0.781250           64
## 2                                      0.711382          246
## 3                                      0.702857          175
## 4                                      0.632653           98
## 
## &lt;string&gt;:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.</code></pre>
<pre class="python"><code>print(f&#39;Average accuracy per difficulty based on speed annotator accuracy:\n{debates.groupby(&quot;Speed annotator accuracy bins&quot;)[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(),Total_Count=&quot;size&quot;)}\nHm, this seems less likely to be a good indicator of question difficulty&#39;)</code></pre>
<pre><code>## Average accuracy per difficulty based on speed annotator accuracy:
##                                Proportion_True  Total_Count
## Speed annotator accuracy bins                              
## 0                                     0.728682          129
## 0.2                                   0.697509          281
## 0.4                                   0.694118          170
## Hm, this seems less likely to be a good indicator of question difficulty
## 
## &lt;string&gt;:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.</code></pre>
<pre class="python"><code>

# Determine settings for each row
def setups(row):
    if &#39;GPT-4&#39; in (row[&#39;Honest debater&#39;], row[&#39;Dishonest debater&#39;]):
        if row[&#39;Is single debater&#39;]:
            return &quot;AI Consultancy &quot; + (&quot;Honest&quot; if row[&#39;Has honest debater&#39;] else &quot;Dishonest&quot;)
        else:
            return &quot;AI Debate&quot;
    else:
        if row[&#39;Is single debater&#39;]:
            return &quot;Human Consultancy &quot; + (&quot;Honest&quot; if row[&#39;Has honest debater&#39;] else &quot;Dishonest&quot;)
        else:
            return &quot;Human Debate&quot;

debates[&#39;Setting&#39;] = debates.apply(setups, axis=1)
# Agregate settings - the 4 that we normally talk about:
debates[&#39;Final_Setting&#39;] = debates[&#39;Setting&#39;].str.replace(&#39; Honest&#39;, &#39;&#39;).str.replace(&#39; Dishonest&#39;, &#39;&#39;)</code></pre>
</div>
<div id="merging-filtering-for-judgments" class="section level2"
number="1.2">
<h2><span class="header-section-number">1.2</span> Merging, filtering
for judgments</h2>
<pre class="python"><code># Merge sessions with debates, so we have each judge&#39;s final probability correct and the debate&#39;s metadata
source = sessions.merge(
        debates[[&quot;Room name&quot;, &quot;Debater A&quot;,&quot;Debater B&quot;,&quot;Honest debater&quot;, &quot;Dishonest debater&quot;,
                 &quot;Is single debater&quot;, &#39;Has honest debater&#39;,
                 &quot;Final_Setting&quot;, &quot;Setting&quot;,
                 &quot;Question&quot;, &quot;Article ID&quot;,
                 &quot;Speed annotator accuracy bins&quot;,&quot;Untimed annotator context bins&quot;,
                 &quot;Speed annotator accuracy&quot;,&quot;Untimed annotator context&quot;, &quot;Is offline&quot;,
                 &#39;End time&#39;, &#39;Last modified time&#39;]],
        how=&quot;left&quot;,
        on=&quot;Room name&quot;,
    )
print(f&#39;After merging debates with sessions, we have the following participant counts for those debates:\n{source[&quot;Role&quot;].value_counts()}&#39;) </code></pre>
<pre><code>## After merging debates with sessions, we have the following participant counts for those debates:
## Role
## Judge            549
## Debater B        487
## Debater A        458
## Offline Judge    223
## Name: count, dtype: int64</code></pre>
<pre class="python"><code>#[source[&#39;Is over&#39;] == True] to check for completed online/offline debates

# Filter out incomplete judgments
judgments = source[source[&#39;Final probability correct&#39;].notnull()]
print(f&#39;After filtering to judges that have finalized their judgment, we have the following judgments per role:\n{judgments[&quot;Role&quot;].value_counts()}\nfor a total of {len(judgments)} judgments.&#39;)</code></pre>
<pre><code>## After filtering to judges that have finalized their judgment, we have the following judgments per role:
## Role
## Judge            508
## Offline Judge    214
## Name: count, dtype: int64
## for a total of 722 judgments.</code></pre>
<pre class="python"><code>judgments[&#39;Final_Accuracy&#39;] = judgments[&#39;Final probability correct&#39;] &gt; 0.5

print(f&#39;Of those judgments, we have this much for each setting (not consolidating honest - dishonest consultancies):\n{judgments[&quot;Setting&quot;].value_counts()}&#39;)</code></pre>
<pre><code>## Of those judgments, we have this much for each setting (not consolidating honest - dishonest consultancies):
## Setting
## Human Debate                   413
## AI Debate                       92
## Human Consultancy Dishonest     68
## AI Consultancy Honest           56
## Human Consultancy Honest        53
## AI Consultancy Dishonest        40
## Name: count, dtype: int64</code></pre>
<pre class="python"><code>print(f&#39;Of those judgments, we have this much for each setting (aggregated):\n{judgments.groupby(&quot;Final_Setting&quot;)[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(),Total_Count=&quot;size&quot;)}&#39;)</code></pre>
<pre><code>## Of those judgments, we have this much for each setting (aggregated):
##                    Proportion_True  Total_Count
## Final_Setting                                  
## AI Consultancy            0.802083           96
## AI Debate                 0.782609           92
## Human Consultancy         0.719008          121
## Human Debate              0.876513          413</code></pre>
<pre class="python"><code># Remove judges who see the story more than once
judgments[&#39;base_room_name&#39;] = judgments[&#39;Room name&#39;].str.extract(&#39;(.*)\d+$&#39;, expand=False).fillna(judgments[&#39;Room name&#39;])
judgments = judgments.sort_values(by=[&#39;base_room_name&#39;,&#39;End time&#39;]).groupby([&#39;Participant&#39;, &#39;base_room_name&#39;]).first().reset_index()

print(f&#39;1. We then filter to judgments where the judge has only seen a story once, and now we have this much for each setting (aggregated):\n{judgments.groupby(&quot;Final_Setting&quot;)[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(),Total_Count=&quot;size&quot;)}&#39;)</code></pre>
<pre><code>## 1. We then filter to judgments where the judge has only seen a story once, and now we have this much for each setting (aggregated):
##                    Proportion_True  Total_Count
## Final_Setting                                  
## AI Consultancy            0.802083           96
## AI Debate                 0.782609           92
## Human Consultancy         0.719008          121
## Human Debate              0.867374          377</code></pre>
<pre class="python"><code># Filter to online judges only
judgments_online = judgments[judgments[&quot;Role&quot;] == &quot;Judge&quot;]
print(f&#39;2. We\&#39;ll make a copy of the online judgments only leaving us with the following judgments:\n{judgments_online.groupby(&quot;Final_Setting&quot;)[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(),Total_Count=&quot;size&quot;)}&#39;)</code></pre>
<pre><code>## 2. We&#39;ll make a copy of the online judgments only leaving us with the following judgments:
##                    Proportion_True  Total_Count
## Final_Setting                                  
## AI Consultancy            0.797872           94
## AI Debate                 0.791209           91
## Human Consultancy         0.709091          110
## Human Debate              0.861538          195</code></pre>
<pre class="python"><code>judgments_online = judgments_online[judgments_online[&#39;Untimed annotator context bins&#39;].isin([&#39;2&#39;, &#39;3&#39;, &#39;4&#39;])]

print(f&#39;3. We then filter to judgments which require more than a sentence or two, and now we have this much for each setting (aggregated):\n{judgments_online.groupby([&quot;Final_Setting&quot;])[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(),Total_Count=&quot;size&quot;)}&#39;)</code></pre>
<pre><code>## 3. We then filter to judgments which require more than a sentence or two, and now we have this much for each setting (aggregated):
##                    Proportion_True  Total_Count
## Final_Setting                                  
## AI Consultancy            0.806452           93
## AI Debate                 0.781609           87
## Human Consultancy         0.700935          107
## Human Debate              0.838710          155</code></pre>
<pre class="python"><code>pd.set_option(&#39;display.max_columns&#39;, None)
total_counts_for_setting = judgments_online.groupby(&#39;Final_Setting&#39;).size()
result = judgments_online.groupby([&quot;Final_Setting&quot;, &quot;Untimed annotator context bins&quot;]).agg(
    Proportion_True=pd.NamedAgg(column=&#39;Final_Accuracy&#39;, aggfunc=lambda x: x.mean()),
    Context_Count=pd.NamedAgg(column=&#39;Final_Accuracy&#39;, aggfunc=&#39;size&#39;),
    Proportion_Context=pd.NamedAgg(column=&#39;Final_Setting&#39;, aggfunc=lambda x: len(x) / total_counts_for_setting[x.mode()])
)</code></pre>
<pre><code>## &lt;string&gt;:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.</code></pre>
<pre class="python"><code>print(f&#39;Are the difficult questions equally enough distributed amongst settings?:\n{result}&#39;)</code></pre>
<pre><code>## Are the difficult questions equally enough distributed amongst settings?:
##                                                   Proportion_True  \
## Final_Setting     Untimed annotator context bins                    
## AI Consultancy    1                                           NaN   
##                   2                                      0.823529   
##                   3                                      0.826087   
##                   4                                      0.736842   
## AI Debate         1                                           NaN   
##                   2                                      0.777778   
##                   3                                      0.772727   
##                   4                                      0.800000   
## Human Consultancy 1                                           NaN   
##                   2                                      0.634146   
##                   3                                      0.708333   
##                   4                                      0.833333   
## Human Debate      1                                           NaN   
##                   2                                      0.890411   
##                   3                                      0.816667   
##                   4                                      0.727273   
## 
##                                                   Context_Count  \
## Final_Setting     Untimed annotator context bins                  
## AI Consultancy    1                                           0   
##                   2                                          51   
##                   3                                          23   
##                   4                                          19   
## AI Debate         1                                           0   
##                   2                                          45   
##                   3                                          22   
##                   4                                          20   
## Human Consultancy 1                                           0   
##                   2                                          41   
##                   3                                          48   
##                   4                                          18   
## Human Debate      1                                           0   
##                   2                                          73   
##                   3                                          60   
##                   4                                          22   
## 
##                                                   Proportion_Context  
## Final_Setting     Untimed annotator context bins                      
## AI Consultancy    1                                              NaN  
##                   2                                         0.548387  
##                   3                                         0.247312  
##                   4                                         0.204301  
## AI Debate         1                                              NaN  
##                   2                                         0.517241  
##                   3                                         0.252874  
##                   4                                         0.229885  
## Human Consultancy 1                                              NaN  
##                   2                                         0.383178  
##                   3                                         0.448598  
##                   4                                         0.168224  
## Human Debate      1                                              NaN  
##                   2                                         0.470968  
##                   3                                         0.387097  
##                   4                                         0.141935</code></pre>
<pre class="python"><code>pd.reset_option(&#39;display.max_columns&#39;)</code></pre>
<p>So question difficulty isn’t perfectly balanced… but consultancies
have a different relationship with question difficulty anyway?
<strong>need a second opinion</strong></p>
</div>
<div id="trying-to-balance-the-data" class="section level2"
number="1.3">
<h2><span class="header-section-number">1.3</span> Trying to balance the
data</h2>
<ol style="list-style-type: decimal">
<li>Balancing honest &amp; dishonest consultancies</li>
<li>Question weights</li>
</ol>
<div id="balancing-honest-dishonest-consultancies"
class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Balancing honest
&amp; dishonest consultancies</h3>
<pre class="python"><code>def balance_consultancies(df, sample_setting, random_state):
    &quot;&quot;&quot;
    Sample distinct questions, then use common questions, ensure equal counts.
    &quot;&quot;&quot;
    consult_df = df[df[&#39;Setting&#39;].str.contains(sample_setting, na=False)]
    honest_df = consult_df[consult_df[&#39;Setting&#39;].str.contains(&#39;Honest&#39;)]
    dishonest_df = consult_df[consult_df[&#39;Setting&#39;].str.contains(&#39;Dishonest&#39;)]
    sample_column_name = f&#39;{sample_setting} Sample&#39;
    df[sample_column_name] = False
    # Separate into distinct and common questions
    # First, let&#39;s extract the combinations of &#39;Article ID&#39; and &#39;Question&#39; for both honest and dishonest dataframes
    honest_combinations = set(honest_df[[&#39;Article ID&#39;, &#39;Question&#39;]].itertuples(index=False, name=None))
    dishonest_combinations = set(dishonest_df[[&#39;Article ID&#39;, &#39;Question&#39;]].itertuples(index=False, name=None))
    # Identifying the common and distinct combinations
    common_combinations = honest_combinations.intersection(dishonest_combinations)
    distinct_honest_combinations = honest_combinations - common_combinations
    distinct_dishonest_combinations = dishonest_combinations - common_combinations
    # Filtering the original dataframes based on these combinations to get distinct and common dataframes
    common_honest_df = honest_df[honest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(common_combinations)]
    common_dishonest_df = dishonest_df[dishonest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(common_combinations)]
    distinct_honest_df = honest_df[honest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(distinct_honest_combinations)]
    distinct_dishonest_df = dishonest_df[dishonest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(distinct_dishonest_combinations)]
    def extract_correct_index(sample_df):
        if isinstance(sample_df.index, pd.MultiIndex):
            return sample_df.index.get_level_values(2)
        else:
            return sample_df.index
    # Get distinct consultancies
    sample_size = min(len(distinct_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;])), len(distinct_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;])))
    honest_sample = distinct_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
    dishonest_sample = distinct_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
    df.loc[extract_correct_index(honest_sample), sample_column_name] = True
    df.loc[extract_correct_index(dishonest_sample), sample_column_name] = True
    # Drop sampled questions from distinct dataframes
    honest_remove_distinct = set(honest_sample[[&#39;Article ID&#39;, &#39;Question&#39;]].itertuples(index=False, name=None))
    dishonest_remove_distinct = set(dishonest_sample[[&#39;Article ID&#39;, &#39;Question&#39;]].itertuples(index=False, name=None))
    distinct_honest_df = distinct_honest_df[~distinct_honest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(honest_remove_distinct)]
    distinct_dishonest_df = distinct_dishonest_df[~distinct_dishonest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(dishonest_remove_distinct)]
    honest_distinct_remaining = len(distinct_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]))
    dishonest_distinct_remaining = len(distinct_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]))
    # Sample from remaining distinct questions, using common questions for the other (bigger count) setting as needed
    if honest_distinct_remaining &gt; dishonest_distinct_remaining:
        sample_size = min(honest_distinct_remaining, len(common_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;])))
        honest_sample = distinct_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
        dishonest_sample = common_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
        df.loc[extract_correct_index(dishonest_sample), sample_column_name] = True
        df.loc[extract_correct_index(honest_sample), sample_column_name] = True
        dishonest_remove_common = set(dishonest_sample[[&#39;Article ID&#39;, &#39;Question&#39;]].itertuples(index=False, name=None))
        common_dishonest_df = common_dishonest_df[~common_dishonest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(dishonest_remove_common)]
        common_honest_df = common_honest_df[~common_honest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(dishonest_remove_common)]
    else:
        sample_size = min(dishonest_distinct_remaining, len(common_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;])))
        honest_sample = common_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
        dishonest_sample = distinct_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
        df.loc[extract_correct_index(dishonest_sample), sample_column_name] = True
        df.loc[extract_correct_index(honest_sample), sample_column_name] = True
        honest_remove_common = set(honest_sample[[&#39;Article ID&#39;, &#39;Question&#39;]].itertuples(index=False, name=None))
        common_dishonest_df = common_dishonest_df[~common_dishonest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(honest_remove_common)]
        common_honest_df = common_honest_df[~common_honest_df.set_index([&#39;Article ID&#39;, &#39;Question&#39;]).index.isin(honest_remove_common)]
    # Remaining independent samples from common_honest_df
    if len(common_honest_df) or len(common_dishonest_df) &gt; 0:
        sample_size = min(len(common_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;])), len(common_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;])))
        honest_sample = common_honest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
        dishonest_sample = common_dishonest_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
        df.loc[extract_correct_index(honest_sample), sample_column_name] = True
        df.loc[extract_correct_index(dishonest_sample), sample_column_name] = True
    return df


# Run the sampling to balance the consultancies
judgments_online = balance_consultancies(judgments_online, &#39;Human Consultancy&#39;, random_state = 123)
judgments_online = balance_consultancies(judgments_online, &#39;AI Consultancy&#39;, random_state = 123)
# Create one sample column for easier indexing, create mask
#sample_columns = [col for col in judgments_online.columns if &#39;Sample&#39; in col]
#judgments_online[&#39;Sample&#39;] = judgments_online[sample_columns].any(axis=1)
#consultancy_balanced = (~judgments_online[&#39;Setting&#39;].str.contains(&#39;Consultancy&#39;, case=False, na=False)) | (judgments_online[&#39;Sample&#39;] == True)

#print(f&#39;Accuracy after balancing consultancies:\n{judgments_online[consultancy_balanced].groupby([&quot;Final_Setting&quot;])[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(),Total_Count=&quot;size&quot;)}&#39;)


#from statsmodels.stats.proportion import proportions_ztest

def run_experiment(judgments_online):
    judgments_online[&#39;Sample&#39;] = False
    judgments_online = balance_consultancies(judgments_online, &#39;Human Consultancy&#39;)
    judgments_online = balance_consultancies(judgments_online, &#39;AI Consultancy&#39;)
    sample_columns = [col for col in judgments_online.columns if &#39;Sample&#39; in col]
    judgments_online[&#39;Sample&#39;] = judgments_online[sample_columns].any(axis=1)
    consultancy_balanced = (~judgments_online[&#39;Setting&#39;].str.contains(&#39;Consultancy&#39;, case=False, na=False)) | (judgments_online[&#39;Sample&#39;] == True)
    result = judgments_online[consultancy_balanced].groupby([&quot;Final_Setting&quot;])[&quot;Final_Accuracy&quot;].agg(Proportion_True=lambda x: x.mean(), Total_Count=&quot;size&quot;)
    return result

# Number of iterations
#num_iterations = 1000

# Store results from each iteration
#results = []
#p_vals = []
# Run the experiment multiple times
#for _ in range(num_iterations):
#    result = run_experiment(judgments_online.copy())  # Use a copy to ensure original data remains unchanged
#    results.append(result)
#    # Run the proportions test
#    group_human_debate = result.loc[&#39;Human Debate&#39;]
#    group_human_consultancy = result.loc[&#39;Human Consultancy&#39;]
#    count = [group_human_debate.Proportion_True * group_human_debate.Total_Count, group_human_consultancy.Proportion_True * group_human_consultancy.Total_Count]
#    nobs = [group_human_debate.Total_Count, group_human_consultancy.Total_Count]
#    z_stat, p_val = proportions_ztest(count, nobs)
#    p_vals.append(p_val)

# Calculate the average of the results
#average_result = pd.concat(results).groupby(level=0).mean()

#print(f&#39;\nAverage accuracy after {num_iterations} iterations:\n{average_result}&#39;)

#print(f&#39;pval mean: {np.mean(p_vals)}&#39;)</code></pre>
</div>
<div id="balance-debates" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Balance
debates</h3>
<pre class="python"><code>def balance_debates(df, sample_setting, random_state):
    debates_df = df[df[&#39;Setting&#39;].str.contains(sample_setting, na=False)]
    sample_column_name = f&#39;{sample_setting} Sample&#39;
    df[sample_column_name] = False
    def extract_correct_index(sample_df):
        if isinstance(sample_df.index, pd.MultiIndex):
            return sample_df.index.get_level_values(2)
        else:
            return sample_df.index
    # Get distinct consultancies
    sample_size = len(debates_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]))
    sample_debates = debates_df.groupby([&#39;Question&#39;, &#39;Article ID&#39;]).apply(lambda x: x.sample(1, random_state=random_state)).sample(sample_size, random_state=random_state)
    df.loc[extract_correct_index(sample_debates), sample_column_name] = True
    return df

# Run the sampling to balance the consultancies
judgments_online = balance_debates(judgments_online, &#39;Human Debate&#39;, random_state = 123)
judgments_online = balance_debates(judgments_online, &#39;AI Debate&#39;, random_state = 123)
# Create one sample column for easier indexing, create mask
sample_columns = [col for col in judgments_online.columns if &#39;Sample&#39; in col]
consultancy_sample_columns = [col for col in judgments_online.columns if &#39;Consultancy Sample&#39; in col]

judgments_online[&#39;Sample&#39;] = judgments_online[sample_columns].any(axis=1)
judgments_online[&#39;Consultancy Sample&#39;] = judgments_online[sample_columns].any(axis=1)

consultancy_balanced = (~judgments_online[&#39;Setting&#39;].str.contains(&#39;Consultancy&#39;, case=False, na=False)) | (judgments_online[&#39;Sample&#39;] == True)

print(f&#39;Accuracy after balancing consultancies:\n{judgments_online.groupby([&quot;Final_Setting&quot;])[&quot;Sample&quot;].value_counts()}&#39;)</code></pre>
<pre><code>## Accuracy after balancing consultancies:
## Final_Setting      Sample
## AI Consultancy     True       76
##                    False      17
## AI Debate          True       75
##                    False      12
## Human Consultancy  True       82
##                    False      25
## Human Debate       True      107
##                    False      48
## Name: count, dtype: int64</code></pre>
</div>
<div id="question-weights" class="section level3" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Question
weights</h3>
<pre class="python"><code>def question_weights(data, columns, weight_column_name, consultancy_sample=None, debate_sample=None):
    # 0. Make a copy of the original data for weight calculations
    working_data = data.copy()
    # 0.1. Custom filtering based on the &#39;Setting&#39; column
    consultancy_condition = working_data[&#39;Setting&#39;].str.contains(&#39;Consultancy&#39;, case=False, na=False)
    debate_condition = ~consultancy_condition
    if consultancy_sample is not None:
        consultancy_condition &amp;= (working_data[&#39;Sample&#39;] == consultancy_sample)
    if debate_sample is not None: # uncomment if we want to sample debates
        debate_condition &amp;= (working_data[&#39;Sample&#39;] == debate_sample)
    combined_mask = consultancy_condition | debate_condition
    working_data = working_data[combined_mask]
    # 1. Calculate the frequency of each question in the dataset
    question_frequency = working_data.groupby(columns).size()
    # 2. Invert the frequency to get the weight for each question
    question_weights = 1 / question_frequency
    # 3. Normalize the weights
    #question_weights = question_weights / question_weights.sum() * len(question_weights)
    # 4. Assign the calculated weights to the original data and fill missing values with 0
    data.loc[combined_mask, weight_column_name] = data[combined_mask].set_index(columns).index.map(question_weights).fillna(0).values
    data[weight_column_name].fillna(0, inplace=True)
    return data

judgments_online = question_weights(
    data=judgments_online, 
    columns=[&#39;Article ID&#39;, &#39;Question&#39;], 
    weight_column_name=&#39;initial_question_weights&#39;
)
judgments_online = question_weights(
    data=judgments_online, 
    columns=[&#39;Article ID&#39;, &#39;Question&#39;, &#39;Final_Setting&#39;], 
    weight_column_name=&#39;initial_question_weights_grouped_setting&#39;
)</code></pre>
<pre class="python"><code>def print_weight_summary_by_setting(df, weight_column, consultancy_sample=None):
    consultancy_condition = df[&#39;Setting&#39;].str.contains(&#39;Consultancy&#39;, case=False, na=False)
    if consultancy_sample is not None:
        consultancy_condition &amp;= (df[&#39;Sample&#39;] == consultancy_sample)
    for setting in df[&#39;Setting&#39;].unique():
        total_weight = df[df[&#39;Setting&#39;] == setting][weight_column].sum()
        print(f&quot;Total {weight_column} for {setting}: {total_weight:.2f}&quot;)
    print(&quot;\n&quot;)

print(&#39;Unsampled (initial) weights, by group setting&#39;)</code></pre>
<pre><code>## Unsampled (initial) weights, by group setting</code></pre>
<pre class="python"><code>print_weight_summary_by_setting(judgments_online, &#39;initial_question_weights_grouped_setting&#39;)</code></pre>
<pre><code>## Total initial_question_weights_grouped_setting for AI Consultancy Dishonest: 32.50
## Total initial_question_weights_grouped_setting for Human Debate: 107.00
## Total initial_question_weights_grouped_setting for AI Debate: 75.00
## Total initial_question_weights_grouped_setting for Human Consultancy Dishonest: 34.67
## Total initial_question_weights_grouped_setting for Human Consultancy Honest: 26.33
## Total initial_question_weights_grouped_setting for AI Consultancy Honest: 49.50</code></pre>
<pre class="python"><code># Recalculate weights for balanced consultancies, all debates
judgments_online = question_weights(
    data=judgments_online, 
    columns=[&#39;Article ID&#39;, &#39;Question&#39;], 
    weight_column_name=&#39;sampled_consultancies_all_debates_weights&#39;,
    consultancy_sample=True
)
judgments_online = question_weights(
    data=judgments_online, 
    columns=[&#39;Article ID&#39;, &#39;Question&#39;, &#39;Final_Setting&#39;], 
    weight_column_name=&#39;sampled_consultancies_all_debates_weights_grouped_setting&#39;,
    consultancy_sample=True
)
judgments_online = question_weights(
    data=judgments_online, 
    columns=[&#39;Article ID&#39;, &#39;Question&#39;, &#39;Setting&#39;], 
    weight_column_name=&#39;sampled_consultancies_all_debates_weights_setting&#39;,
    consultancy_sample=True
)
print(&#39;Consultancy balanced weights, by no/yes group setting&#39;)</code></pre>
<pre><code>## Consultancy balanced weights, by no/yes group setting</code></pre>
<pre class="python"><code>print_weight_summary_by_setting(judgments_online[consultancy_balanced], &#39;sampled_consultancies_all_debates_weights&#39;, consultancy_sample=True)</code></pre>
<pre><code>## Total sampled_consultancies_all_debates_weights for AI Consultancy Dishonest: 28.07
## Total sampled_consultancies_all_debates_weights for Human Debate: 82.48
## Total sampled_consultancies_all_debates_weights for AI Debate: 66.52
## Total sampled_consultancies_all_debates_weights for Human Consultancy Honest: 16.52
## Total sampled_consultancies_all_debates_weights for Human Consultancy Dishonest: 16.00
## Total sampled_consultancies_all_debates_weights for AI Consultancy Honest: 36.42</code></pre>
<pre class="python"><code>print_weight_summary_by_setting(judgments_online[consultancy_balanced], &#39;sampled_consultancies_all_debates_weights_grouped_setting&#39;, consultancy_sample=True)</code></pre>
<pre><code>## Total sampled_consultancies_all_debates_weights_grouped_setting for AI Consultancy Dishonest: 38.00
## Total sampled_consultancies_all_debates_weights_grouped_setting for Human Debate: 107.00
## Total sampled_consultancies_all_debates_weights_grouped_setting for AI Debate: 75.00
## Total sampled_consultancies_all_debates_weights_grouped_setting for Human Consultancy Honest: 30.50
## Total sampled_consultancies_all_debates_weights_grouped_setting for Human Consultancy Dishonest: 30.50
## Total sampled_consultancies_all_debates_weights_grouped_setting for AI Consultancy Honest: 38.00</code></pre>
<pre class="python"><code>print_weight_summary_by_setting(judgments_online[consultancy_balanced], &#39;sampled_consultancies_all_debates_weights_setting&#39;, consultancy_sample=True)</code></pre>
<pre><code>## Total sampled_consultancies_all_debates_weights_setting for AI Consultancy Dishonest: 38.00
## Total sampled_consultancies_all_debates_weights_setting for Human Debate: 107.00
## Total sampled_consultancies_all_debates_weights_setting for AI Debate: 75.00
## Total sampled_consultancies_all_debates_weights_setting for Human Consultancy Honest: 41.00
## Total sampled_consultancies_all_debates_weights_setting for Human Consultancy Dishonest: 41.00
## Total sampled_consultancies_all_debates_weights_setting for AI Consultancy Honest: 38.00</code></pre>
<pre class="python"><code>
judgments_online = question_weights(
    data=judgments_online, 
    columns=[&#39;Article ID&#39;, &#39;Question&#39;, &#39;Final_Setting&#39;], 
    weight_column_name=&#39;sampled_consultancies_debates_weights_grouped_setting&#39;,
    consultancy_sample=True,
    debate_sample=True
)
judgments_online = question_weights(
    data=judgments_online, 
    columns=[&#39;Article ID&#39;, &#39;Question&#39;], 
    weight_column_name=&#39;sampled_consultancies_debates_weights&#39;,
    consultancy_sample=True,
    debate_sample=True
)</code></pre>
<p>Note: we are not balancing <em>between settings</em>, and some of the
counts of the debate settings are on the same questions</p>
</div>
</div>
<div id="load-into-r-environment" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Load into R
environment</h2>
<pre class="r"><code>set.seed(123)
judgments &lt;- py$judgments
judgments_online &lt;- py$judgments_online
# Convert the Accuracy column to a factor for better plotting
judgments_online$Final_Accuracy_char &lt;- as.logical.factor(as.character(judgments_online$Final_Accuracy))
judgments_online$Participant &lt;- as.factor(judgments_online$Participant)
judgments_online$Setting &lt;- as.factor(judgments_online$Setting)


subset_dishonest &lt;- judgments_online[judgments_online$`Human Consultancy Sample` == TRUE &amp; judgments_online$Setting == &#39;Human Consultancy Dishonest&#39;, c(&quot;sampled_consultancies_all_debates_weights_grouped_setting&quot;,&quot;Final_Accuracy&quot;)]
subset_honest &lt;- judgments_online[judgments_online$`Human Consultancy Sample` == TRUE &amp; judgments_online$Setting == &#39;Human Consultancy Honest&#39;, c(&quot;sampled_consultancies_all_debates_weights_grouped_setting&quot;,&quot;Final_Accuracy&quot;)]
table(subset_dishonest$sampled_consultancies_all_debates_weights_grouped_setting, subset_dishonest$Final_Accuracy)</code></pre>
<pre><code>##      
##       FALSE TRUE
##   0.5    11   10
##   1       7   13</code></pre>
<pre class="r"><code>table(subset_honest$sampled_consultancies_all_debates_weights_grouped_setting, subset_honest$Final_Accuracy)</code></pre>
<pre><code>##      
##       FALSE TRUE
##   0.5     5   16
##   1       1   19</code></pre>
<pre class="r"><code>table(subset_dishonest$sampled_consultancies_all_debates_weights_grouped_setting)</code></pre>
<pre><code>## 
## 0.5   1 
##  21  20</code></pre>
<pre class="r"><code>table(subset_honest$sampled_consultancies_all_debates_weights_grouped_setting)</code></pre>
<pre><code>## 
## 0.5   1 
##  21  20</code></pre>
<pre class="r"><code>subset_human_consultancies &lt;- judgments_online[judgments_online$`Human Consultancy Sample` == TRUE &amp; judgments_online$Final_Setting == &#39;Human Consultancy&#39;, c(&quot;sampled_consultancies_all_debates_weights_grouped_setting&quot;,&quot;Final_Accuracy&quot;)]
table(subset_human_consultancies$sampled_consultancies_all_debates_weights_grouped_setting, subset_human_consultancies$Final_Accuracy)</code></pre>
<pre><code>##      
##       FALSE TRUE
##   0.5    16   26
##   1       8   32</code></pre>
<pre class="r"><code>table(judgments_online$Final_Setting, judgments_online$sampled_consultancies_all_debates_weights_grouped_setting)</code></pre>
<pre><code>##                    
##                      0 0.5  1
##   AI Consultancy    17   0 76
##   AI Debate          0  24 63
##   Human Consultancy 25  42 40
##   Human Debate       0  96 59</code></pre>
<pre class="r"><code>table(judgments_online$Final_Setting, judgments_online$sampled_consultancies_debates_weights)</code></pre>
<pre><code>##                    
##                      0 0.2 0.25 0.333333333333333 0.5  1
##   AI Consultancy    17   1    9                 4   1 61
##   AI Debate         12   1    9                 3   1 61
##   Human Consultancy 25   2    9                32  32  7
##   Human Debate      48   1    9                15  20 62</code></pre>
</div>
</div>
<div id="results" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Results</h1>
<div id="accuracy" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Accuracy</h2>
<div id="difference-in-proportions" class="section level3"
number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Difference in
proportions</h3>
<pre class="r"><code>acc_diff_test &lt;- function(design, Setting){
  print(design)
  freq_table &lt;- svytable(~Final_Setting+Final_Accuracy, design)
  chisq_result &lt;- svychisq(~Final_Setting+Final_Accuracy, design, statistic = &quot;Chisq&quot;)
  print(chisq_result)
  pairwise_result &lt;- pairwise.prop.test(freq_table, p.adjust.method=&quot;none&quot;, alternative=&quot;two.sided&quot;)
  print(pairwise_result)
  freq_table &lt;- cbind(freq_table, Accuracy = (freq_table[,2] / (freq_table[,1]+freq_table[,2]))*100)
  print(freq_table)
}

print(&quot;Really raw&quot;)</code></pre>
<pre><code>## [1] &quot;Really raw&quot;</code></pre>
<pre class="r"><code>acc_diff_test(svydesign(ids = ~1, data = judgments))</code></pre>
<pre><code>## Warning in svydesign.default(ids = ~1, data = judgments): No weights or
## probabilities supplied, assuming equal probability</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## print(design)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 15.218, df = 3, p-value = 0.001657
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         0.88133        -         -                
## Human Consultancy 0.20924        0.36922   -                
## Human Debate      0.14538        0.05977   0.00026          
## 
## P value adjustment method: none 
##                   FALSE TRUE Accuracy
## AI Consultancy       19   77 80.20833
## AI Debate            20   72 78.26087
## Human Consultancy    34   87 71.90083
## Human Debate         50  327 86.73740</code></pre>
<pre class="r"><code>print(&quot;Raw&quot;)</code></pre>
<pre><code>## [1] &quot;Raw&quot;</code></pre>
<pre class="r"><code>acc_diff_test(svydesign(ids = ~1, data = judgments_online))</code></pre>
<pre><code>## Warning in svydesign.default(ids = ~1, data = judgments_online): No weights or
## probabilities supplied, assuming equal probability</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## print(design)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 7.4336, df = 3, p-value = 0.05973
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         0.820          -         -                
## Human Consultancy 0.120          0.269     -                
## Human Debate      0.634          0.352     0.012            
## 
## P value adjustment method: none 
##                   FALSE TRUE Accuracy
## AI Consultancy       18   75 80.64516
## AI Debate            19   68 78.16092
## Human Consultancy    32   75 70.09346
## Human Debate         25  130 83.87097</code></pre>
<pre class="r"><code>print(&quot;Balanced consultancies&quot;)</code></pre>
<pre><code>## [1] &quot;Balanced consultancies&quot;</code></pre>
<pre class="r"><code>acc_diff_test(svydesign(ids = ~1, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting))))</code></pre>
<pre><code>## Warning in svydesign.default(ids = ~1, data = subset(judgments_online,
## `Consultancy Sample` == : No weights or probabilities supplied, assuming equal
## probability</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## print(design)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 5.9826, df = 3, p-value = 0.1132
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         0.729          -         -                
## Human Consultancy 0.159          0.352     -                
## Human Debate      0.803          0.352     0.027            
## 
## P value adjustment method: none 
##                   FALSE TRUE Accuracy
## AI Consultancy       14   62 81.57895
## AI Debate            19   68 78.16092
## Human Consultancy    24   58 70.73171
## Human Debate         25  130 83.87097</code></pre>
<pre class="r"><code>print(&quot;Balanced consultancies, question weights (grouped settings)&quot;)</code></pre>
<pre><code>## [1] &quot;Balanced consultancies, question weights (grouped settings)&quot;</code></pre>
<pre class="r"><code>acc_diff_test(svydesign(ids = ~1, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting))</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## print(design)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 3.7897, df = 3, p-value = 0.3186
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         0.89           -         -                
## Human Consultancy 0.37           0.58      -                
## Human Debate      0.74           0.47      0.13             
## 
## P value adjustment method: none 
##                   FALSE TRUE Accuracy
## AI Consultancy     14.0 62.0 81.57895
## AI Debate          15.5 59.5 79.33333
## Human Consultancy  16.0 45.0 73.77049
## Human Debate       16.5 90.5 84.57944</code></pre>
<pre class="r"><code>acc_diff_test(svydesign(ids = ~1, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting)), weights = ~sampled_consultancies_all_debates_weights))</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## print(design)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 7.6386, df = 3, p-value = 0.09546
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         1.000          -         -                
## Human Consultancy 0.409          0.446     -                
## Human Debate      0.335          0.286     0.059            
## 
## P value adjustment method: none 
##                       FALSE     TRUE Accuracy
## AI Consultancy    13.200000 51.28333 79.52959
## AI Debate         14.016667 52.50000 78.92759
## Human Consultancy  9.866667 22.65000 69.65659
## Human Debate      10.850000 71.63333 86.84583</code></pre>
<pre class="r"><code>print(&quot;Balanced consultancies sampled debates, question weights (grouped settings)&quot;)</code></pre>
<pre><code>## [1] &quot;Balanced consultancies sampled debates, question weights (grouped settings)&quot;</code></pre>
<pre class="r"><code>acc_diff_test(svydesign(ids = ~1, data = subset(judgments_online, `Sample` == TRUE), weights = ~sampled_consultancies_debates_weights_grouped_setting))</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## print(design)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 3.4707, df = 3, p-value = 0.3286
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         0.97           -         -                
## Human Consultancy 0.37           0.51      -                
## Human Debate      0.67           0.49      0.11             
## 
## P value adjustment method: none 
##                   FALSE TRUE Accuracy
## AI Consultancy       14   62 81.57895
## AI Debate            15   60 80.00000
## Human Consultancy    16   45 73.77049
## Human Debate         16   91 85.04673</code></pre>
<pre class="r"><code>acc_diff_test(svydesign(ids = ~1, data = judgments_online, weights = ~sampled_consultancies_debates_weights_grouped_setting))</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## print(design)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 4.5119, df = 3, p-value = 0.3283
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         0.97           -         -                
## Human Consultancy 0.37           0.51      -                
## Human Debate      0.67           0.49      0.11             
## 
## P value adjustment method: none 
##                   FALSE TRUE Accuracy
## AI Consultancy       14   62 81.57895
## AI Debate            15   60 80.00000
## Human Consultancy    16   45 73.77049
## Human Debate         16   91 85.04673</code></pre>
<pre class="r"><code>design = svydesign(ids = ~1, data = subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting) &amp; !grepl(&quot;AI&quot;, Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)
acc_diff_test(design)</code></pre>
<pre><code>## Independent Sampling design (with replacement)
## svydesign(ids = ~1, data = subset(judgments_online, `Human Consultancy Sample` == 
##     TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting) &amp; !grepl(&quot;AI&quot;, 
##     Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)
## 
##  Pearson&#39;s X^2: Rao &amp; Scott adjustment
## 
## data:  svychisq(~Final_Setting + Final_Accuracy, design, statistic = &quot;Chisq&quot;)
## X-squared = 4.104, df = 1, p-value = 0.05155
## 
## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  freq_table 
## 
##              Human Consultancy
## Human Debate 0.13             
## 
## P value adjustment method: none 
##                   FALSE TRUE Accuracy
## Human Consultancy  16.0 45.0 73.77049
## Human Debate       16.5 90.5 84.57944</code></pre>
<pre class="r"><code>final_table &lt;- svytable(~Final_Setting+Final_Accuracy, 
                        design = svydesign(ids = ~1, 
                                           data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting)),
                                           weights = ~sampled_consultancies_all_debates_weights_grouped_setting))
final_table</code></pre>
<pre><code>##                    Final_Accuracy
## Final_Setting       FALSE TRUE
##   AI Consultancy     14.0 62.0
##   AI Debate          15.5 59.5
##   Human Consultancy  16.0 45.0
##   Human Debate       16.5 90.5</code></pre>
<pre class="r"><code># Add accuracy
final_table &lt;- cbind(final_table, Accuracy = (final_table[,2] / (final_table[,1]+final_table[,2]))*100)
# Calculate the difference in accuracy for each row compared to &quot;Human Debate&quot;
difference_with_debate &lt;- final_table[,&quot;Accuracy&quot;] - final_table[&quot;Human Debate&quot;, &quot;Accuracy&quot;]
# Bind the difference column to the final_table
final_table &lt;- cbind(final_table, difference_with_debate)

# Loop through each setting
ci_lowers &lt;- c()
ci_uppers &lt;- c()
p_values &lt;- c()
# Loop through each setting
for (setting in rownames(final_table)) {
  # Use prop.test to compare the setting&#39;s accuracy with &quot;Human Debate&quot;
  results &lt;- prop.test(c(final_table[&quot;Human Debate&quot;, &quot;TRUE&quot;], final_table[setting, &quot;TRUE&quot;]), c((final_table[&quot;Human Debate&quot;, &quot;TRUE&quot;]+final_table[&quot;Human Debate&quot;, &quot;FALSE&quot;]), (final_table[setting, &quot;TRUE&quot;]+final_table[setting, &quot;FALSE&quot;])))
  
  # Extract the confidence interval and store it as a string in the format &quot;lower - upper&quot;
  ci_lower &lt;- results$conf.int[1] * 100  # Multiply by 100 to convert to percentage
  ci_upper &lt;- results$conf.int[2] * 100  # Multiply by 100 to convert to percentage
  ci_lowers &lt;- c(ci_lowers, ci_lower)
  ci_uppers &lt;- c(ci_uppers, ci_upper)
  p_values &lt;- c(p_values, results$p.value)
}
final_table &lt;- cbind(final_table, ci_lowers, ci_uppers, p_values)
final_table</code></pre>
<pre><code>##                   FALSE TRUE Accuracy difference_with_debate ci_lowers
## AI Consultancy     14.0 62.0 81.57895              -3.000492 -9.205452
## AI Debate          15.5 59.5 79.33333              -5.246106 -7.324725
## Human Consultancy  16.0 45.0 73.77049             -10.808947 -3.465654
## Human Debate       16.5 90.5 84.57944               0.000000 -9.677288
##                   ci_uppers  p_values
## AI Consultancy    15.206436 0.7372949
## AI Debate         17.816936 0.4731832
## Human Consultancy 25.083549 0.1329563
## Human Debate       9.677288 1.0000000</code></pre>
<pre class="r"><code># Display the updated table using knitr::kable
knitr::kable(final_table, booktab = TRUE,  digits = c(rep(1,6),3),
             col.names = c(&quot;# Incorrect (weighted)&quot;, &quot;# Correct (weighted)&quot;, &quot;Accuracy&quot;, &quot;Difference&quot;, &quot;95% CI Lower Limit&quot;,&quot;95% CI Upper Limit&quot;,&quot;p-value&quot;))</code></pre>
<table>
<colgroup>
<col width="14%" />
<col width="17%" />
<col width="16%" />
<col width="7%" />
<col width="8%" />
<col width="14%" />
<col width="14%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right"># Incorrect (weighted)</th>
<th align="right"># Correct (weighted)</th>
<th align="right">Accuracy</th>
<th align="right">Difference</th>
<th align="right">95% CI Lower Limit</th>
<th align="right">95% CI Upper Limit</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">AI Consultancy</td>
<td align="right">14.0</td>
<td align="right">62.0</td>
<td align="right">81.6</td>
<td align="right">-3.0</td>
<td align="right">-9.2</td>
<td align="right">15.2</td>
<td align="right">0.737</td>
</tr>
<tr class="even">
<td align="left">AI Debate</td>
<td align="right">15.5</td>
<td align="right">59.5</td>
<td align="right">79.3</td>
<td align="right">-5.2</td>
<td align="right">-7.3</td>
<td align="right">17.8</td>
<td align="right">0.473</td>
</tr>
<tr class="odd">
<td align="left">Human Consultancy</td>
<td align="right">16.0</td>
<td align="right">45.0</td>
<td align="right">73.8</td>
<td align="right">-10.8</td>
<td align="right">-3.5</td>
<td align="right">25.1</td>
<td align="right">0.133</td>
</tr>
<tr class="even">
<td align="left">Human Debate</td>
<td align="right">16.5</td>
<td align="right">90.5</td>
<td align="right">84.6</td>
<td align="right">0.0</td>
<td align="right">-9.7</td>
<td align="right">9.7</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<pre class="r"><code>human_only &lt;- subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting) &amp; !grepl(&quot;AI&quot;, Final_Setting))
human_only$Setting &lt;- droplevels(human_only$Setting)
table(human_only$Setting)</code></pre>
<pre><code>## 
## Human Consultancy Dishonest    Human Consultancy Honest 
##                          41                          41 
##                Human Debate 
##                         155</code></pre>
<pre class="r"><code>final_table &lt;- svytable(~Setting+Final_Accuracy, 
                        design = svydesign(ids = ~1, 
                                           data = human_only,
                                           weights = ~sampled_consultancies_all_debates_weights_setting))
final_table</code></pre>
<pre><code>##                              Final_Accuracy
## Setting                       FALSE TRUE
##   Human Consultancy Dishonest  18.0 23.0
##   Human Consultancy Honest      6.0 35.0
##   Human Debate                 16.5 90.5</code></pre>
<pre class="r"><code># Add accuracy
final_table &lt;- cbind(final_table, Accuracy = (final_table[,2] / (final_table[,1]+final_table[,2]))*100)
# Calculate the difference in accuracy for each row compared to &quot;Human Debate&quot;
difference_with_debate &lt;- final_table[,&quot;Accuracy&quot;] - final_table[&quot;Human Debate&quot;, &quot;Accuracy&quot;]
# Bind the difference column to the final_table
final_table &lt;- cbind(final_table, difference_with_debate)

# Loop through each setting
ci_lowers &lt;- c()
ci_uppers &lt;- c()
p_values &lt;- c()
# Loop through each setting
for (setting in rownames(final_table)) {
  # Use prop.test to compare the setting&#39;s accuracy with &quot;Human Debate&quot;
  results &lt;- prop.test(c(final_table[&quot;Human Debate&quot;, &quot;TRUE&quot;], final_table[setting, &quot;TRUE&quot;]), c((final_table[&quot;Human Debate&quot;, &quot;TRUE&quot;]+final_table[&quot;Human Debate&quot;, &quot;FALSE&quot;]), (final_table[setting, &quot;TRUE&quot;]+final_table[setting, &quot;FALSE&quot;])))
  
  # Extract the confidence interval and store it as a string in the format &quot;lower - upper&quot;
  ci_lower &lt;- results$conf.int[1] * 100  # Multiply by 100 to convert to percentage
  ci_upper &lt;- results$conf.int[2] * 100  # Multiply by 100 to convert to percentage
  ci_lowers &lt;- c(ci_lowers, ci_lower)
  ci_uppers &lt;- c(ci_uppers, ci_upper)
  p_values &lt;- c(p_values, results$p.value)
}
final_table &lt;- cbind(final_table, ci_lowers, ci_uppers, p_values)
final_table</code></pre>
<pre><code>##                             FALSE TRUE Accuracy difference_with_debate
## Human Consultancy Dishonest  18.0 23.0 56.09756            -28.4818783
## Human Consultancy Honest      6.0 35.0 85.36585              0.7864144
## Human Debate                 16.5 90.5 84.57944              0.0000000
##                              ci_lowers ci_uppers     p_values
## Human Consultancy Dishonest  10.134444 46.829313 0.0005598759
## Human Consultancy Honest    -14.374115 12.801286 1.0000000000
## Human Debate                 -9.677288  9.677288 1.0000000000</code></pre>
<pre class="r"><code># Display the updated table using knitr::kable
knitr::kable(final_table, booktab = TRUE,  digits = c(rep(1,6),3),
             col.names = c(&quot;# Incorrect (weighted)&quot;, &quot;# Correct (weighted)&quot;, &quot;Accuracy&quot;, &quot;Difference&quot;, &quot;95% CI Lower Limit&quot;,&quot;95% CI Upper Limit&quot;,&quot;p-value&quot;))</code></pre>
<table>
<colgroup>
<col width="20%" />
<col width="16%" />
<col width="15%" />
<col width="6%" />
<col width="7%" />
<col width="13%" />
<col width="13%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right"># Incorrect (weighted)</th>
<th align="right"># Correct (weighted)</th>
<th align="right">Accuracy</th>
<th align="right">Difference</th>
<th align="right">95% CI Lower Limit</th>
<th align="right">95% CI Upper Limit</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Human Consultancy Dishonest</td>
<td align="right">18.0</td>
<td align="right">23.0</td>
<td align="right">56.1</td>
<td align="right">-28.5</td>
<td align="right">10.1</td>
<td align="right">46.8</td>
<td align="right">0.001</td>
</tr>
<tr class="even">
<td align="left">Human Consultancy Honest</td>
<td align="right">6.0</td>
<td align="right">35.0</td>
<td align="right">85.4</td>
<td align="right">0.8</td>
<td align="right">-14.4</td>
<td align="right">12.8</td>
<td align="right">1.000</td>
</tr>
<tr class="odd">
<td align="left">Human Debate</td>
<td align="right">16.5</td>
<td align="right">90.5</td>
<td align="right">84.6</td>
<td align="right">0.0</td>
<td align="right">-9.7</td>
<td align="right">9.7</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<pre class="r"><code>prop_table &lt;- svytable(~Final_Setting+Final_Accuracy, design = svydesign(ids = ~1, data = subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting) &amp; !grepl(&quot;AI&quot;, Final_Setting)),weights = ~sampled_consultancies_all_debates_weights))
#prop_table &lt;- svytable(~Final_Setting+Final_Accuracy, design = svydesign(ids = ~1, data = subset(judgments_online, !grepl(&quot;Consultancy&quot;, Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting))
prop_table</code></pre>
<pre><code>##                    Final_Accuracy
## Final_Setting           FALSE      TRUE
##   Human Consultancy  9.866667 22.650000
##   Human Debate      10.850000 71.633333</code></pre>
<pre class="r"><code>print(prop.test(c(prop_table[&quot;Human Consultancy&quot;,&quot;TRUE&quot;],prop_table[&quot;Human Debate&quot;,&quot;TRUE&quot;]),c(prop_table[&quot;Human Consultancy&quot;, &quot;TRUE&quot;]+prop_table[&quot;Human Consultancy&quot;, &quot;FALSE&quot;], prop_table[&quot;Human Debate&quot;, &quot;TRUE&quot;]+prop_table[&quot;Human Debate&quot;, &quot;FALSE&quot;])))</code></pre>
<pre><code>## 
##  2-sample test for equality of proportions with continuity correction
## 
## data:  c(prop_table[&quot;Human Consultancy&quot;, &quot;TRUE&quot;], prop_table[&quot;Human Debate&quot;, &quot;TRUE&quot;]) out of c(prop_table[&quot;Human Consultancy&quot;, &quot;TRUE&quot;] + prop_table[&quot;Human Consultancy&quot;, &quot;FALSE&quot;], prop_table[&quot;Human Debate&quot;, &quot;TRUE&quot;] + prop_table[&quot;Human Debate&quot;, &quot;FALSE&quot;])
## X-squared = 3.5746, df = 1, p-value = 0.05867
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.36737199  0.02358717
## sample estimates:
##    prop 1    prop 2 
## 0.6965659 0.8684583</code></pre>
<pre class="r"><code>judgments_online$fpc &lt;- judgments_online$`Final probability correct`
judgments_online %&gt;%
  ggplot() +
  geom_boxplot(aes(x = Final_Setting, y = fpc)) +
  labs(y = &quot;fpc&quot;, x = &quot;Setting&quot;)+
  theme_minimal()</code></pre>
<p><img src="debate-2309_files/figure-html/final%20probability%20correct-1.png" width="672" /></p>
<pre class="r"><code>judgments_online %&gt;%
  group_by(Final_Setting) %&gt;% summarise(fpcmed = median(fpc),
                                                           fpcmean = mean(Final_Accuracy)) %&gt;%
  ggplot() +
  geom_boxplot(aes(x = Final_Setting, y = fpcmean)) +
  labs(y = &quot;acc&quot;, x = &quot;Setting&quot;)+
  theme_minimal()</code></pre>
<p><img src="debate-2309_files/figure-html/final%20probability%20correct-2.png" width="672" /></p>
<pre class="r"><code>consultancy_design &lt;- svydesign(ids = ~1, data = subset(judgments_online, `Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)



human_consultancy_design &lt;- svydesign(ids = ~1, data = subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting) &amp; !grepl(&quot;AI&quot;, Final_Setting)), weights = ~sampled_consultancies_all_debates_weights_grouped_setting)


svyranktest(fpc~Final_Setting, human_consultancy_design)</code></pre>
<pre><code>## 
##  Design-based KruskalWallis test
## 
## data:  fpc ~ Final_Setting
## t = 2.4508, df = 235, p-value = 0.01499
## alternative hypothesis: true difference in mean rank score is not equal to 0
## sample estimates:
## difference in mean rank score 
##                     0.0969166</code></pre>
<pre class="r"><code>judgments_online %&gt;% group_by(Final_Setting) %&gt;% summarise(fpcmed = median(fpc),
                                                           fpcmean = mean(fpc))</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Final_Setting"],"name":[1],"type":["chr"],"align":["left"]},{"label":["fpcmed"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["fpcmean"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"AI Consultancy","2":"0.96","3":"0.7639785"},{"1":"AI Debate","2":"0.99","3":"0.7539080"},{"1":"Human Consultancy","2":"0.87","3":"0.6722430"},{"1":"Human Debate","2":"0.95","3":"0.7921935"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>svyranktest(fpc~Final_Setting, consultancy_design, test = &quot;median&quot;)</code></pre>
<pre><code>## 
##  Design-based median test
## 
## data:  fpc ~ Final_Setting
## df = 3, Chisq = 13.969, p-value = 0.003272</code></pre>
<pre class="r"><code>svyranktest(fpc~Final_Setting, consultancy_design, test = &quot;wilcoxon&quot;)</code></pre>
<pre><code>## 
##  Design-based KruskalWallis test
## 
## data:  fpc ~ Final_Setting
## df = 3, Chisq = 12.446, p-value = 0.006514</code></pre>
<pre class="r"><code>svyranktest(fpc~Final_Setting, consultancy_design, test = &quot;vanderWaerden&quot;)</code></pre>
<pre><code>## 
##  Design-based vanderWaerden test
## 
## data:  fpc ~ Final_Setting
## df = 3, Chisq = 9.8037, p-value = 0.02133</code></pre>
<pre class="r"><code>weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)</code></pre>
<pre><code>## Warning in summary.glm(glm.object): observations with zero weight not used for
## calculating dispersion</code></pre>
<pre><code>## 
## # Weighted Kruskal-Wallis test
## 
##   comparison of fpc by Final_Setting
##   Chisq=3.00  df=12  p-value=0.006</code></pre>
<pre class="r"><code>data(efc)
str(efc)</code></pre>
<pre><code>## &#39;data.frame&#39;:    908 obs. of  26 variables:
##  $ c12hour : num  16 148 70 168 168 16 161 110 28 40 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;average number of hours of care per week&quot;
##  $ e15relat: num  2 2 1 1 2 2 1 4 2 2 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;relationship to elder&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:8] 1 2 3 4 5 6 7 8
##   .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;spouse/partner&quot; &quot;child&quot; &quot;sibling&quot; &quot;daughter or son -in-law&quot; ...
##  $ e16sex  : num  2 2 2 2 2 2 1 2 2 2 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;elder&#39;s gender&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:2] 1 2
##   .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;male&quot; &quot;female&quot;
##  $ e17age  : num  83 88 82 67 84 85 74 87 79 83 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;elder&#39; age&quot;
##  $ e42dep  : num  3 3 3 4 4 4 4 4 4 4 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;elder&#39;s dependency&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;independent&quot; &quot;slightly dependent&quot; &quot;moderately dependent&quot; &quot;severely dependent&quot;
##  $ c82cop1 : num  3 3 2 4 3 2 4 3 3 3 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;do you feel you cope well as caregiver?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;never&quot; &quot;sometimes&quot; &quot;often&quot; &quot;always&quot;
##  $ c83cop2 : num  2 3 2 1 2 2 2 2 2 2 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;do you find caregiving too demanding?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Never&quot; &quot;Sometimes&quot; &quot;Often&quot; &quot;Always&quot;
##  $ c84cop3 : num  2 3 1 3 1 3 4 2 3 1 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;does caregiving cause difficulties in your relationship with your friends?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Never&quot; &quot;Sometimes&quot; &quot;Often&quot; &quot;Always&quot;
##  $ c85cop4 : num  2 3 4 1 2 3 1 1 2 2 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;does caregiving have negative effect on your physical health?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Never&quot; &quot;Sometimes&quot; &quot;Often&quot; &quot;Always&quot;
##  $ c86cop5 : num  1 4 1 1 2 3 1 1 2 1 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;does caregiving cause difficulties in your relationship with your family?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Never&quot; &quot;Sometimes&quot; &quot;Often&quot; &quot;Always&quot;
##  $ c87cop6 : num  1 1 1 1 2 2 2 1 1 1 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;does caregiving cause financial difficulties?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Never&quot; &quot;Sometimes&quot; &quot;Often&quot; &quot;Always&quot;
##  $ c88cop7 : num  2 3 1 1 1 2 4 2 3 1 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;do you feel trapped in your role as caregiver?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Never&quot; &quot;Sometimes&quot; &quot;Often&quot; &quot;Always&quot;
##  $ c89cop8 : num  3 2 4 2 4 1 1 3 1 1 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;do you feel supported by friends/neighbours?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;never&quot; &quot;sometimes&quot; &quot;often&quot; &quot;always&quot;
##  $ c90cop9 : num  3 2 3 4 4 1 4 3 3 3 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;do you feel caregiving worthwhile?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4
##   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;never&quot; &quot;sometimes&quot; &quot;often&quot; &quot;always&quot;
##  $ c160age : num  56 54 80 69 47 56 61 67 59 49 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;carer&#39; age&quot;
##  $ c161sex : num  2 2 1 1 2 1 2 2 2 2 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;carer&#39;s gender&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:2] 1 2
##   .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Male&quot; &quot;Female&quot;
##  $ c172code: num  2 2 1 2 2 2 2 2 NA 2 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;carer&#39;s level of education&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:3] 1 2 3
##   .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;low level of education&quot; &quot;intermediate level of education&quot; &quot;high level of education&quot;
##  $ c175empl: num  1 1 0 0 0 1 0 0 0 0 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;are you currently employed?&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:2] 0 1
##   .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;no&quot; &quot;yes&quot;
##  $ barthtot: num  75 75 35 0 25 60 5 35 15 0 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Total score BARTHEL INDEX&quot;
##  $ neg_c_7 : num  12 20 11 10 12 19 15 11 15 10 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Negative impact with 7 items&quot;
##  $ pos_v_4 : num  12 11 13 15 15 9 13 14 13 13 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Positive value with 4 items&quot;
##  $ quol_5  : num  14 10 7 12 19 8 20 20 8 15 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Quality of life 5 items&quot;
##  $ resttotn: num  0 4 0 2 2 1 0 0 0 1 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Job restrictions&quot;
##  $ tot_sc_e: num  4 0 1 0 1 3 0 1 2 1 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Services for elderly&quot;
##  $ n4pstu  : num  0 0 2 3 2 2 3 1 3 3 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Care level&quot;
##   ..- attr(*, &quot;labels&quot;)= Named chr [1:5] &quot;0&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ...
##   .. ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;No Care Level&quot; &quot;Care Level 1&quot; &quot;Care Level 2&quot; &quot;Care Level 3&quot; ...
##  $ nur_pst : num  NA NA 2 3 2 2 3 1 3 3 ...
##   ..- attr(*, &quot;label&quot;)= chr &quot;Care level&quot;
##   ..- attr(*, &quot;labels&quot;)= Named chr [1:3] &quot;1&quot; &quot;2&quot; &quot;3&quot;
##   .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;Care Level 1&quot; &quot;Care Level 2&quot; &quot;Care Level 3/3+&quot;</code></pre>
<pre class="r"><code>efc$weight &lt;- abs(rnorm(nrow(efc), 1, .3))
weighted_mannwhitney(c12hour ~ c161sex + weight, efc)</code></pre>
<pre><code>## 
## # Weighted Mann-Whitney-U test
## 
##   comparison of c12hour by c161sex
##   Chisq=2.47  df=899  p-value=0.014</code></pre>
<pre class="r"><code>weighted_mannwhitney(fpc ~ Final_Setting + sampled_consultancies_all_debates_weights_grouped_setting, judgments_online)</code></pre>
<pre><code>## Warning in summary.glm(glm.object): observations with zero weight not used for
## calculating dispersion</code></pre>
<pre><code>## 
## # Weighted Kruskal-Wallis test
## 
##   comparison of fpc by Final_Setting
##   Chisq=3.00  df=12  p-value=0.006</code></pre>
<pre class="r"><code>wilcox.test(efc$c12hour,efc$c161sex)</code></pre>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  efc$c12hour and efc$c161sex
## W = 812702, p-value &lt; 0.00000000000000022
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<pre class="r"><code>judgments_online$fpcw &lt;- judgments_online$fpc *judgments_online$sampled_consultancies_all_debates_weights_grouped_setting
wilcox.test(fpcw~Final_Setting, subset(judgments_online, `Human Consultancy Sample` == TRUE | !grepl(&quot;Consultancy&quot;, Final_Setting) &amp; !grepl(&quot;AI&quot;, Final_Setting)), conf.int=T)</code></pre>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  fpcw by Final_Setting
## W = 5837, p-value = 0.3003
## alternative hypothesis: true location shift is not equal to 0
## 95 percent confidence interval:
##  -0.09001393  0.01492054
## sample estimates:
## difference in location 
##            -0.01505394</code></pre>
</div>
<div id="logistic-regression" class="section level3" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Logistic
regression</h3>
<pre class="r"><code>#judgments_online$Final_Setting &lt;- relevel(judgments_online$Final_Setting, ref = &quot;Human Debate&quot;)
model1 &lt;- glm(Final_Accuracy ~ relevel(factor(Final_Setting), &#39;Human Debate&#39;), family = &#39;binomial&#39;, data = judgments_online)

summary(model1)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Final_Accuracy ~ relevel(factor(Final_Setting), 
##     &quot;Human Debate&quot;), family = &quot;binomial&quot;, data = judgments_online)
## 
## Coefficients:
##                                                                 Estimate
## (Intercept)                                                       1.6487
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy     -0.2215
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate          -0.3736
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy  -0.7969
##                                                                 Std. Error
## (Intercept)                                                         0.2184
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy        0.3414
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate             0.3392
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy     0.3038
##                                                                 z value
## (Intercept)                                                       7.549
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy     -0.649
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate          -1.102
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy  -2.623
##                                                                           Pr(&gt;|z|)
## (Intercept)                                                     0.0000000000000438
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy               0.51644
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                    0.27067
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy            0.00871
##                                                                    
## (Intercept)                                                     ***
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy       
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate            
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 457.45  on 441  degrees of freedom
## Residual deviance: 450.23  on 438  degrees of freedom
## AIC: 458.23
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>table(model1$fitted.values &gt; 0.5) </code></pre>
<pre><code>## 
## TRUE 
##  442</code></pre>
<pre class="r"><code>table(judgments_online$Final_Accuracy)</code></pre>
<pre><code>## 
## FALSE  TRUE 
##    94   348</code></pre>
<pre class="r"><code>model2 &lt;- glm(Final_Accuracy ~ relevel(factor(Participant),&#39;Aliyaah Toussaint&#39;) + relevel(factor(Final_Setting), &#39;Human Debate&#39;), family = &#39;binomial&#39;, data = judgments_online)

summary(model2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Final_Accuracy ~ relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;) + 
##     relevel(factor(Final_Setting), &quot;Human Debate&quot;), family = &quot;binomial&quot;, 
##     data = judgments_online)
## 
## Coefficients:
##                                                                       Estimate
## (Intercept)                                                            2.19432
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Adelle Fernando      -0.79600
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Anuj Jain            -0.89691
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)David Rein           -0.43887
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Emmanuel Makinde    -17.76039
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Ethan Rosen          -0.24841
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jackson Petty        -0.55820
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jessica Li           -0.16347
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julian Michael       -0.08063
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julien Dirani        13.37175
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Max Layden           13.37175
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Noor Mirza-Rashid    -1.27803
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Reeya Kansra         -0.96379
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Salsabila Mahdi      -0.17942
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sam Jin              -0.01031
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sean Wang             0.17177
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shlomo Kofman        -1.13135
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shreeram Modi        -1.16733
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Vishakh Padmakumar   -0.40256
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy          -0.27193
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate               -0.42241
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy       -0.74485
##                                                                     Std. Error
## (Intercept)                                                            0.49853
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Adelle Fernando       0.63661
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Anuj Jain             0.53893
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)David Rein            0.77471
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Emmanuel Makinde   1455.39762
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Ethan Rosen           1.17957
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jackson Petty         0.66085
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jessica Li            0.64365
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julian Michael        0.75783
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julien Dirani      1029.12159
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Max Layden         1029.12159
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Noor Mirza-Rashid     0.97393
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Reeya Kansra          0.58143
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Salsabila Mahdi       0.90289
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sam Jin               0.56587
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sean Wang             0.67879
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shlomo Kofman         0.50759
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shreeram Modi         0.63420
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Vishakh Padmakumar    1.18962
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy           0.39222
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                0.39204
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy        0.36432
##                                                                     z value
## (Intercept)                                                           4.402
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Adelle Fernando     -1.250
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Anuj Jain           -1.664
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)David Rein          -0.566
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Emmanuel Makinde    -0.012
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Ethan Rosen         -0.211
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jackson Petty       -0.845
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jessica Li          -0.254
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julian Michael      -0.106
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julien Dirani        0.013
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Max Layden           0.013
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Noor Mirza-Rashid   -1.312
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Reeya Kansra        -1.658
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Salsabila Mahdi     -0.199
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sam Jin             -0.018
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sean Wang            0.253
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shlomo Kofman       -2.229
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shreeram Modi       -1.841
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Vishakh Padmakumar  -0.338
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy         -0.693
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate              -1.077
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy      -2.045
##                                                                      Pr(&gt;|z|)
## (Intercept)                                                         0.0000107
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Adelle Fernando       0.2112
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Anuj Jain             0.0961
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)David Rein            0.5711
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Emmanuel Makinde      0.9903
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Ethan Rosen           0.8332
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jackson Petty         0.3983
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jessica Li            0.7995
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julian Michael        0.9153
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julien Dirani         0.9896
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Max Layden            0.9896
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Noor Mirza-Rashid     0.1894
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Reeya Kansra          0.0974
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Salsabila Mahdi       0.8425
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sam Jin               0.9855
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sean Wang             0.8002
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shlomo Kofman         0.0258
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shreeram Modi         0.0657
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Vishakh Padmakumar    0.7351
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy           0.4881
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                0.2813
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy        0.0409
##                                                                        
## (Intercept)                                                         ***
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Adelle Fernando       
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Anuj Jain          .  
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)David Rein            
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Emmanuel Makinde      
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Ethan Rosen           
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jackson Petty         
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Jessica Li            
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julian Michael        
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Julien Dirani         
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Max Layden            
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Noor Mirza-Rashid     
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Reeya Kansra       .  
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Salsabila Mahdi       
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sam Jin               
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Sean Wang             
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shlomo Kofman      *  
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Shreeram Modi      .  
## relevel(factor(Participant), &quot;Aliyaah Toussaint&quot;)Vishakh Padmakumar    
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy           
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy     *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 457.45  on 441  degrees of freedom
## Residual deviance: 429.05  on 420  degrees of freedom
## AIC: 473.05
## 
## Number of Fisher Scoring iterations: 14</code></pre>
</div>
<div id="lmer" class="section level3" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> LMER</h3>
<pre class="r"><code>random.intercept.model = lmer(`Final probability correct` ~ (1|Final_Setting), 
                              data = judgments, REML = TRUE)
judgments$random.intercept.preds = predict(random.intercept.model)
summary(random.intercept.model)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: `Final probability correct` ~ (1 | Final_Setting)
##    Data: judgments
## 
## REML criterion at convergence: 364
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5652 -0.2013  0.5015  0.5654  0.9255 
## 
## Random effects:
##  Groups        Name        Variance Std.Dev.
##  Final_Setting (Intercept) 0.00272  0.05215 
##  Residual                  0.09799  0.31304 
## Number of obs: 686, groups:  Final_Setting, 4
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  0.75723    0.02948 3.33321   25.68  0.00006 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>ranef(random.intercept.model)</code></pre>
<pre><code>## $Final_Setting
##                    (Intercept)
## AI Consultancy     0.002319435
## AI Debate         -0.001131440
## Human Consultancy -0.056960042
## Human Debate       0.055772047
## 
## with conditional variances for &quot;Final_Setting&quot;</code></pre>
<pre class="r"><code>ranova(random.intercept.model)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["npar"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["logLik"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["LRT"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"3","2":"-182.0001","3":"370.0002","4":"NA","5":"NA","6":"NA","_rn_":"<none>"},{"1":"2","2":"-187.2282","3":"378.4564","4":"10.45621","5":"1","6":"0.001222376","_rn_":"(1 | Final_Setting)"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>random.intercept.model = lmer(`Final probability correct` ~ (1|Participant) + (1|Final_Setting), 
                              data = judgments, REML = TRUE)
judgments$random.intercept.preds = predict(random.intercept.model)
summary(random.intercept.model)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: `Final probability correct` ~ (1 | Participant) + (1 | Final_Setting)
##    Data: judgments
## 
## REML criterion at convergence: 357.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.7461 -0.1555  0.4368  0.5996  1.1083 
## 
## Random effects:
##  Groups        Name        Variance Std.Dev.
##  Participant   (Intercept) 0.002215 0.04707 
##  Final_Setting (Intercept) 0.002718 0.05213 
##  Residual                  0.095721 0.30939 
## Number of obs: 686, groups:  Participant, 19; Final_Setting, 4
## 
## Fixed effects:
##             Estimate Std. Error      df t value   Pr(&gt;|t|)    
## (Intercept)  0.75549    0.03211 4.44845   23.52 0.00000772 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>ranef(random.intercept.model)</code></pre>
<pre><code>## $Participant
##                      (Intercept)
## Adelle Fernando    -0.0231887667
## Aliyaah Toussaint   0.0445495902
## Anuj Jain          -0.0460548530
## David Rein          0.0107246587
## Emmanuel Makinde   -0.0115704647
## Ethan Rosen        -0.0171199427
## Jackson Petty      -0.0051104119
## Jessica Li         -0.0047621455
## Julian Michael      0.0348708056
## Julien Dirani      -0.0008138972
## Max Layden         -0.0038287458
## Noor Mirza-Rashid  -0.0117445230
## Reeya Kansra       -0.0261229696
## Salsabila Mahdi     0.0321800144
## Sam Jin             0.0480694982
## Sean Wang           0.0477306783
## Shlomo Kofman      -0.0519667486
## Shreeram Modi       0.0020512016
## Vishakh Padmakumar -0.0178929784
## 
## $Final_Setting
##                     (Intercept)
## AI Consultancy     0.0012586597
## AI Debate         -0.0009034629
## Human Consultancy -0.0564188188
## Human Debate       0.0560636219
## 
## with conditional variances for &quot;Participant&quot; &quot;Final_Setting&quot;</code></pre>
<pre class="r"><code>ranova(random.intercept.model)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["npar"],"name":[1],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["LRT"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"4","2":"-178.9522","3":"365.9045","4":"NA","5":"NA","6":"NA","_rn_":"<none>"},{"1":"3","2":"-182.0001","3":"370.0002","4":"6.095678","5":"1","6":"0.013551293","_rn_":"(1 | Participant)"},{"1":"3","2":"-183.6525","3":"373.3049","4":"9.400441","5":"1","6":"0.002169332","_rn_":"(1 | Final_Setting)"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="brms" class="section level3" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> BRMS</h3>
<pre class="r"><code>#brm1 &lt;- brm(data = judgments_online,
#             formula = as.numeric(Final_Accuracy) | trials(2) ~ 1 + (1 | Final_Setting),
#             family = binomial(&quot;identity&quot;),
#             iter = 2000, warmup = 1000, chains = 4, cores = 4,
#             control = list(adapt_delta = .975, max_treedepth = 20),
#             seed = 190831)
#plot(brm1)</code></pre>
</div>
</div>
<div id="efficiency" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Efficiency</h2>
<div id="quotes-caveats" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Quotes %,
caveats</h3>
<pre class="python"><code>characters = turns.merge(
        debates[[&quot;Room name&quot;, &quot;Question&quot;, &quot;Story length&quot;,
                 &quot;Untimed annotator context&quot;,&quot;Untimed annotator context bins&quot;,
                 &quot;Setting&quot;, &quot;Final_Setting&quot;, &quot;Final_Accuracy&quot;,
                 &quot;Is offline&quot;]],
        how=&quot;left&quot;,
        on=&quot;Room name&quot;,
    )



# Filtering for specific roles
characters = characters[characters[&#39;Role (honest/dishonest)&#39;].isin([&#39;Honest debater&#39;, &#39;Dishonest debater&#39;])]

# Extracting the spans
def extract_spans(span_str):
    &quot;&quot;&quot;Extract numerical spans from the given string.&quot;&quot;&quot;
    if pd.isna(span_str):
        return []
    spans = re.findall(r&#39;&lt;&lt;(\d+)-(\d+)&gt;&gt;&#39;, span_str)
    return [(int(start), int(end)) for start, end in spans]

# Merging overlapping spans
def merge_overlapping_spans(span_str):
    if not isinstance(span_str, str):
        return span_str
    spans = extract_spans(span_str)
    if not spans:
        return span_str
    spans.sort(key=lambda x: x[0])
    merged = [spans[0]]
    for current in spans:
        previous = merged[-1]
        if current[0] &lt;= previous[1]:
            upper_bound = max(previous[1], current[1])
            merged[-1] = (previous[0], upper_bound)
        else:
            merged.append(current)
    return &#39; &#39;.join(f&#39;&lt;&lt;{start}-{end}&gt;&gt;&#39; for start, end in merged)

# Aggregating function to concatenate quote spans
def custom_join(series):
    return &#39; &#39;.join(filter(lambda x: isinstance(x, str), series))

# Identify questions with more than one setting and filter out the characters dataframe
questions_with_multi_settings = characters.groupby(&quot;Question&quot;).filter(lambda x: len(x[&quot;Setting&quot;].unique()) &gt; 1)[&quot;Question&quot;].unique()
filtered_characters = characters[characters[&quot;Question&quot;].isin(questions_with_multi_settings)]

# Aggregating data
aggregates = {
    &#39;Quote length&#39;: &#39;sum&#39;,
    &#39;Story length&#39;: &#39;mean&#39;,
    &#39;Num previous judging rounds&#39;: &#39;max&#39;,
    &#39;Participant quote span&#39;: custom_join
}
# Grouping by &#39;Room name&#39; and aggregating
characters_agg_by_room = filtered_characters.groupby(&#39;Room name&#39;).agg(aggregates).reset_index()

# Merging the aggregated results with the original data to reintroduce the desired columns
characters_agg = characters_agg_by_room.merge(
    filtered_characters[[&#39;Room name&#39;, &#39;Setting&#39;, &#39;Final_Setting&#39;, &#39;Question&#39;, &#39;Untimed annotator context bins&#39;,&#39;Final_Accuracy&#39;]].drop_duplicates(),
    on=&#39;Room name&#39;
)

# Merge overlapping spans after the aggregation
characters_agg[&quot;merged_quote_spans&quot;] = characters_agg[&quot;Participant quote span&quot;].apply(merge_overlapping_spans)

# Functions to compute and compare spans across settings
def extract_numbers_from_span(span_str):
    spans = extract_spans(span_str)
    numbers = set()
    for start, end in spans:
        numbers.update(range(int(start), int(end)+1))
    return numbers

def quote_length(span_str):
  spans = extract_spans(span_str)
  numbers = set()
  for start, end in spans:
    numbers.update(range(int(start), int(end)))
  return numbers

characters_agg[&quot;quote_length&quot;] = characters_agg[&quot;Participant quote span&quot;].apply(lambda row: len(quote_length(row)))
#characters_agg[&quot;merged_quote_length&quot;] = characters_agg[&quot;Participant quote span&quot;].apply(lambda row: len(quote_length(row)))
#print(characters_agg[&quot;merged_quote_length&quot;][1])
#print((characters_agg[&quot;merged_quote_length&quot;]==characters_agg[&quot;quote_length&quot;]).value_counts())

#print((characters_agg[&#39;quote_length&#39;].fillna(0)/characters_agg[&#39;Story length&#39;].fillna(0)).describe())


def convert_to_span_format(numbers):
    sorted_numbers = sorted(list(numbers))
    spans = []
    if sorted_numbers:
        start = sorted_numbers[0]
        end = sorted_numbers[0]
        for num in sorted_numbers[1:]:
            if num == end + 1:
                end = num
            else:
                spans.append((start, end))
                start = end = num
        spans.append((start, end))
    return &#39; &#39;.join(f&#39;&lt;&lt;{start}-{end}&gt;&gt;&#39; for start, end in spans)

def compute_span_differences(dataframe):
    differences = {}
    for question, group in dataframe.groupby(&quot;Question&quot;):
        settings = group[&quot;Setting&quot;].unique()
        if len(settings) &gt; 1:
            for i in range(len(settings)):
                for j in range(i+1, len(settings)):
                    setting_1 = settings[i]
                    setting_2 = settings[j]
                    room_1 = group[group[&quot;Setting&quot;] == setting_1][&quot;Room name&quot;].values[0]
                    room_2 = group[group[&quot;Setting&quot;] == setting_2][&quot;Room name&quot;].values[0]
                    acc_1 = group[group[&quot;Setting&quot;] == setting_1][&quot;Final_Accuracy&quot;].values[0]
                    acc_2 = group[group[&quot;Setting&quot;] == setting_2][&quot;Final_Accuracy&quot;].values[0]
                    span_str_1 = group[group[&quot;Setting&quot;] == setting_1][&quot;merged_quote_spans&quot;].values[0]
                    span_str_2 = group[group[&quot;Setting&quot;] == setting_2][&quot;merged_quote_spans&quot;].values[0]
                    numbers_1 = extract_numbers_from_span(span_str_1)
                    numbers_2 = extract_numbers_from_span(span_str_2)
                    diff_1 = numbers_1 - numbers_2
                    diff_2 = numbers_2 - numbers_1
                    key = (question, setting_1, room_1, acc_1, setting_2, room_2, acc_2)
                    value = (convert_to_span_format(diff_1), convert_to_span_format(diff_2))
                    differences[key] = value
    return differences

span_differences_all = compute_span_differences(characters_agg)

#print(span_differences_all.keys())
#for span in span_differences_all[(&#39;Why were Jorgenson and Ganti not put to death?&#39;, &#39;Human Consultancy Dishonest&#39;, &#39;Human Consultancy Honest&#39;)]:
#  print(len(quote_length(span)))</code></pre>
<pre class="python"><code>split_span_differences_with_room = []
# Iterate over the span differences
for (question, setting_1, room_1, acc_1, setting_2, room_2, acc_2), (diff_1, diff_2) in span_differences_all.items():
    split_span_differences_with_room.append((question, setting_1, room_1, acc_1, setting_2, room_2, acc_2, diff_1))
    split_span_differences_with_room.append((question, setting_2, room_2, acc_2, setting_1, room_1, acc_1, diff_2))
    
# Convert the list to a DataFrame
split_span_df = pd.DataFrame(split_span_differences_with_room, columns=[&#39;Question&#39;, &#39;Setting 1&#39;, &#39;Room 1&#39;, &#39;Acc_1&#39;, &#39;Setting 2&#39;, &#39;Room 2&#39;, &#39;Acc_2&#39;, &#39;Span Difference&#39;])

split_span_df[&quot;Span Difference Count&quot;] = split_span_df[&quot;Span Difference&quot;].apply(lambda x: len(quote_length(x)))
split_span_df[&quot;Settings&quot;] = split_span_df[&quot;Setting 1&quot;] + &quot; - &quot; + split_span_df[&quot;Setting 2&quot;]


# Group by the new &#39;Settings&#39; column and compute aggregated counts and average of &#39;Span Difference Count&#39;
grouped_data = split_span_df.groupby(&quot;Settings&quot;).agg(
    Count=(&#39;Span Difference Count&#39;, &#39;size&#39;),
    Average_Span_Difference=(&#39;Span Difference Count&#39;, &#39;mean&#39;)
).reset_index()

grouped_data</code></pre>
<pre><code>##                                              Settings  Count  Average_Span_Difference
## 0    AI Consultancy Dishonest - AI Consultancy Honest     12               137.416667
## 1                AI Consultancy Dishonest - AI Debate     12               141.500000
## 2   AI Consultancy Dishonest - Human Consultancy D...     12               169.833333
## 3   AI Consultancy Dishonest - Human Consultancy H...     13                96.384615
## 4             AI Consultancy Dishonest - Human Debate     13               129.153846
## 5    AI Consultancy Honest - AI Consultancy Dishonest     12               202.916667
## 6                   AI Consultancy Honest - AI Debate     12               189.750000
## 7   AI Consultancy Honest - Human Consultancy Dish...     12               211.333333
## 8    AI Consultancy Honest - Human Consultancy Honest     12               177.416667
## 9                AI Consultancy Honest - Human Debate     12               197.833333
## 10               AI Debate - AI Consultancy Dishonest     12                85.083333
## 11                  AI Debate - AI Consultancy Honest     12                65.500000
## 12            AI Debate - Human Consultancy Dishonest     12                94.500000
## 13               AI Debate - Human Consultancy Honest     12                78.000000
## 14                           AI Debate - Human Debate     16                88.062500
## 15  Human Consultancy Dishonest - AI Consultancy D...     12               340.166667
## 16  Human Consultancy Dishonest - AI Consultancy H...     12               315.000000
## 17            Human Consultancy Dishonest - AI Debate     12               404.750000
## 18  Human Consultancy Dishonest - Human Consultanc...     38               334.815789
## 19         Human Consultancy Dishonest - Human Debate     46               300.847826
## 20  Human Consultancy Honest - AI Consultancy Dish...     13               280.692308
## 21   Human Consultancy Honest - AI Consultancy Honest     12               293.333333
## 22               Human Consultancy Honest - AI Debate     12               299.083333
## 23  Human Consultancy Honest - Human Consultancy D...     38               272.763158
## 24            Human Consultancy Honest - Human Debate     42               255.380952
## 25            Human Debate - AI Consultancy Dishonest     13               179.153846
## 26               Human Debate - AI Consultancy Honest     12               201.250000
## 27                           Human Debate - AI Debate     16               188.625000
## 28         Human Debate - Human Consultancy Dishonest     46               163.956522
## 29            Human Debate - Human Consultancy Honest     42               147.880952</code></pre>
<pre class="python"><code>filtered_df = split_span_df[
    (split_span_df[&quot;Setting 1&quot;] == &quot;Human Debate&quot;) &amp;
    ((split_span_df[&quot;Setting 2&quot;] == &quot;Human Consultancy Honest&quot;) | (split_span_df[&quot;Setting 2&quot;] == &quot;Human Consultancy Dishonest&quot;))
]

print(filtered_df.groupby([&#39;Setting 2&#39;,&#39;Acc_1&#39;,&#39;Acc_2&#39;])[&#39;Span Difference Count&#39;].describe())</code></pre>
<pre><code>##                                          count        mean         std    min     25%    50%     75%    max
## Setting 2                   Acc_1 Acc_2                                                                    
## Human Consultancy Dishonest False False    5.0  187.200000   90.698401   92.0  131.00  145.0  275.00  293.0
##                                   True     8.0  149.625000  100.637876   39.0   42.75  156.5  236.25  275.0
##                             True  False   16.0  148.687500   81.308236   47.0   89.75  128.0  182.00  358.0
##                                   True    17.0  178.235294  115.183294   57.0   92.00  161.0  233.00  526.0
## Human Consultancy Honest    False False    4.0  144.750000  134.321443   14.0   36.50  149.0  257.25  267.0
##                                   True    12.0  122.416667   95.625651   30.0   55.50   83.0  164.75  325.0
##                             True  False    4.0  197.000000   63.050245  120.0  170.25  197.5  224.25  273.0
##                                   True    22.0  153.409091   94.780277   30.0   75.00  130.0  195.00  394.0</code></pre>
<pre class="python"><code># Calculate the IQR and bounds for each group in &#39;Setting 2&#39;
grouped = filtered_df.groupby(&#39;Setting 2&#39;)[&#39;Span Difference Count&#39;]

Q1 = grouped.quantile(0.25)
Q3 = grouped.quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers based on the computed bounds
filtered_no_outliers = filtered_df[
    (filtered_df[&#39;Setting 2&#39;].map(lower_bound) &lt;= filtered_df[&#39;Span Difference Count&#39;]) &amp;
    (filtered_df[&#39;Setting 2&#39;].map(upper_bound) &gt;= filtered_df[&#39;Span Difference Count&#39;])
]

filtered_no_outliers</code></pre>
<pre><code>##                                               Question  ...                                    Settings
## 0    By the end of the passage. what can we underst...  ...     Human Debate - Human Consultancy Honest
## 2    By the end of the passage. what can we underst...  ...  Human Debate - Human Consultancy Dishonest
## 30   Did the questions Tremaine needed answers to g...  ...     Human Debate - Human Consultancy Honest
## 32   Did the questions Tremaine needed answers to g...  ...  Human Debate - Human Consultancy Dishonest
## 60   From the information the story provides, do yo...  ...     Human Debate - Human Consultancy Honest
## ..                                                 ...  ...                                         ...
## 510  Why was the main character daydreaming about b...  ...  Human Debate - Human Consultancy Dishonest
## 514            Why was the murderer trying to kill Bo?  ...     Human Debate - Human Consultancy Honest
## 516            Why was the murderer trying to kill Bo?  ...  Human Debate - Human Consultancy Dishonest
## 544     Why were Jorgenson and Ganti not put to death?  ...  Human Debate - Human Consultancy Dishonest
## 546     Why were Jorgenson and Ganti not put to death?  ...     Human Debate - Human Consultancy Honest
## 
## [87 rows x 10 columns]</code></pre>
<pre class="python"><code>print(filtered_no_outliers.groupby([&#39;Setting 2&#39;,&#39;Acc_1&#39;,&#39;Acc_2&#39;])[&#39;Span Difference Count&#39;].describe())</code></pre>
<pre><code>##                                          count        mean         std    min     25%    50%     75%    max
## Setting 2                   Acc_1 Acc_2                                                                    
## Human Consultancy Dishonest False False    5.0  187.200000   90.698401   92.0  131.00  145.0  275.00  293.0
##                                   True     8.0  149.625000  100.637876   39.0   42.75  156.5  236.25  275.0
##                             True  False   16.0  148.687500   81.308236   47.0   89.75  128.0  182.00  358.0
##                                   True    16.0  156.500000   74.733304   57.0   91.25  143.0  220.25  289.0
## Human Consultancy Honest    False False    4.0  144.750000  134.321443   14.0   36.50  149.0  257.25  267.0
##                                   True    12.0  122.416667   95.625651   30.0   55.50   83.0  164.75  325.0
##                             True  False    4.0  197.000000   63.050245  120.0  170.25  197.5  224.25  273.0
##                                   True    22.0  153.409091   94.780277   30.0   75.00  130.0  195.00  394.0</code></pre>
<pre class="r"><code>characters&lt;- py$characters_agg
span_difference_debate_consultancies&lt;-py$filtered_df
ggplot(span_difference_debate_consultancies) +
  geom_boxplot(aes(x = `Setting 2`, y = `Span Difference Count`))</code></pre>
<p><img src="debate-2309_files/figure-html/quote_length%20graph-1.png" width="100%" /></p>
<pre class="r"><code>filtered_outliers &lt;- characters %&gt;%
  group_by(Final_Setting) %&gt;%
  mutate(Q1 = quantile(quote_length, 0.25),
         Q3 = quantile(quote_length, 0.75),
         IQR = Q3 - Q1,
         lower_bound = Q1 - 1.5 * IQR,
         upper_bound = Q3 + 1.5 * IQR)

ggplot(characters) +
  geom_boxplot(aes(x = Final_Setting, y = `Quote length`)) +
  labs(y = &quot;Total Quote Length (characters)&quot;)+
  theme_minimal()</code></pre>
<p><img src="debate-2309_files/figure-html/quote_length%20graph-2.png" width="100%" /></p>
<pre class="r"><code>filtered &lt;- characters %&gt;%
  group_by(Final_Setting) %&gt;%
  mutate(Q1 = quantile(quote_length, 0.25),
         Q3 = quantile(quote_length, 0.75),
         IQR = Q3 - Q1,
         lower_bound = Q1 - 1.5 * IQR,
         upper_bound = Q3 + 1.5 * IQR) %&gt;%
  filter(quote_length &gt; 0 &amp; quote_length &lt; 750) %&gt;%
  select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound) 
filtered %&gt;%
  ggplot() +
  geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
  labs(y = &quot;Total Quote Length in a Debate/Consultancy (unique tokens)&quot;, x = &quot;Setting&quot;)+
  theme_minimal()</code></pre>
<p><img src="debate-2309_files/figure-html/quote_length%20graph-3.png" width="100%" /></p>
<pre class="r"><code>characters %&gt;%
  ggplot() +
  geom_boxplot(aes(x = Final_Setting, y = quote_length)) +
  labs(y = &quot;Total Quote Length in a Debate/Consultancy (unique tokens)&quot;, x = &quot;Setting&quot;)+
  theme_minimal()</code></pre>
<p><img src="debate-2309_files/figure-html/quote_length%20graph-4.png" width="100%" /></p>
<pre class="r"><code>pairwise.t.test(filtered$quote_length, filtered$Final_Setting)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  filtered$quote_length and filtered$Final_Setting 
## 
##                   AI Consultancy AI Debate      Human Consultancy
## AI Debate         0.04290        -              -                
## Human Consultancy 0.00017        0.000000000018 -                
## Human Debate      0.80222        0.00443        0.000000019213   
## 
## P value adjustment method: holm</code></pre>
<pre class="r"><code>filtered %&gt;% group_by(Final_Setting) %&gt;% summarise(avground = median(quote_length))</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Final_Setting"],"name":[1],"type":["chr"],"align":["left"]},{"label":["avground"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"AI Consultancy","2":"160.0"},{"1":"AI Debate","2":"117.5"},{"1":"Human Consultancy","2":"296.0"},{"1":"Human Debate","2":"181.0"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>characters %&gt;% group_by(Final_Setting) %&gt;% summarise(avground = median(quote_length))</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Final_Setting"],"name":[1],"type":["chr"],"align":["left"]},{"label":["avground"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"AI Consultancy","2":"160.0"},{"1":"AI Debate","2":"117.5"},{"1":"Human Consultancy","2":"309.0"},{"1":"Human Debate","2":"181.0"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>characters &lt;- characters %&gt;%
  group_by(`Room name`,) %&gt;%
  mutate(`Max judge rounds by room` = max(`Num previous judging rounds`, na.rm = TRUE)) %&gt;%
  ungroup()
ggplot(characters) +
  geom_boxplot(aes(x = Final_Setting, y = `Max judge rounds by room`)) +
  labs(y = &#39;Max Judging Rounds&#39;) +
  theme_minimal() </code></pre>
<p><img src="debate-2309_files/figure-html/rounds%20graph-1.png" width="100%" /></p>
<pre class="r"><code>pairwise.t.test(characters$`Max judge rounds by room`, characters$Final_Setting)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  characters$`Max judge rounds by room` and characters$Final_Setting 
## 
##                   AI Consultancy AI Debate Human Consultancy
## AI Debate         0.137          -         -                
## Human Consultancy 0.055          0.914     -                
## Human Debate      0.0000003      0.002     0.0000020        
## 
## P value adjustment method: holm</code></pre>
<pre class="r"><code>filtered &lt;- characters %&gt;%
  group_by(Final_Setting) %&gt;%
  mutate(Q1 = quantile(`Max judge rounds by room`, 0.25),
         Q3 = quantile(`Max judge rounds by room`, 0.75),
         IQR = Q3 - Q1,
         lower_bound = Q1 - 1.5 * IQR,
         upper_bound = Q3 + 1.5 * IQR) %&gt;%
  filter(`Max judge rounds by room` &gt;= lower_bound &amp; `Max judge rounds by room` &lt;= upper_bound) %&gt;%
  select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)
filtered %&gt;%
  ggplot() +
  geom_boxplot(aes(x = Final_Setting, y = `Max judge rounds by room`), outlier.shape = NA) +
  labs(y = &quot;Rounds&quot;, x = &quot;Setting&quot;)+
  theme_minimal()</code></pre>
<p><img src="debate-2309_files/figure-html/rounds%20graph-2.png" width="100%" /></p>
<pre class="r"><code>characters %&gt;%
  ggplot() +
  geom_boxplot(aes(x = Final_Setting, y = `Max judge rounds by room`)) +
  labs(y = &quot;Rounds&quot;, x = &quot;Setting&quot;)+
  theme_minimal()</code></pre>
<p><img src="debate-2309_files/figure-html/rounds%20graph-3.png" width="100%" /></p>
<pre class="r"><code>pairwise.t.test(filtered$quote_length, filtered$Final_Setting)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  filtered$quote_length and filtered$Final_Setting 
## 
##                   AI Consultancy   AI Debate        Human Consultancy
## AI Debate         0.192            -                -                
## Human Consultancy 0.00000150627713 0.00000000000097 -                
## Human Debate      0.560            0.018            0.00000000003675 
## 
## P value adjustment method: holm</code></pre>
<pre class="r"><code>filtered %&gt;% group_by(Final_Setting) %&gt;% summarise(avground = mean(`Max judge rounds by room`))</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Final_Setting"],"name":[1],"type":["chr"],"align":["left"]},{"label":["avground"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"AI Consultancy","2":"4.240000"},{"1":"AI Debate","2":"4.066667"},{"1":"Human Consultancy","2":"3.611111"},{"1":"Human Debate","2":"2.522222"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="length-of-debates-stratified" class="section level3"
number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Length of debates,
stratified</h3>
<pre class="python"><code>per_turn = turns.merge(
        debates[[&quot;Room name&quot;, &quot;Honest debater&quot;, &quot;Dishonest debater&quot;, &quot;Question&quot;, &quot;Article ID&quot;,
                 &quot;Speed annotator accuracy&quot;,&quot;Untimed annotator context&quot;,&quot;Untimed annotator context bins&quot;,&quot;Is offline&quot;,&quot;Final_Setting&quot;, &quot;Setting&quot;,&quot;Final_Accuracy&quot;]],
        how=&quot;left&quot;,
        on=&quot;Room name&quot;,
    )

print(per_turn.groupby(&#39;Final_Setting&#39;)[&#39;Num previous judging rounds&#39;].mean())</code></pre>
<pre><code>## Final_Setting
## AI Consultancy       4.173252
## AI Debate            2.986231
## Human Consultancy    2.759310
## Human Debate         1.475072
## Name: Num previous judging rounds, dtype: float64</code></pre>
<pre class="python"><code># Calculate the IQR and bounds for each group in &#39;Setting 2&#39;
grouped = per_turn.groupby(&#39;Setting&#39;)[&#39;Num previous judging rounds&#39;]

Q1 = grouped.quantile(0.25)
Q3 = grouped.quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers based on the computed bounds
filtered_no_outliers = per_turn[
    (per_turn[&#39;Setting&#39;].map(lower_bound) &lt;= per_turn[&#39;Num previous judging rounds&#39;]) &amp;
    (per_turn[&#39;Setting&#39;].map(upper_bound) &gt;= per_turn[&#39;Num previous judging rounds&#39;])
]

filtered_no_outliers</code></pre>
<pre><code>##                            Room name  Room start time  ...                      Setting Final_Accuracy
## 0                         ambition-8    1686950589862  ...  Human Consultancy Dishonest           True
## 1                         ambition-8    1686950589862  ...  Human Consultancy Dishonest           True
## 2                         ambition-8    1686950589862  ...  Human Consultancy Dishonest           True
## 3                         ambition-8    1686950589862  ...  Human Consultancy Dishonest           True
## 4                         ambition-8    1686950589862  ...  Human Consultancy Dishonest           True
## ...                              ...              ...  ...                          ...            ...
## 6013                   break-a-leg-3    1682110823449  ...                 Human Debate           True
## 6014                   break-a-leg-3    1682110823449  ...                 Human Debate           True
## 6015  the-absurdity-of-family-love-2    1689876267578  ...     Human Consultancy Honest           True
## 6016  the-absurdity-of-family-love-2    1689876267578  ...     Human Consultancy Honest           True
## 6017  the-absurdity-of-family-love-2    1689876267578  ...     Human Consultancy Honest           True
## 
## [5875 rows x 27 columns]</code></pre>
<pre class="python"><code>for setting in filtered_no_outliers[&#39;Setting&#39;].unique():
  per_turn_setting = filtered_no_outliers[filtered_no_outliers[&#39;Setting&#39;]==setting]
  print(setting)
  # Calculate the maximum &#39;Num previous judging rounds&#39; for each combination of &#39;Room name&#39; and &#39;Participant&#39;
  per_turn_setting[&#39;Max judge rounds by room&#39;] = per_turn_setting.groupby([&#39;Room name&#39;, &#39;Participant&#39;])[&#39;Num previous judging rounds&#39;].transform(&#39;max&#39;)
  ## Just based on the number of rounds
  
  for i in range(1, per_turn_setting[&#39;Max judge rounds by room&#39;].max() + 1):
      max_rounds = per_turn_setting[(per_turn_setting[&#39;Max judge rounds by room&#39;] == i) &amp; (per_turn_setting[&#39;Untimed annotator context&#39;] &gt; 0)]
      print(len(max_rounds))
      # Group by &#39;Num previous judging rounds&#39; and calculate the mean of &#39;Probability correct&#39;
      average_pc_per_round = max_rounds.groupby(&#39;Num previous judging rounds&#39;)[&#39;Probability correct&#39;].mean()
  
      # Create a new DataFrame with &#39;Num previous judging rounds&#39; and &#39;Average pc per round&#39;
      probability_correct_round = pd.DataFrame({&#39;Num previous judging rounds&#39;: average_pc_per_round.index,
                                                &#39;Average pc per round&#39;: average_pc_per_round.values})
  
      # Plotting the data with label for the line
      plt.plot(probability_correct_round[&#39;Num previous judging rounds&#39;], probability_correct_round[&#39;Average pc per round&#39;], label=f&quot;Max Rounds: {i}&quot;)
  
  plt.title(f&quot;Probability Correct for Setting: {setting}&quot;) 
  plt.xlabel(&#39;Num previous judging rounds&#39;)
  plt.ylabel(&#39;Average pc per round&#39;)
  plt.legend()
  plt.show()</code></pre>
<p><img src="debate-2309_files/figure-html/strat-1.png" width="100%" /><img src="debate-2309_files/figure-html/strat-2.png" width="100%" /><img src="debate-2309_files/figure-html/strat-3.png" width="100%" /><img src="debate-2309_files/figure-html/strat-4.png" width="100%" /><img src="debate-2309_files/figure-html/strat-5.png" width="100%" /><img src="debate-2309_files/figure-html/strat-6.png" width="100%" /></p>
<pre class="r"><code>strat &lt;- py$per_turn
strat &lt;- strat %&gt;%
  group_by(`Room name`, Participant) %&gt;%
  mutate(`Max judge rounds by room` = max(`Num previous judging rounds`, na.rm = TRUE)) %&gt;%
  ungroup()
strat &lt;- strat %&gt;%
  mutate(`Max judge rounds bin` = cut(`Max judge rounds by room`, 
                                      breaks = seq(0, max(`Max judge rounds by room`, na.rm = TRUE) + 3, by = 3), 
                                      labels = FALSE, 
                                      include.lowest = TRUE, 
                                      right = FALSE))

# Plot using ggplot2
strat %&gt;%
  group_by(Setting, `Num previous judging rounds`, `Max judge rounds bin`) %&gt;%
  summarize(
    `Average Probability Correct` = mean(`Probability correct`, na.rm = TRUE),
    n = n(),
    se = sqrt(`Average Probability Correct` * (1 - `Average Probability Correct`) / n)
  ) %&gt;%
  mutate(
    lower_ci = `Average Probability Correct` - 1.96 * se,
    upper_ci = `Average Probability Correct` + 1.96 * se
  ) %&gt;%
  ggplot(aes(x = `Num previous judging rounds`, y = `Average Probability Correct`, col = as.factor(`Max judge rounds bin`))) +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = as.factor(`Max judge rounds bin`), group = as.factor(`Max judge rounds bin`), color = NULL), alpha = 0.15) +
  labs(title = &quot;Average Probability Correct Each Round, \nstratified by Max Round Binned&quot;,
       x = &quot;Round&quot;, 
       y = &quot;Average Intermediate Probability Correct&quot;) +
  geom_line() +
  facet_wrap(~Setting) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;Setting&#39;, &#39;Num previous judging rounds&#39;. You can override using the `.groups`
## argument.</code></pre>
<p><img src="debate-2309_files/figure-html/strat%20ggplot-13.png" width="2100" /></p>
<pre class="r"><code>strat %&gt;%
  group_by(Setting, `Num previous judging rounds`, `Max judge rounds by room`) %&gt;%
  summarize(`Average Probability Correct` = mean(`Probability correct`, na.rm = TRUE)) %&gt;%
  mutate(Completion = `Num previous judging rounds` / `Max judge rounds by room`) %&gt;%
  ggplot(aes(x = Completion, y = `Average Probability Correct`, col = as.factor(`Max judge rounds by room`), group = as.factor(`Max judge rounds by room`))) +
  geom_line() +
  labs(title = &quot;Average Probability Correct by Percentage of Completion&quot;,
       x = &quot;Percentage of Completion&quot;, 
       y = &quot;Average Probability Correct&quot;) +
  facet_wrap(~Setting) +
  theme_minimal() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;Setting&#39;, &#39;Num previous judging rounds&#39;. You can override using the `.groups`
## argument.</code></pre>
<pre><code>## Warning: Removed 10 rows containing missing values (`geom_line()`).</code></pre>
<p><img src="debate-2309_files/figure-html/strat%20ggplot-14.png" width="2100" /></p>
</div>
<div id="time-offline-judging.." class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Time (offline
judging..?)</h3>
<pre class="python"><code># Convert to datetime
judgments[&quot;Offline judging start time&quot;] = pd.to_datetime(judgments[&quot;Offline judging start time&quot;], unit=&quot;ms&quot;)
judgments[&quot;Offline judging end time&quot;] = pd.to_datetime(judgments[&quot;Offline judging end time&quot;], unit=&quot;ms&quot;)

# Calculate offline judging time in minutes
judgments[&quot;Offline judging time&quot;] = (judgments[&quot;Offline judging end time&quot;] - judgments[&quot;Offline judging start time&quot;]).dt.total_seconds() / 60


print(f&quot;Number of offline judgments on consultancies:\n{judgments[judgments[&#39;Setting&#39;].str.contains(&#39;Consultancy&#39;)][&#39;Offline judging time&#39;].dropna().describe()}\nOnly 13...&quot;)</code></pre>
<pre><code>## Number of offline judgments on consultancies:
## count      13.000000
## mean      447.514203
## std      1236.792144
## min         1.169167
## 25%         1.836600
## 50%         5.664767
## 75%        13.967783
## max      4369.697933
## Name: Offline judging time, dtype: float64
## Only 13...</code></pre>
<pre class="python"><code># Filter out rows with NaT values
valid_judging_time = judgments[&quot;Offline judging time&quot;].dropna()

# Calculate summary statistics
summary_stats = valid_judging_time.describe()
print(summary_stats)</code></pre>
<pre><code>## count      203.000000
## mean       255.826710
## std       1372.208730
## min          0.667467
## 25%          2.867950
## 50%          5.176250
## 75%         10.295583
## max      14202.493917
## Name: Offline judging time, dtype: float64</code></pre>
<pre class="python"><code># Filter judgments with offline judging time above 65 minutes
filtered_judgments = judgments[(judgments[&quot;Offline judging time&quot;] &lt; 65) &amp; (judgments[&quot;Untimed annotator context&quot;] &gt; 0)]

# Print filtered judgments
# print(&quot;Filtered judgments with offline judging time above 65 minutes:&quot;)
print(filtered_judgments[&#39;Offline judging time&#39;].describe())</code></pre>
<pre><code>## count    193.000000
## mean       8.013787
## std        9.410150
## min        0.667467
## 25%        2.850450
## 50%        5.107450
## 75%        8.716300
## max       64.173267
## Name: Offline judging time, dtype: float64</code></pre>
<pre class="python"><code># Create the histogram
plt.hist(filtered_judgments[&#39;Offline judging time&#39;], bins=10)

# Set labels and title
plt.xlabel(&quot;Offline Judging Time (minutes)&quot;)
plt.ylabel(&quot;Frequency&quot;)
plt.title(&quot;Histogram of Offline Judging Time&quot;)

# Display the histogram
plt.show()</code></pre>
<p><img src="debate-2309_files/figure-html/TODO%20offline%20judging-1.png" width="672" /></p>
<pre class="python"><code>
aggregates = {
    &#39;Final probability correct&#39;: &#39;mean&#39;,
    &#39;Untimed annotator context&#39;: &#39;mean&#39;
}
filtered_judgments = filtered_judgments.groupby(&#39;Offline judging time&#39;).agg(aggregates).reset_index()
</code></pre>
</div>
</div>
</div>
<div id="analysis" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Analysis</h1>
<div id="question-difficulty" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Question
Difficulty</h2>
<p>confounder rounds, quotes</p>
<pre class="python"><code>judgments[&quot;Number of judge continues bins&quot;] = pd.cut(
    judgments[&quot;Number of judge continues&quot;], 
    bins=[0, 3, 6, 9, float(&#39;inf&#39;)],  # bin edges
    labels=[&#39;1-3&#39;, &#39;4-6&#39;, &#39;7-9&#39;, &#39;10+&#39;],  # labels for the resulting bins
    right=True  # includes the right edge of the bin
)
aggregated_df = judgments.groupby([&quot;Setting&quot;, &quot;Number of judge continues bins&quot;])[&quot;Final_Accuracy&quot;].agg(
    Proportion_True=lambda x: x.mean(),
    Total_Count=&quot;size&quot;
).reset_index()</code></pre>
<pre><code>## &lt;string&gt;:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.</code></pre>
<pre class="python"><code>pd.set_option(&#39;display.max_columns&#39;, None)
print(aggregated_df)</code></pre>
<pre><code>##                         Setting Number of judge continues bins  \
## 0      AI Consultancy Dishonest                            1-3   
## 1      AI Consultancy Dishonest                            4-6   
## 2      AI Consultancy Dishonest                            7-9   
## 3      AI Consultancy Dishonest                            10+   
## 4         AI Consultancy Honest                            1-3   
## 5         AI Consultancy Honest                            4-6   
## 6         AI Consultancy Honest                            7-9   
## 7         AI Consultancy Honest                            10+   
## 8                     AI Debate                            1-3   
## 9                     AI Debate                            4-6   
## 10                    AI Debate                            7-9   
## 11                    AI Debate                            10+   
## 12  Human Consultancy Dishonest                            1-3   
## 13  Human Consultancy Dishonest                            4-6   
## 14  Human Consultancy Dishonest                            7-9   
## 15  Human Consultancy Dishonest                            10+   
## 16     Human Consultancy Honest                            1-3   
## 17     Human Consultancy Honest                            4-6   
## 18     Human Consultancy Honest                            7-9   
## 19     Human Consultancy Honest                            10+   
## 20                 Human Debate                            1-3   
## 21                 Human Debate                            4-6   
## 22                 Human Debate                            7-9   
## 23                 Human Debate                            10+   
## 
##     Proportion_True  Total_Count  
## 0          0.962963           27  
## 1          0.833333            6  
## 2          1.000000            2  
## 3          0.400000            5  
## 4          0.740741           27  
## 5          0.777778           18  
## 6          1.000000            3  
## 7          0.625000            8  
## 8          0.843137           51  
## 9          0.740741           27  
## 10         0.700000           10  
## 11         0.500000            4  
## 12         0.483871           31  
## 13         0.655172           29  
## 14         0.833333            6  
## 15         0.500000            2  
## 16         0.928571           28  
## 17         0.833333           18  
## 18         1.000000            5  
## 19         0.500000            2  
## 20         0.871069          318  
## 21         0.859649           57  
## 22         1.000000            1  
## 23              NaN            0</code></pre>
<pre class="python"><code>pd.reset_option(&#39;display.max_columns&#39;)

total_counts_for_setting = judgments.groupby(&#39;Final_Setting&#39;).size()
result = judgments.groupby([&quot;Final_Setting&quot;, &quot;Untimed annotator context bins&quot;, &quot;Number of judge continues bins&quot;]).agg(
    Proportion_True=pd.NamedAgg(column=&#39;Final_Accuracy&#39;, aggfunc=lambda x: x.mean()),
    Context_Count=pd.NamedAgg(column=&#39;Final_Accuracy&#39;, aggfunc=&#39;size&#39;),
    Proportion_Context=pd.NamedAgg(column=&#39;Final_Setting&#39;, aggfunc=lambda x: len(x) / total_counts_for_setting[x.mode()])
).reset_index()</code></pre>
<pre><code>## &lt;string&gt;:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.</code></pre>
<pre class="python"><code>print(f&#39;Is it number of rounds (meaning more evidence) that confounds the consultancy accuracy?:\n{result}&#39;)</code></pre>
<pre><code>## Is it number of rounds (meaning more evidence) that confounds the consultancy accuracy?:
##      Final_Setting Untimed annotator context bins  ... Context_Count  Proportion_Context
## 0   AI Consultancy                              1  ...             0                 NaN
## 1   AI Consultancy                              1  ...             1            0.010417
## 2   AI Consultancy                              1  ...             0                 NaN
## 3   AI Consultancy                              1  ...             0                 NaN
## 4   AI Consultancy                              2  ...            28            0.291667
## ..             ...                            ...  ...           ...                 ...
## 59    Human Debate                              3  ...             0                 NaN
## 60    Human Debate                              4  ...            29            0.076923
## 61    Human Debate                              4  ...             7            0.018568
## 62    Human Debate                              4  ...             0                 NaN
## 63    Human Debate                              4  ...             0                 NaN
## 
## [64 rows x 6 columns]</code></pre>
<pre class="r"><code>judgments$`Untimed annotator context bins` &lt;- as.factor(judgments$`Untimed annotator context bins`)

bootstrap_mean &lt;- function(data, indices) {
  return(mean(data[indices], na.rm = TRUE))
}

judgments_online %&gt;%
  group_by(`Untimed annotator context bins`, Final_Setting) %&gt;%
  do({
    boot_result &lt;- boot(data = .$Final_Accuracy, statistic = bootstrap_mean, R = 1000)
    data.frame(
      mean_accuracy = mean(boot_result$t, na.rm = TRUE),
      lower_ci = quantile(boot_result$t, 0.025),
      upper_ci = quantile(boot_result$t, 0.975)
    )
  }) %&gt;%
  ggplot(aes(x = `Untimed annotator context bins`, y = mean_accuracy, color = Final_Setting, group = Final_Setting)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = Final_Setting, color = NULL), alpha = 0.25) +
  labs(y = &quot;Average Final Accuracy&quot;, x = &quot;Untimed Annotator Context&quot;) +
  theme_minimal() +
  facet_wrap(~ Final_Setting)</code></pre>
<p><img src="debate-2309_files/figure-html/Accuracy%20by%20Context%20Graph-3.png" width="100%" /></p>
</div>
<div id="judge-skill" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Judge Skill</h2>
<div id="judge-experience" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Judge
“Experience”</h3>
<pre class="r"><code>judgments_online %&gt;% 
  group_by(Final_Setting, Participant) %&gt;%
  arrange(`End time`) %&gt;%
  mutate(count=row_number()) %&gt;% 
  group_by(Final_Setting, count) %&gt;%
  do({
    boot_result &lt;- boot(data = .$Final_Accuracy, statistic = bootstrap_mean, R = 1000)
    data.frame(
      mean_accuracy = mean(boot_result$t, na.rm = TRUE),
      lower_ci = quantile(boot_result$t, 0.025, na.rm = TRUE),
      upper_ci = quantile(boot_result$t, 0.975, na.rm = TRUE)
    )
  }) %&gt;%
  ggplot(aes(x = count, y = mean_accuracy, color = Final_Setting, group = Final_Setting)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = Final_Setting, color = NULL), alpha = 0.25) +
  labs(y = &quot;Average Final Accuracy&quot;, x = &quot;Judging Counts&quot;) +
  theme_minimal() +
  facet_wrap(~ Final_Setting)</code></pre>
<p><img src="debate-2309_files/figure-html/unnamed-chunk-2-1.png" width="100%" /></p>
<pre class="r"><code>subset(judgments_online, judgments_online[&#39;Setting&#39;] == &#39;Human Debate&#39;) %&gt;% 
  group_by(`Untimed annotator context bins`, Participant) %&gt;%
  arrange(`End time`) %&gt;%
  mutate(count=row_number()) %&gt;% 
  group_by(`Untimed annotator context bins`, count) %&gt;%
  do({
    boot_result &lt;- boot(data = .$Final_Accuracy, statistic = bootstrap_mean, R = 1000)
    data.frame(
      mean_accuracy = mean(boot_result$t, na.rm = TRUE),
      lower_ci = quantile(boot_result$t, 0.025, na.rm = TRUE),
      upper_ci = quantile(boot_result$t, 0.975, na.rm = TRUE)
    )
  }) %&gt;%
  ggplot(aes(x = count, y = mean_accuracy, color = `Untimed annotator context bins`, group = `Untimed annotator context bins`)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = `Untimed annotator context bins`, color = NULL), alpha = 0.25) +
  labs(y = &quot;Average Final Accuracy&quot;, x = &quot;Judging Counts&quot;) +
  theme_minimal() +
  facet_wrap(~ `Untimed annotator context bins`)</code></pre>
<p><img src="debate-2309_files/figure-html/unnamed-chunk-2-2.png" width="100%" /></p>
</div>
<div id="calibration" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Calibration</h3>
<p>S: (1) debaters didnt learn calibration -&gt; calibration over time?
S: (2) dishonest debater tricks</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.calibration import calibration_curve

def calibration_plot(df, setting_name, ax=None):
    df[&#39;outcome&#39;] = pd.Series(df[&#39;Final probability correct&#39;] &gt; 0.5, dtype=int)
    df[&#39;confidence&#39;] = df[&#39;Final probability correct&#39;].apply(lambda x: x if x &gt; 0.5 else 1 - x)
    df[&#39;bins&#39;] = pd.cut(df[&#39;confidence&#39;], [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99])
    # Group by bins and calculate the mean outcome
    df_grouped = df.groupby(&#39;bins&#39;)[&#39;outcome&#39;].mean().reset_index()
    # Compute standard error in each bin
    std_error = df.groupby(&#39;bins&#39;)[&#39;outcome&#39;].apply(lambda x: x.std() / np.sqrt(len(x)) if len(x) &gt; 1 else 0)
    df_grouped[&#39;std_error&#39;] = df[&#39;bins&#39;].cat.categories.map(std_error)
    if ax is None:
        plt.rcParams.update({&#39;font.size&#39;: 16})
        fig, ax = plt.subplots(figsize=(8, 6))
    # Plot the calibration curve with error bars
    ax.plot(df_grouped[&#39;bins&#39;].apply(lambda x: x.mid), df_grouped[&#39;outcome&#39;], marker=&#39;o&#39;, linewidth=2, label=&#39;Calibration Curve&#39;)
    ax.errorbar(df_grouped[&#39;bins&#39;].apply(lambda x: x.mid), df_grouped[&#39;outcome&#39;], yerr=df_grouped[&#39;std_error&#39;], fmt=&#39;o&#39;, capsize=5, linewidth=2, label=&#39;Error Bars&#39;)
    ax.set_xlabel(&#39;Final judge probability&#39;)
    ax.set_ylabel(&#39;Accuracy&#39;)
    ax.set_title(f&#39;Judge calibration for {setting_name}&#39;)
    ax.plot([0.5, 1], [0.5, 1], linestyle=&#39;--&#39;, color=&#39;gray&#39;, label=&#39;Perfect Calibration&#39;)
    ax.grid(True)
    ax.legend()
    # Calculate ECE
    actual_labels = df[&#39;outcome&#39;].values
    predicted_probs = df[&#39;Final probability correct&#39;].values
    prob_true, prob_pred = calibration_curve(actual_labels, predicted_probs, n_bins=10)
    ece = np.mean(np.abs(prob_pred - prob_true) * (prob_true.size / len(actual_labels)))
    # Print ECE
    print(f&quot;Expected Calibration Error (ECE) for {setting_name}: {ece:.4f}&quot;)
    plt.show()
    plt.rcParams.update({&#39;font.size&#39;: plt.rcParamsDefault[&#39;font.size&#39;]})

# Loop through each unique setting and create a calibration plot
for setting in judgments_online[&#39;Final_Setting&#39;].unique():
    setting_df = judgments_online[judgments[&#39;Final_Setting&#39;] == setting].copy()
    calibration_plot(setting_df, setting)</code></pre>
<pre><code>## Expected Calibration Error (ECE) for AI Consultancy: 0.0213
## Expected Calibration Error (ECE) for Human Debate: 0.0152
## Expected Calibration Error (ECE) for AI Debate: 0.0268
## Expected Calibration Error (ECE) for Human Consultancy: 0.0220
## 
## &lt;string&gt;:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
## &lt;string&gt;:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
## &lt;string&gt;:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
## &lt;string&gt;:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
## &lt;string&gt;:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
## &lt;string&gt;:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
## &lt;string&gt;:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
## &lt;string&gt;:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
## &lt;string&gt;:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
## &lt;string&gt;:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
## &lt;string&gt;:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
## &lt;string&gt;:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.</code></pre>
<p><img src="debate-2309_files/figure-html/calibration-1.png" width="100%" /><img src="debate-2309_files/figure-html/calibration-2.png" width="100%" /><img src="debate-2309_files/figure-html/calibration-3.png" width="100%" /><img src="debate-2309_files/figure-html/calibration-4.png" width="100%" /></p>
</div>
<div id="judge-involvement" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Judge
Involvement</h3>
</div>
<div id="judge-mistakes" class="section level3" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Judge Mistakes</h3>
</div>
</div>
<div id="debater-skill" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Debater Skill</h2>
<pre class="r"><code>random.intercept.model = lmer(`Final probability correct` ~  (1|Final_Setting), 
                              data = judgments, REML = TRUE)

judgments$random.intercept.preds = predict(random.intercept.model)

colnames(judgments)</code></pre>
<pre><code>##  [1] &quot;Participant&quot;                            
##  [2] &quot;base_room_name&quot;                         
##  [3] &quot;Room name&quot;                              
##  [4] &quot;Room start time&quot;                        
##  [5] &quot;Role&quot;                                   
##  [6] &quot;Is turn&quot;                                
##  [7] &quot;Is over&quot;                                
##  [8] &quot;Number of judge continues&quot;              
##  [9] &quot;Final probability correct&quot;              
## [10] &quot;Offline judging start time&quot;             
## [11] &quot;Offline judging end time&quot;               
## [12] &quot;other&quot;                                  
## [13] &quot;factual informativeness (comparative).1&quot;
## [14] &quot;factual informativeness (comparative).2&quot;
## [15] &quot;facts versus semantics (single)&quot;        
## [16] &quot;factual accuracy (single)&quot;              
## [17] &quot;clarity.1&quot;                              
## [18] &quot;clarity.2&quot;                              
## [19] &quot;factual accuracy.1&quot;                     
## [20] &quot;factual accuracy.2&quot;                     
## [21] &quot;judge reasoning&quot;                        
## [22] &quot;reason for outcome&quot;                     
## [23] &quot;protocol&quot;                               
## [24] &quot;evidence use.1&quot;                         
## [25] &quot;evidence use.2&quot;                         
## [26] &quot;evidence in story.1&quot;                    
## [27] &quot;evidence in story.2&quot;                    
## [28] &quot;other factors&quot;                          
## [29] &quot;judge adaptation (single)&quot;              
## [30] &quot;evidence in debate.1&quot;                   
## [31] &quot;evidence in debate.2&quot;                   
## [32] &quot;interface&quot;                              
## [33] &quot;evidence in debate (single)&quot;            
## [34] &quot;facts versus semantics.1&quot;               
## [35] &quot;facts versus semantics.2&quot;               
## [36] &quot;clash.1&quot;                                
## [37] &quot;clash.2&quot;                                
## [38] &quot;identity guesses.Judge&quot;                 
## [39] &quot;identity guesses.Debater A&quot;             
## [40] &quot;identity guesses.Debater B&quot;             
## [41] &quot;judge adaptation.1&quot;                     
## [42] &quot;judge adaptation.2&quot;                     
## [43] &quot;subjective correctness&quot;                 
## [44] &quot;evidence use (single)&quot;                  
## [45] &quot;factual informativeness (total)&quot;        
## [46] &quot;judge strategies&quot;                       
## [47] &quot;clarity (single)&quot;                       
## [48] &quot;Debater A&quot;                              
## [49] &quot;Debater B&quot;                              
## [50] &quot;Honest debater&quot;                         
## [51] &quot;Dishonest debater&quot;                      
## [52] &quot;Is single debater&quot;                      
## [53] &quot;Has honest debater&quot;                     
## [54] &quot;Final_Setting&quot;                          
## [55] &quot;Setting&quot;                                
## [56] &quot;Question&quot;                               
## [57] &quot;Article ID&quot;                             
## [58] &quot;Speed annotator accuracy bins&quot;          
## [59] &quot;Untimed annotator context bins&quot;         
## [60] &quot;Speed annotator accuracy&quot;               
## [61] &quot;Untimed annotator context&quot;              
## [62] &quot;Is offline&quot;                             
## [63] &quot;End time&quot;                               
## [64] &quot;Last modified time&quot;                     
## [65] &quot;Final_Accuracy&quot;                         
## [66] &quot;random.intercept.preds&quot;</code></pre>
<pre class="r"><code>dishonest &lt;- judgments[!is.na(judgments$`Dishonest debater`), ]
model3 &lt;- glm(Final_Accuracy ~ relevel(factor(`Dishonest debater`), &#39;Shlomo Kofman&#39;) + relevel(factor(Final_Setting), &#39;Human Debate&#39;), family = &#39;binomial&#39;, data = judgments[!is.na(judgments$`Dishonest debater`), ])
summary(model3)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Final_Accuracy ~ relevel(factor(`Dishonest debater`), 
##     &quot;Shlomo Kofman&quot;) + relevel(factor(Final_Setting), &quot;Human Debate&quot;), 
##     family = &quot;binomial&quot;, data = judgments[!is.na(judgments$`Dishonest debater`), 
##         ])
## 
## Coefficients: (1 not defined because of singularities)
##                                                                           Estimate
## (Intercept)                                                                0.52739
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Adelle Fernando       0.95584
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Aliyaah Toussaint     2.41514
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Anuj Jain             1.47707
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)David Rein            1.41852
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Emmanuel Makinde     17.03868
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Ethan Rosen           1.45361
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)GPT-4                 0.75355
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jackson Petty         2.08187
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jessica Li            0.53268
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julian Michael        2.41705
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julien Dirani         1.55205
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Max Layden           17.03868
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Noor Mirza-Rashid    -0.05738
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Reeya Kansra          1.44916
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Salsabila Mahdi       1.47874
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sam Jin               1.30012
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sean Wang             1.43988
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Shreeram Modi         1.45605
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Vishakh Padmakumar   17.03868
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy               0.66498
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                         NA
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy           -1.33091
##                                                                         Std. Error
## (Intercept)                                                                0.66115
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Adelle Fernando       0.73718
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Aliyaah Toussaint     1.23691
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Anuj Jain             0.84884
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)David Rein            0.90447
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Emmanuel Makinde   2797.44202
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Ethan Rosen           0.84947
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)GPT-4                 0.70782
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jackson Petty         0.98698
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jessica Li            0.74081
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julian Michael        1.22055
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julien Dirani         1.24985
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Max Layden         3956.18038
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Noor Mirza-Rashid     0.87300
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Reeya Kansra          0.90748
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Salsabila Mahdi       0.79085
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sam Jin               0.93690
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sean Wang             0.75579
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Shreeram Modi         0.75586
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Vishakh Padmakumar  863.30958
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy               0.54080
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                         NA
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy            0.32388
##                                                                         z value
## (Intercept)                                                               0.798
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Adelle Fernando      1.297
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Aliyaah Toussaint    1.953
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Anuj Jain            1.740
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)David Rein           1.568
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Emmanuel Makinde     0.006
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Ethan Rosen          1.711
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)GPT-4                1.065
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jackson Petty        2.109
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jessica Li           0.719
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julian Michael       1.980
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julien Dirani        1.242
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Max Layden           0.004
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Noor Mirza-Rashid   -0.066
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Reeya Kansra         1.597
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Salsabila Mahdi      1.870
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sam Jin              1.388
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sean Wang            1.905
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Shreeram Modi        1.926
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Vishakh Padmakumar   0.020
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy              1.230
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                      NA
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy          -4.109
##                                                                          Pr(&gt;|z|)
## (Intercept)                                                                0.4251
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Adelle Fernando       0.1948
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Aliyaah Toussaint     0.0509
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Anuj Jain             0.0818
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)David Rein            0.1168
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Emmanuel Makinde      0.9951
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Ethan Rosen           0.0870
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)GPT-4                 0.2871
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jackson Petty         0.0349
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jessica Li            0.4721
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julian Michael        0.0477
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julien Dirani         0.2143
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Max Layden            0.9966
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Noor Mirza-Rashid     0.9476
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Reeya Kansra          0.1103
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Salsabila Mahdi       0.0615
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sam Jin               0.1652
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sean Wang             0.0568
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Shreeram Modi         0.0541
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Vishakh Padmakumar    0.9843
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy               0.2188
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                        NA
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy         0.0000397
##                                                                            
## (Intercept)                                                                
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Adelle Fernando       
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Aliyaah Toussaint  .  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Anuj Jain          .  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)David Rein            
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Emmanuel Makinde      
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Ethan Rosen        .  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)GPT-4                 
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jackson Petty      *  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Jessica Li            
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julian Michael     *  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Julien Dirani         
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Max Layden            
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Noor Mirza-Rashid     
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Reeya Kansra          
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Salsabila Mahdi    .  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sam Jin               
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Sean Wang          .  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Shreeram Modi      .  
## relevel(factor(`Dishonest debater`), &quot;Shlomo Kofman&quot;)Vishakh Padmakumar    
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Consultancy               
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)AI Debate                    
## relevel(factor(Final_Setting), &quot;Human Debate&quot;)Human Consultancy         ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 541.37  on 576  degrees of freedom
## Residual deviance: 487.85  on 555  degrees of freedom
## AIC: 531.85
## 
## Number of Fisher Scoring iterations: 16</code></pre>
<pre class="r"><code>result &lt;- judgments_online %&gt;%
  group_by(`Dishonest debater`) %&gt;%
  summarize(
    Win_Rate = sum(Final_Accuracy == &quot;FALSE&quot;) / n()
  ) %&gt;%
  ungroup() %&gt;%
  arrange(desc(Win_Rate))

result</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Dishonest debater"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Win_Rate"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"Shlomo Kofman","2":"0.54545455"},{"1":"Salsabila Mahdi","2":"0.35714286"},{"1":"Jessica Li","2":"0.35294118"},{"1":"Noor Mirza-Rashid","2":"0.33333333"},{"1":"Adelle Fernando","2":"0.29629630"},{"1":"Sean Wang","2":"0.28000000"},{"1":"Reeya Kansra","2":"0.27272727"},{"1":"Sam Jin","2":"0.25000000"},{"1":"Shreeram Modi","2":"0.24000000"},{"1":"GPT-4","2":"0.19200000"},{"1":"NA","2":"0.18446602"},{"1":"Anuj Jain","2":"0.14285714"},{"1":"Julian Michael","2":"0.12500000"},{"1":"Aliyaah Toussaint","2":"0.11111111"},{"1":"Ethan Rosen","2":"0.09090909"},{"1":"Jackson Petty","2":"0.07692308"},{"1":"David Rein","2":"0.00000000"},{"1":"Julien Dirani","2":"0.00000000"},{"1":"Max Layden","2":"0.00000000"},{"1":"Vishakh Padmakumar","2":"0.00000000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>result1 &lt;- judgments_online %&gt;%
  group_by(`Honest debater`) %&gt;%
  summarize(
    Win_Rate = sum(Final_Accuracy == &quot;TRUE&quot;) / n()
  ) %&gt;%
  ungroup() %&gt;%
  arrange(desc(Win_Rate))

result1</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Honest debater"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Win_Rate"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"Julian Michael","2":"1.0000000"},{"1":"Julien Dirani","2":"1.0000000"},{"1":"Noor Mirza-Rashid","2":"1.0000000"},{"1":"Sean Wang","2":"0.9600000"},{"1":"Jessica Li","2":"0.9230769"},{"1":"Salsabila Mahdi","2":"0.9166667"},{"1":"Adelle Fernando","2":"0.9047619"},{"1":"Reeya Kansra","2":"0.9000000"},{"1":"Vishakh Padmakumar","2":"0.8571429"},{"1":"Shlomo Kofman","2":"0.8333333"},{"1":"Anuj Jain","2":"0.8000000"},{"1":"David Rein","2":"0.8000000"},{"1":"Shreeram Modi","2":"0.8000000"},{"1":"Ethan Rosen","2":"0.7857143"},{"1":"GPT-4","2":"0.7746479"},{"1":"NA","2":"0.6804124"},{"1":"Jackson Petty","2":"0.6666667"},{"1":"Sam Jin","2":"0.6666667"},{"1":"Aliyaah Toussaint","2":"0.6250000"},{"1":"Emmanuel Makinde","2":"0.0000000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code># Filter for high win rate debaters
high_win_rate_debaters &lt;- result1 %&gt;%
  filter(Win_Rate &gt; 0.90)  # Set the threshold for high win rate

# Filter original data for debates with &#39;Debate&#39; in Final_Setting
filtered_data &lt;- judgments_online %&gt;%
  filter(grepl(&quot;Debate&quot;, Final_Setting)) 

# Find cases where high win rate debaters lost
cases_high_win_rate_lost &lt;- filtered_data %&gt;%
  filter(`Honest debater` %in% high_win_rate_debaters$`Honest debater` &amp; Final_Accuracy != &quot;TRUE&quot;)

cases_high_win_rate_lost</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Participant"],"name":[1],"type":["fct"],"align":["left"]},{"label":["base_room_name"],"name":[2],"type":["chr"],"align":["left"]},{"label":["Room name"],"name":[3],"type":["chr"],"align":["left"]},{"label":["Room start time"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Role"],"name":[5],"type":["chr"],"align":["left"]},{"label":["Is turn"],"name":[6],"type":["lgl"],"align":["right"]},{"label":["Is over"],"name":[7],"type":["lgl"],"align":["right"]},{"label":["Number of judge continues"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["Final probability correct"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["Offline judging start time"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["Offline judging end time"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["other"],"name":[12],"type":["chr"],"align":["left"]},{"label":["factual informativeness (comparative).1"],"name":[13],"type":["dbl"],"align":["right"]},{"label":["factual informativeness (comparative).2"],"name":[14],"type":["dbl"],"align":["right"]},{"label":["facts versus semantics (single)"],"name":[15],"type":["dbl"],"align":["right"]},{"label":["factual accuracy (single)"],"name":[16],"type":["dbl"],"align":["right"]},{"label":["clarity.1"],"name":[17],"type":["dbl"],"align":["right"]},{"label":["clarity.2"],"name":[18],"type":["dbl"],"align":["right"]},{"label":["factual accuracy.1"],"name":[19],"type":["dbl"],"align":["right"]},{"label":["factual accuracy.2"],"name":[20],"type":["dbl"],"align":["right"]},{"label":["judge reasoning"],"name":[21],"type":["dbl"],"align":["right"]},{"label":["reason for outcome"],"name":[22],"type":["chr"],"align":["left"]},{"label":["protocol"],"name":[23],"type":["chr"],"align":["left"]},{"label":["evidence use.1"],"name":[24],"type":["dbl"],"align":["right"]},{"label":["evidence use.2"],"name":[25],"type":["dbl"],"align":["right"]},{"label":["evidence in story.1"],"name":[26],"type":["dbl"],"align":["right"]},{"label":["evidence in story.2"],"name":[27],"type":["dbl"],"align":["right"]},{"label":["other factors"],"name":[28],"type":["chr"],"align":["left"]},{"label":["judge adaptation (single)"],"name":[29],"type":["dbl"],"align":["right"]},{"label":["evidence in debate.1"],"name":[30],"type":["dbl"],"align":["right"]},{"label":["evidence in debate.2"],"name":[31],"type":["dbl"],"align":["right"]},{"label":["interface"],"name":[32],"type":["chr"],"align":["left"]},{"label":["evidence in debate (single)"],"name":[33],"type":["dbl"],"align":["right"]},{"label":["facts versus semantics.1"],"name":[34],"type":["dbl"],"align":["right"]},{"label":["facts versus semantics.2"],"name":[35],"type":["dbl"],"align":["right"]},{"label":["clash.1"],"name":[36],"type":["dbl"],"align":["right"]},{"label":["clash.2"],"name":[37],"type":["dbl"],"align":["right"]},{"label":["identity guesses.Judge"],"name":[38],"type":["chr"],"align":["left"]},{"label":["identity guesses.Debater A"],"name":[39],"type":["chr"],"align":["left"]},{"label":["identity guesses.Debater B"],"name":[40],"type":["chr"],"align":["left"]},{"label":["judge adaptation.1"],"name":[41],"type":["dbl"],"align":["right"]},{"label":["judge adaptation.2"],"name":[42],"type":["dbl"],"align":["right"]},{"label":["subjective correctness"],"name":[43],"type":["dbl"],"align":["right"]},{"label":["evidence use (single)"],"name":[44],"type":["dbl"],"align":["right"]},{"label":["factual informativeness (total)"],"name":[45],"type":["dbl"],"align":["right"]},{"label":["judge strategies"],"name":[46],"type":["chr"],"align":["left"]},{"label":["clarity (single)"],"name":[47],"type":["dbl"],"align":["right"]},{"label":["Debater A"],"name":[48],"type":["chr"],"align":["left"]},{"label":["Debater B"],"name":[49],"type":["chr"],"align":["left"]},{"label":["Honest debater"],"name":[50],"type":["chr"],"align":["left"]},{"label":["Dishonest debater"],"name":[51],"type":["chr"],"align":["left"]},{"label":["Is single debater"],"name":[52],"type":["lgl"],"align":["right"]},{"label":["Has honest debater"],"name":[53],"type":["lgl"],"align":["right"]},{"label":["Final_Setting"],"name":[54],"type":["chr"],"align":["left"]},{"label":["Setting"],"name":[55],"type":["fct"],"align":["left"]},{"label":["Question"],"name":[56],"type":["chr"],"align":["left"]},{"label":["Article ID"],"name":[57],"type":["dbl"],"align":["right"]},{"label":["Speed annotator accuracy bins"],"name":[58],"type":["ord"],"align":["right"]},{"label":["Untimed annotator context bins"],"name":[59],"type":["ord"],"align":["right"]},{"label":["Speed annotator accuracy"],"name":[60],"type":["dbl"],"align":["right"]},{"label":["Untimed annotator context"],"name":[61],"type":["dbl"],"align":["right"]},{"label":["Is offline"],"name":[62],"type":["lgl"],"align":["right"]},{"label":["End time"],"name":[63],"type":["dttm"],"align":["right"]},{"label":["Last modified time"],"name":[64],"type":["dttm"],"align":["right"]},{"label":["Final_Accuracy"],"name":[65],"type":["lgl"],"align":["right"]},{"label":["Human Consultancy Sample"],"name":[66],"type":["lgl"],"align":["right"]},{"label":["AI Consultancy Sample"],"name":[67],"type":["lgl"],"align":["right"]},{"label":["Human Debate Sample"],"name":[68],"type":["lgl"],"align":["right"]},{"label":["AI Debate Sample"],"name":[69],"type":["lgl"],"align":["right"]},{"label":["Sample"],"name":[70],"type":["lgl"],"align":["right"]},{"label":["Consultancy Sample"],"name":[71],"type":["lgl"],"align":["right"]},{"label":["initial_question_weights"],"name":[72],"type":["dbl"],"align":["right"]},{"label":["initial_question_weights_grouped_setting"],"name":[73],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_all_debates_weights"],"name":[74],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_all_debates_weights_grouped_setting"],"name":[75],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_all_debates_weights_setting"],"name":[76],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_debates_weights_grouped_setting"],"name":[77],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_debates_weights"],"name":[78],"type":["dbl"],"align":["right"]},{"label":["Final_Accuracy_char"],"name":[79],"type":["lgl"],"align":["right"]},{"label":["fpc"],"name":[80],"type":["dbl"],"align":["right"]},{"label":["fpcw"],"name":[81],"type":["dbl"],"align":["right"]}],"data":[{"1":"Anuj Jain","2":"survival-type-","3":"survival-type-5","4":"1681159356736","5":"Judge","6":"FALSE","7":"TRUE","8":"5","9":"0.33","10":"NaN","11":"NaN","12":"NA","13":"4","14":"4","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"i suck","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"3","35":"3","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Ethan Rosen","50":"Adelle Fernando","51":"Ethan Rosen","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How did the planet of Niobe compare to others that Earth was exploring?","57":"51395","58":"0.2","59":"3","60":"0.1666667","61":"2.750000","62":"FALSE","63":"2023-04-17 17:12:59.017","64":"2023-04-28 12:29:25.259","65":"FALSE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.33","81":"0.165","_rn_":"146"},{"1":"Ethan Rosen","2":"the-great-nebraska-sea-","3":"the-great-nebraska-sea-0","4":"1683321454611","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.01","10":"NaN","11":"NaN","12":"NA","13":"1","14":"1","15":"NaN","16":"NaN","17":"2","18":"2","19":"NaN","20":"NaN","21":"1","22":"I thought \"like\" was over-technical compared to what these questions typically ask for. I was wrong.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"2","32":"NA","33":"NaN","34":"1","35":"3","36":"4","37":"4","38":"NA","39":"NA","40":"NA","41":"4","42":"3","43":"NaN","44":"NaN","45":"1","46":"NA","47":"NaN","48":"Salsabila Mahdi","49":"Sean Wang","50":"Sean Wang","51":"Salsabila Mahdi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How is this article written?","57":"50893","58":"0.2","59":"3","60":"0.2000000","61":"3.333333","62":"FALSE","63":"2023-05-08 17:14:28.855","64":"2023-06-22 15:20:58.914","65":"FALSE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2000000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"1","78":"0.3333333","79":"NA","80":"0.01","81":"0.005","_rn_":"214"},{"1":"Jessica Li","2":"rx-","3":"rx-1","4":"1683298141840","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.01","10":"NaN","11":"NaN","12":"NA","13":"4","14":"2","15":"NaN","16":"NaN","17":"4","18":"1","19":"NaN","20":"NaN","21":"4","22":"B's last arg was literally 2 sentences, and A's ev was very convincing.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"2","32":"NA","33":"NaN","34":"1","35":"3","36":"4","37":"2","38":"NA","39":"NA","40":"NA","41":"4","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Reeya Kansra","49":"Adelle Fernando","50":"Adelle Fernando","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What were the specialties of the Red and Green Doctors, respectively?","57":"60412","58":"0.2","59":"3","60":"0.2000000","61":"2.800000","62":"FALSE","63":"2023-06-22 15:18:02.838","64":"2023-06-22 15:18:02.838","65":"FALSE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"1","78":"0.5000000","79":"NA","80":"0.01","81":"0.005","_rn_":"289"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code># Filter for high win rate debaters
high_win_rate_debaters &lt;- result %&gt;%
  filter(Win_Rate &gt; 0.20)  # Set the threshold for high win rate

# Filter original data for debates with &#39;Debate&#39; in Final_Setting
filtered_data &lt;- judgments_online %&gt;%
  filter(grepl(&quot;Debate&quot;, Final_Setting)) 

# Find cases where high win rate debaters lost
cases_high_win_rate_lost &lt;- filtered_data %&gt;%
  filter(`Dishonest debater` %in% high_win_rate_debaters$`Dishonest debater` &amp; Final_Accuracy != &quot;FALSE&quot;)

cases_high_win_rate_lost</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Participant"],"name":[1],"type":["fct"],"align":["left"]},{"label":["base_room_name"],"name":[2],"type":["chr"],"align":["left"]},{"label":["Room name"],"name":[3],"type":["chr"],"align":["left"]},{"label":["Room start time"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Role"],"name":[5],"type":["chr"],"align":["left"]},{"label":["Is turn"],"name":[6],"type":["lgl"],"align":["right"]},{"label":["Is over"],"name":[7],"type":["lgl"],"align":["right"]},{"label":["Number of judge continues"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["Final probability correct"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["Offline judging start time"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["Offline judging end time"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["other"],"name":[12],"type":["chr"],"align":["left"]},{"label":["factual informativeness (comparative).1"],"name":[13],"type":["dbl"],"align":["right"]},{"label":["factual informativeness (comparative).2"],"name":[14],"type":["dbl"],"align":["right"]},{"label":["facts versus semantics (single)"],"name":[15],"type":["dbl"],"align":["right"]},{"label":["factual accuracy (single)"],"name":[16],"type":["dbl"],"align":["right"]},{"label":["clarity.1"],"name":[17],"type":["dbl"],"align":["right"]},{"label":["clarity.2"],"name":[18],"type":["dbl"],"align":["right"]},{"label":["factual accuracy.1"],"name":[19],"type":["dbl"],"align":["right"]},{"label":["factual accuracy.2"],"name":[20],"type":["dbl"],"align":["right"]},{"label":["judge reasoning"],"name":[21],"type":["dbl"],"align":["right"]},{"label":["reason for outcome"],"name":[22],"type":["chr"],"align":["left"]},{"label":["protocol"],"name":[23],"type":["chr"],"align":["left"]},{"label":["evidence use.1"],"name":[24],"type":["dbl"],"align":["right"]},{"label":["evidence use.2"],"name":[25],"type":["dbl"],"align":["right"]},{"label":["evidence in story.1"],"name":[26],"type":["dbl"],"align":["right"]},{"label":["evidence in story.2"],"name":[27],"type":["dbl"],"align":["right"]},{"label":["other factors"],"name":[28],"type":["chr"],"align":["left"]},{"label":["judge adaptation (single)"],"name":[29],"type":["dbl"],"align":["right"]},{"label":["evidence in debate.1"],"name":[30],"type":["dbl"],"align":["right"]},{"label":["evidence in debate.2"],"name":[31],"type":["dbl"],"align":["right"]},{"label":["interface"],"name":[32],"type":["chr"],"align":["left"]},{"label":["evidence in debate (single)"],"name":[33],"type":["dbl"],"align":["right"]},{"label":["facts versus semantics.1"],"name":[34],"type":["dbl"],"align":["right"]},{"label":["facts versus semantics.2"],"name":[35],"type":["dbl"],"align":["right"]},{"label":["clash.1"],"name":[36],"type":["dbl"],"align":["right"]},{"label":["clash.2"],"name":[37],"type":["dbl"],"align":["right"]},{"label":["identity guesses.Judge"],"name":[38],"type":["chr"],"align":["left"]},{"label":["identity guesses.Debater A"],"name":[39],"type":["chr"],"align":["left"]},{"label":["identity guesses.Debater B"],"name":[40],"type":["chr"],"align":["left"]},{"label":["judge adaptation.1"],"name":[41],"type":["dbl"],"align":["right"]},{"label":["judge adaptation.2"],"name":[42],"type":["dbl"],"align":["right"]},{"label":["subjective correctness"],"name":[43],"type":["dbl"],"align":["right"]},{"label":["evidence use (single)"],"name":[44],"type":["dbl"],"align":["right"]},{"label":["factual informativeness (total)"],"name":[45],"type":["dbl"],"align":["right"]},{"label":["judge strategies"],"name":[46],"type":["chr"],"align":["left"]},{"label":["clarity (single)"],"name":[47],"type":["dbl"],"align":["right"]},{"label":["Debater A"],"name":[48],"type":["chr"],"align":["left"]},{"label":["Debater B"],"name":[49],"type":["chr"],"align":["left"]},{"label":["Honest debater"],"name":[50],"type":["chr"],"align":["left"]},{"label":["Dishonest debater"],"name":[51],"type":["chr"],"align":["left"]},{"label":["Is single debater"],"name":[52],"type":["lgl"],"align":["right"]},{"label":["Has honest debater"],"name":[53],"type":["lgl"],"align":["right"]},{"label":["Final_Setting"],"name":[54],"type":["chr"],"align":["left"]},{"label":["Setting"],"name":[55],"type":["fct"],"align":["left"]},{"label":["Question"],"name":[56],"type":["chr"],"align":["left"]},{"label":["Article ID"],"name":[57],"type":["dbl"],"align":["right"]},{"label":["Speed annotator accuracy bins"],"name":[58],"type":["ord"],"align":["right"]},{"label":["Untimed annotator context bins"],"name":[59],"type":["ord"],"align":["right"]},{"label":["Speed annotator accuracy"],"name":[60],"type":["dbl"],"align":["right"]},{"label":["Untimed annotator context"],"name":[61],"type":["dbl"],"align":["right"]},{"label":["Is offline"],"name":[62],"type":["lgl"],"align":["right"]},{"label":["End time"],"name":[63],"type":["dttm"],"align":["right"]},{"label":["Last modified time"],"name":[64],"type":["dttm"],"align":["right"]},{"label":["Final_Accuracy"],"name":[65],"type":["lgl"],"align":["right"]},{"label":["Human Consultancy Sample"],"name":[66],"type":["lgl"],"align":["right"]},{"label":["AI Consultancy Sample"],"name":[67],"type":["lgl"],"align":["right"]},{"label":["Human Debate Sample"],"name":[68],"type":["lgl"],"align":["right"]},{"label":["AI Debate Sample"],"name":[69],"type":["lgl"],"align":["right"]},{"label":["Sample"],"name":[70],"type":["lgl"],"align":["right"]},{"label":["Consultancy Sample"],"name":[71],"type":["lgl"],"align":["right"]},{"label":["initial_question_weights"],"name":[72],"type":["dbl"],"align":["right"]},{"label":["initial_question_weights_grouped_setting"],"name":[73],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_all_debates_weights"],"name":[74],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_all_debates_weights_grouped_setting"],"name":[75],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_all_debates_weights_setting"],"name":[76],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_debates_weights_grouped_setting"],"name":[77],"type":["dbl"],"align":["right"]},{"label":["sampled_consultancies_debates_weights"],"name":[78],"type":["dbl"],"align":["right"]},{"label":["Final_Accuracy_char"],"name":[79],"type":["lgl"],"align":["right"]},{"label":["fpc"],"name":[80],"type":["dbl"],"align":["right"]},{"label":["fpcw"],"name":[81],"type":["dbl"],"align":["right"]}],"data":[{"1":"Adelle Fernando","2":"monopoly-","3":"monopoly-1","4":"1680552464768","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.70","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"1","18":"1","19":"NaN","20":"NaN","21":"3","22":"This was a tough question because it deals with a character's intent, which seemed to be given little textual support in the story. I voted A because I think the ev showing him fighting with rebels was more conclusive and I wasn't convinced he lost hope.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"2","32":"NA","33":"NaN","34":"3","35":"3","36":"1","37":"2","38":"NA","39":"NA","40":"NA","41":"1","42":"1","43":"NaN","44":"NaN","45":"1","46":"NA","47":"NaN","48":"Ethan Rosen","49":"Sean Wang","50":"Ethan Rosen","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Which is the best summary of this story?","57":"61499","58":"0","59":"4","60":"0.0000000","61":"3.666667","62":"FALSE","63":"2023-04-10 16:16:41.598","64":"2023-04-28 11:30:24.344","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.70","81":"0.350","_rn_":"21"},{"1":"Adelle Fernando","2":"tollivers-orbit-","3":"tollivers-orbit-1","4":"1681765942714","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.90","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"2","18":"3","19":"NaN","20":"NaN","21":"3","22":"A was quite defensive, and B was countering alot of their ev, so it went to B","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"3","32":"NA","33":"NaN","34":"3","35":"2","36":"2","37":"2","38":"NA","39":"NA","40":"NA","41":"2","42":"3","43":"NaN","44":"NaN","45":"2","46":"NA","47":"NaN","48":"Jessica Li","49":"Ethan Rosen","50":"Ethan Rosen","51":"Jessica Li","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Which word doesn't describe Tolliver?","57":"61053","58":"0","59":"4","60":"0.0000000","61":"3.666667","62":"FALSE","63":"2023-05-21 14:03:16.038","64":"2023-05-26 10:54:34.612","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.90","81":"0.450","_rn_":"43"},{"1":"Aliyaah Toussaint","2":"rx-","3":"rx-3","4":"1683298141840","5":"Judge","6":"FALSE","7":"TRUE","8":"1","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"4","15":"NaN","16":"NaN","17":"3","18":"4","19":"NaN","20":"NaN","21":"4","22":"I got it right because A never stated that Earth was the site of a pervious wartime hospital. If you look at the quotes B shows the rest of A's quotes. The evidence is for the recent events not previous wartime hospital.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"4","32":"NA","33":"NaN","34":"2","35":"1","36":"1","37":"4","38":"NA","39":"NA","40":"NA","41":"2","42":"4","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Reeya Kansra","49":"Julian Michael","50":"Julian Michael","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How did Earth come to be the hospital planet?","57":"60412","58":"0","59":"2","60":"0.0000000","61":"2.000000","62":"FALSE","63":"2023-05-19 15:40:18.598","64":"2023-05-19 16:20:39.934","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"78"},{"1":"Aliyaah Toussaint","2":"stranger-from-space-","3":"stranger-from-space-0","4":"1683298716462","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"B characterized the character as delusional which made me think the character is crazy enough for A's answer to be true.\\n","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"3","32":"NA","33":"NaN","34":"1","35":"1","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Sean Wang","50":"Shreeram Modi","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why does Koroby feel motivated to start the fire?","57":"62314","58":"0.2","59":"3","60":"0.2000000","61":"3.000000","62":"FALSE","63":"2023-06-22 17:38:01.177","64":"2023-06-23 11:56:33.036","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2500000","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"81"},{"1":"Aliyaah Toussaint","2":"the-long-remembered-thunder-","3":"the-long-remembered-thunder-1","4":"1689876270711","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.98","10":"NaN","11":"NaN","12":"NA","13":"1","14":"3","15":"NaN","16":"NaN","17":"1","18":"3","19":"NaN","20":"NaN","21":"4","22":"B does an amazing job showing that Ms.Caroll was not spiteful toward Mr.Bram. Also A seems confused about the story which leads me to believe that B is right because no one knows if Tremaine got his answer resolved.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"3","32":"NA","33":"NaN","34":"3","35":"1","36":"0","37":"3","38":"NA","39":"NA","40":"NA","41":"2","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Shlomo Kofman","49":"Sean Wang","50":"Sean Wang","51":"Shlomo Kofman","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Did the questions Tremaine needed answers to get resolved?","57":"52844","58":"0.2","59":"4","60":"0.2000000","61":"4.000000","62":"FALSE","63":"2023-07-27 16:36:48.035","64":"2023-07-27 16:36:48.035","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.1666667","73":"1.0","74":"0.2000000","75":"1.0","76":"1.0","77":"1","78":"0.2500000","79":"NA","80":"0.98","81":"0.980","_rn_":"91"},{"1":"Aliyaah Toussaint","2":"the-princess-and-the-physicist-","3":"the-princess-and-the-physicist-4","4":"1682112300045","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"4","14":"2","15":"NaN","16":"NaN","17":"2","18":"4","19":"NaN","20":"NaN","21":"4","22":"A failed to address my concerns in the end which made me confidently vote B.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"3","32":"NA","33":"NaN","34":"2","35":"1","36":"1","37":"4","38":"NA","39":"NA","40":"NA","41":"1","42":"4","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sean Wang","49":"Anuj Jain","50":"Anuj Jain","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why did the physicist and anthropologist travel to Uxen?","57":"51126","58":"0.2","59":"2","60":"0.2000000","61":"1.800000","62":"FALSE","63":"2023-06-29 18:36:11.250","64":"2023-06-29 18:41:52.359","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"94"},{"1":"Aliyaah Toussaint","2":"the-starsent-knaves-","3":"the-starsent-knaves-2","4":"1688757372245","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.85","10":"NaN","11":"NaN","12":"NA","13":"1","14":"3","15":"NaN","16":"NaN","17":"1","18":"3","19":"NaN","20":"NaN","21":"4","22":"I got the right answer because A gave up. B had clear strong evidence. A conceded that the vehicle was called a cage.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"4","32":"NA","33":"NaN","34":"2","35":"3","36":"1","37":"3","38":"NA","39":"NA","40":"NA","41":"0","42":"4","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Shreeram Modi","50":"Shreeram Modi","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What was the blue spectral vehicle Dan acquired?","57":"52855","58":"0.2","59":"3","60":"0.2000000","61":"2.600000","62":"FALSE","63":"2023-07-13 17:57:20.122","64":"2023-07-31 15:39:55.230","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.85","81":"0.425","_rn_":"99"},{"1":"Anuj Jain","2":"cosmic-yoyo-","3":"cosmic-yoyo-0","4":"1681159027164","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"2","18":"2","19":"NaN","20":"NaN","21":"2","22":"B gave up LOL","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"2","32":"NA","33":"NaN","34":"2","35":"2","36":"2","37":"2","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"2","46":"NA","47":"NaN","48":"Noor Mirza-Rashid","49":"Sean Wang","50":"Noor Mirza-Rashid","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is likely the next step in the story?","57":"63527","58":"0","59":"3","60":"0.0000000","61":"3.000000","62":"FALSE","63":"2023-04-21 16:43:34.572","64":"2023-04-21 16:48:05.522","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.3333333","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"113"},{"1":"Anuj Jain","2":"out-of-the-iron-womb-","3":"out-of-the-iron-womb-0","4":"1689876275997","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"4","14":"3","15":"NaN","16":"NaN","17":"4","18":"3","19":"NaN","20":"NaN","21":"4","22":"b struggled to give ev that answered key questions","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"3","32":"NA","33":"NaN","34":"4","35":"3","36":"4","37":"3","38":"NA","39":"NA","40":"NA","41":"4","42":"3","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Adelle Fernando","50":"Shreeram Modi","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was the murderer trying to kill Bo?","57":"63633","58":"0.2","59":"4","60":"0.2000000","61":"4.000000","62":"FALSE","63":"2023-07-24 15:45:08.755","64":"2023-07-24 15:45:08.755","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.1428571","73":"0.5","74":"0.1666667","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"136"},{"1":"Anuj Jain","2":"planet-of-dread-","3":"planet-of-dread-2","4":"1680829456935","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"4","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"4","22":"B provided a functionally true quote but then A cooked it up by giving the full context. Next speech A cooked by proving the second part.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"3","32":"NA","33":"NaN","34":"1","35":"3","36":"3","37":"2","38":"NA","39":"NA","40":"NA","41":"3","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Reeya Kansra","49":"Jessica Li","50":"Reeya Kansra","51":"Jessica Li","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is the mission of the crew?","57":"43046","58":"0.4","59":"2","60":"0.4000000","61":"1.600000","62":"FALSE","63":"2023-04-17 16:40:55.302","64":"2023-06-12 16:25:09.391","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.990","_rn_":"140"},{"1":"Anuj Jain","2":"the-air-of-castor-oil-","3":"the-air-of-castor-oil-5","4":"1680552962919","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.85","10":"NaN","11":"NaN","12":"NA","13":"1","14":"3","15":"NaN","16":"NaN","17":"1","18":"2","19":"NaN","20":"NaN","21":"4","22":"B uses lots of evidence and explains the story. A operates on just defense.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"3","32":"NA","33":"NaN","34":"3","35":"1","36":"2","37":"2","38":"NA","39":"Emmanuel Makinde","40":"NA","41":"1","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Salsabila Mahdi","49":"Jessica Li","50":"Jessica Li","51":"Salsabila Mahdi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was the main character daydreaming about being a war-time pilot?","57":"51688","58":"0.2","59":"2","60":"0.2000000","61":"2.333333","62":"FALSE","63":"2023-04-10 17:33:21.834","64":"2023-04-12 17:18:09.483","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.85","81":"0.425","_rn_":"149"},{"1":"David Rein","2":"monopoly-","3":"monopoly-2","4":"1680552464768","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.85","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"2","18":"2","19":"NaN","20":"NaN","21":"3","22":"This was a weird/hard one, where I felt like the debaters didn't clash as much as they could have. Overall though I thought the evidence for A was a bit better than B.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"2","32":"NA","33":"NaN","34":"1","35":"3","36":"2","37":"2","38":"NA","39":"NA","40":"NA","41":"1","42":"1","43":"NaN","44":"NaN","45":"1","46":"NA","47":"NaN","48":"Ethan Rosen","49":"Reeya Kansra","50":"Ethan Rosen","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Generally, which of the following best describes Brian's character?","57":"61499","58":"0.2","59":"3","60":"0.2000000","61":"3.333333","62":"FALSE","63":"2023-04-18 15:05:57.536","64":"2023-04-28 10:25:57.801","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.85","81":"0.425","_rn_":"177"},{"1":"David Rein","2":"peggy-finds-the-theatre-","3":"peggy-finds-the-theatre-4","4":"1682110072206","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.90","10":"NaN","11":"NaN","12":"NA","13":"NaN","14":"NaN","15":"NaN","16":"NaN","17":"NaN","18":"NaN","19":"NaN","20":"NaN","21":"NaN","22":"NA","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"NaN","31":"NaN","32":"NA","33":"NaN","34":"NaN","35":"NaN","36":"NaN","37":"NaN","38":"NA","39":"NA","40":"NA","41":"NaN","42":"NaN","43":"NaN","44":"NaN","45":"NaN","46":"NA","47":"NaN","48":"Reeya Kansra","49":"Jackson Petty","50":"Jackson Petty","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Which of these sets of descriptions best describes Peggy?","57":"55933","58":"0.4","59":"3","60":"0.4000000","61":"3.333333","62":"FALSE","63":"2023-07-20 15:41:51.076","64":"2023-07-20 15:41:51.076","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.90","81":"0.450","_rn_":"179"},{"1":"David Rein","2":"stalemate-in-space-","3":"stalemate-in-space-0","4":"1677532762430","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"3","18":"4","19":"NaN","20":"NaN","21":"4","22":"This was an easy debate, because there was basically no specific textual evidence for option A, the incorrect answer.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"0","31":"3","32":"I accidentally entered the probabilities backwards","33":"NaN","34":"2","35":"1","36":"2","37":"3","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"1","46":"I said this to debater A: Are there any other resources mentioned, or context that helps explain resources? I'm not convinced that a \"key\" is the kind of resource that the question-writer would refer to. Also, I don't think Terrans (I'm assuming they are humans or some living species) would be referred to as a resource.","47":"NaN","48":"Shreeram Modi","49":"Ethan Rosen","50":"Ethan Rosen","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What was the relationship between the globes?","57":"63862","58":"0.2","59":"2","60":"0.2000000","61":"2.000000","62":"FALSE","63":"2023-02-27 17:02:34.740","64":"2023-04-28 16:44:08.378","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.990","_rn_":"185"},{"1":"David Rein","2":"stranger-from-space-","3":"stranger-from-space-4","4":"1683298716462","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"1","14":"1","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"4","22":"Partially because the dishonest debater gave up after a while, and partially because there was a bit more evidence in favor of A.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"2","32":"NA","33":"NaN","34":"2","35":"1","36":"4","37":"2","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"1","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Adelle Fernando","50":"Shreeram Modi","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How does Robert view Koroby?","57":"62314","58":"0.2","59":"3","60":"0.2000000","61":"2.600000","62":"FALSE","63":"2023-05-12 16:09:16.963","64":"2023-05-12 16:09:16.963","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.95","81":"0.475","_rn_":"186"},{"1":"David Rein","2":"the-great-nebraska-sea-","3":"the-great-nebraska-sea-1","4":"1683321454611","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"1","14":"1","15":"NaN","16":"NaN","17":"2","18":"2","19":"NaN","20":"NaN","21":"4","22":"A was unable to explain why the article was written in the past tense if it's supposed to be a theory.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"3","32":"NA","33":"NaN","34":"3","35":"3","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"4","42":"4","43":"NaN","44":"NaN","45":"1","46":"NA","47":"NaN","48":"Sean Wang","49":"Salsabila Mahdi","50":"Salsabila Mahdi","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How is this article written?","57":"50893","58":"0.2","59":"3","60":"0.2000000","61":"3.333333","62":"FALSE","63":"2023-05-09 16:15:12.746","64":"2023-05-19 16:52:53.628","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2000000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.95","81":"0.475","_rn_":"191"},{"1":"Ethan Rosen","2":"cosmic-yoyo-","3":"cosmic-yoyo-3","4":"1681159027164","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.90","10":"NaN","11":"NaN","12":"NA","13":"3","14":"4","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"B had better evidence that it was a fad","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"4","32":"NA","33":"NaN","34":"0","35":"0","36":"3","37":"4","38":"NA","39":"NA","40":"NA","41":"2","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Sean Wang","50":"Sean Wang","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why do Bob and Quezy haul asteroids in the first place?","57":"63527","58":"0.2","59":"2","60":"0.2000000","61":"1.666667","62":"FALSE","63":"2023-04-14 18:04:29.331","64":"2023-04-29 18:16:46.082","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.90","81":"0.450","_rn_":"202"},{"1":"Ethan Rosen","2":"stranger-from-space-","3":"stranger-from-space-5","4":"1683298716462","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"4","14":"2","15":"NaN","16":"NaN","17":"4","18":"1","19":"NaN","20":"NaN","21":"4","22":"B failed to present evidence that addressed my concerns.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"0","32":"NA","33":"NaN","34":"0","35":"4","36":"4","37":"1","38":"NA","39":"NA","40":"NA","41":"4","42":"1","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sean Wang","49":"Shreeram Modi","50":"Sean Wang","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How does Robert view Koroby?","57":"62314","58":"0.2","59":"3","60":"0.2000000","61":"2.600000","62":"FALSE","63":"2023-05-12 16:15:12.634","64":"2023-05-18 11:38:29.727","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.95","81":"0.475","_rn_":"211"},{"1":"Ethan Rosen","2":"the-man-who-was-six-","3":"the-man-who-was-six-1","4":"1676313105423","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.80","10":"NaN","11":"NaN","12":"nope.","13":"3","14":"2","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"A cut out key context that said the only memory he had was C. That indicates to me that W is new","23":"nope.","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"Nope.","29":"NaN","30":"4","31":"1","32":"The interface is great!","33":"NaN","34":"0","35":"1","36":"3","37":"2","38":"NA","39":"NA","40":"NA","41":"4","42":"4","43":"NaN","44":"NaN","45":"2","46":"I wanted clash on complexity vs. time. A gave new evidence, B repeated. I figured B was surface level.","47":"NaN","48":"David Rein","49":"Sean Wang","50":"David Rein","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was Dr. Crander so proud of his work on the patient?","57":"51295","58":"0.4","59":"3","60":"0.4000000","61":"3.000000","62":"FALSE","63":"2023-02-13 16:41:56.983","64":"2023-02-13 16:41:56.983","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.80","81":"0.800","_rn_":"215"},{"1":"Ethan Rosen","2":"the-monster-maker-","3":"the-monster-maker-4","4":"1681159292566","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"A accidentally argued for B. In fairness, the question was weirdly worded.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"0","31":"4","32":"NA","33":"NaN","34":"0","35":"0","36":"0","37":"4","38":"NA","39":"NA","40":"NA","41":"2","42":"4","43":"NaN","44":"NaN","45":"0","46":"NA","47":"NaN","48":"Noor Mirza-Rashid","49":"Shreeram Modi","50":"Shreeram Modi","51":"Noor Mirza-Rashid","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is not a type technology that is used in this story?","57":"62569","58":"0.4","59":"3","60":"0.4000000","61":"3.000000","62":"FALSE","63":"2023-04-14 16:31:19.063","64":"2023-05-01 16:31:54.842","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"216"},{"1":"Jackson Petty","2":"atom-mystery-young-atom-detective-","3":"atom-mystery-young-atom-detective-0","4":"1689949095893","5":"Judge","6":"FALSE","7":"TRUE","8":"6","9":"0.80","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"Honest had better ev and a more coherent story.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"2","32":"NA","33":"NaN","34":"2","35":"2","36":"3","37":"2","38":"NA","39":"NA","40":"NA","41":"3","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Anuj Jain","49":"Sam Jin","50":"Anuj Jain","51":"Sam Jin","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What best describes how the overall tone changed from the beginning of the article?","57":"53269","58":"0.2","59":"4","60":"0.2000000","61":"3.666667","62":"FALSE","63":"2023-07-28 15:39:59.035","64":"2023-07-28 15:39:59.035","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.1666667","73":"1.0","74":"0.2000000","75":"1.0","76":"1.0","77":"1","78":"0.2500000","79":"NA","80":"0.80","81":"0.800","_rn_":"219"},{"1":"Jackson Petty","2":"muck-man-","3":"muck-man-5","4":"1687546720669","5":"Judge","6":"FALSE","7":"TRUE","8":"7","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"2","18":"3","19":"NaN","20":"NaN","21":"4","22":"The honest debater apparently had a dynamite quote that they didn't bring in until speech 7, but gosh was it good.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"1","35":"1","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Sam Jin","49":"Shlomo Kofman","50":"Shlomo Kofman","51":"Sam Jin","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What would best describe Asa's motive for working as a muck man?","57":"61467","58":"0.4","59":"2","60":"0.4000000","61":"2.333333","62":"FALSE","63":"2023-06-26 17:15:36.480","64":"2023-06-26 17:15:36.480","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"236"},{"1":"Jackson Petty","2":"rx-","3":"rx-4","4":"1683298141840","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.90","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"4","22":"Dishonest debater ended up making somewhat vague and unconvincing points.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"2","32":"NA","33":"NaN","34":"1","35":"1","36":"4","37":"3","38":"NA","39":"NA","40":"NA","41":"4","42":"2","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Reeya Kansra","50":"Adelle Fernando","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why did the Earth doctor use the mortar and pestle?","57":"60412","58":"0.2","59":"3","60":"0.2000000","61":"2.600000","62":"FALSE","63":"2023-06-16 16:50:59.292","64":"2023-06-23 23:14:19.180","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.90","81":"0.450","_rn_":"240"},{"1":"Jackson Petty","2":"silence-isdeadly-","3":"silence-isdeadly-3","4":"1688157095546","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"4","14":"4","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"Honest debater's quote in the second round was a clear winner.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"0","35":"0","36":"3","37":"4","38":"NA","39":"NA","40":"NA","41":"2","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Sam Jin","49":"Anuj Jain","50":"Anuj Jain","51":"Sam Jin","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Who are the four to blame for the Comerford’s incident? \\n","57":"61481","58":"0.2","59":"3","60":"0.2000000","61":"3.333333","62":"FALSE","63":"2023-07-17 16:33:07.888","64":"2023-07-17 16:33:07.888","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"241"},{"1":"Jackson Petty","2":"the-princess-and-the-physicist-","3":"the-princess-and-the-physicist-0","4":"1682112300045","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"2","19":"NaN","20":"NaN","21":"3","22":"Dishonest debater avoided questions.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"2","32":"NA","33":"NaN","34":"1","35":"3","36":"3","37":"2","38":"NA","39":"NA","40":"NA","41":"3","42":"1","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Anuj Jain","49":"Reeya Kansra","50":"Anuj Jain","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What did Zen think of the plan the royal father and daughter hatched?","57":"51126","58":"0","59":"2","60":"0.0000000","61":"2.200000","62":"FALSE","63":"2023-07-17 15:04:00.321","64":"2023-07-17 15:04:00.321","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.95","81":"0.475","_rn_":"254"},{"1":"Jessica Li","2":"doctor-universe-","3":"doctor-universe-0","4":"1680206097221","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.70","10":"NaN","11":"NaN","12":"NA","13":"2","14":"3","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"B has more direct and clear ev, A's ev was mostly implicit/insubstantial.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"2","35":"0","36":"2","37":"2","38":"NA","39":"NA","40":"NA","41":"3","42":"4","43":"NaN","44":"NaN","45":"3","46":"B, could you give evidence that the current political climate is restless?\\nA, I understand how the Doctor is using the flames, but do you have direct proof that the show is meant to manipulate?","47":"NaN","48":"Reeya Kansra","49":"Anuj Jain","50":"Anuj Jain","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why is Grannie Annie so concerned about the Green Flame’s whereabouts?","57":"63109","58":"0.2","59":"2","60":"0.2000000","61":"1.666667","62":"FALSE","63":"2023-04-14 17:10:57.200","64":"2023-04-28 16:50:44.996","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.70","81":"0.700","_rn_":"270"},{"1":"Jessica Li","2":"how-to-make-friends-1","3":"how-to-make-friends-11","4":"1681724583153","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"3","15":"NaN","16":"NaN","17":"3","18":"4","19":"NaN","20":"NaN","21":"4","22":"B proves that mc does have access to a part needed to make the third person.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"2","35":"0","36":"2","37":"4","38":"NA","39":"NA","40":"NA","41":"2","42":"4","43":"NaN","44":"NaN","45":"4","46":"I kind of pushed a semantic argument which the debaters didn't pick up, but it was largely irrelevant to the debate.","47":"NaN","48":"Adelle Fernando","49":"Ethan Rosen","50":"Ethan Rosen","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How many companions did Manet make with the kit?","57":"50818","58":"0.2","59":"3","60":"0.2000000","61":"3.400000","62":"FALSE","63":"2023-05-15 16:10:35.476","64":"2023-05-15 16:10:35.476","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"276"},{"1":"Jessica Li","2":"silence-isdeadly-","3":"silence-isdeadly-2","4":"1688157095546","5":"Judge","6":"FALSE","7":"TRUE","8":"1","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"4","15":"NaN","16":"NaN","17":"3","18":"4","19":"NaN","20":"NaN","21":"4","22":"B's ev is clear cut and explicit. B also helped me understand the context + the individuals more.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"3","35":"0","36":"1","37":"2","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Sam Jin","50":"Sam Jin","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Who are the four to blame for the Comerford’s incident? \\n","57":"61481","58":"0.2","59":"3","60":"0.2000000","61":"3.333333","62":"FALSE","63":"2023-07-06 15:47:04.918","64":"2023-07-06 15:47:04.918","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"1","78":"0.3333333","79":"NA","80":"0.99","81":"0.495","_rn_":"290"},{"1":"Jessica Li","2":"the-princess-and-the-physicist-","3":"the-princess-and-the-physicist-2","4":"1682112300045","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"1","14":"0","15":"NaN","16":"NaN","17":"1","18":"0","19":"NaN","20":"NaN","21":"4","22":"B's last speech was literally just please vote for me, and on principle that makes me not want to vote for B","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"0","32":"NA","33":"NaN","34":"4","35":"3","36":"1","37":"0","38":"NA","39":"NA","40":"NA","41":"1","42":"0","43":"NaN","44":"NaN","45":"0","46":"NA","47":"NaN","48":"Anuj Jain","49":"Sean Wang","50":"Anuj Jain","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What was the population of the Uxen like among the galaxy?","57":"51126","58":"0.2","59":"2","60":"0.2000000","61":"2.200000","62":"FALSE","63":"2023-06-29 17:10:29.615","64":"2023-07-17 18:30:49.420","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"306"},{"1":"Julian Michael","2":"monopoly-","3":"monopoly-0","4":"1680552464768","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"4","15":"NaN","16":"NaN","17":"0","18":"3","19":"NaN","20":"NaN","21":"4","22":"A's story was internally inconsistent, they didn't back up important claims with necessary evidence, and B eventually was able to provide enough evidence and context to back up their side. I tried to cajole the debaters, and it might have helped, but I'm not sure.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"0","31":"3","32":"NA","33":"NaN","34":"0","35":"0","36":"1","37":"4","38":"NA","39":"Reeya Kansra","40":"Sean Wang","41":"2","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Reeya Kansra","49":"Sean Wang","50":"Sean Wang","51":"Reeya Kansra","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Which is the best summary of this story?","57":"61499","58":"0","59":"4","60":"0.0000000","61":"3.666667","62":"FALSE","63":"2023-05-01 17:55:02.894","64":"2023-05-11 16:49:22.963","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"324"},{"1":"Julian Michael","2":"stranger-from-space-","3":"stranger-from-space-1","4":"1683298716462","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"3","15":"NaN","16":"NaN","17":"3","18":"4","19":"NaN","20":"NaN","21":"4","22":"A didn't have evidence for the critical part of their answer, A's story contradicted some of B's evidence in serious ways, A failed to meaningfully respond or produce evidence in the second round, and A failed to respond to any of my concerns. The decision was clear.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"4","32":"NA","33":"NaN","34":"0","35":"0","36":"1","37":"4","38":"NA","39":"Reeya Kansra","40":"Sean Wang","41":"0","42":"4","43":"NaN","44":"NaN","45":"3","46":"I identified particular holes/burdens for A and posed them as questions, so A not having a response was more incriminating.","47":"NaN","48":"Shreeram Modi","49":"Sean Wang","50":"Sean Wang","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why does Koroby feel motivated to start the fire?","57":"62314","58":"0.2","59":"3","60":"0.2000000","61":"3.000000","62":"FALSE","63":"2023-05-05 11:55:03.127","64":"2023-05-11 15:50:12.046","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2500000","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"1","78":"0.5000000","79":"NA","80":"0.99","81":"0.495","_rn_":"331"},{"1":"Julian Michael","2":"survival-type-","3":"survival-type-4","4":"1681159356736","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"Maybe I could have decided sooner, even. but first round is a lot to go for.","13":"1","14":"4","15":"NaN","16":"NaN","17":"3","18":"4","19":"NaN","20":"NaN","21":"4","22":"A's case was weak and contained a bunch of lies, especially in the last round; B had a decent case and pointed out the lies effectively.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"0","31":"3","32":"NA","33":"NaN","34":"0","35":"0","36":"0","37":"4","38":"NA","39":"NA","40":"NA","41":"4","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Ethan Rosen","50":"Ethan Rosen","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How did the planet of Niobe compare to others that Earth was exploring?","57":"51395","58":"0.2","59":"3","60":"0.1666667","61":"2.750000","62":"FALSE","63":"2023-04-15 06:30:53.125","64":"2023-04-29 17:56:08.565","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"332"},{"1":"Julian Michael","2":"the-monster-maker-","3":"the-monster-maker-3","4":"1681159292566","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"1","14":"4","15":"NaN","16":"NaN","17":"1","18":"4","19":"NaN","20":"NaN","21":"4","22":"A provided zero evidence for their side after the first argument, while B refuted well and provided evidence.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"0","31":"3","32":"NA","33":"NaN","34":"0","35":"0","36":"0","37":"4","38":"NA","39":"NA","40":"NA","41":"0","42":"4","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Anuj Jain","50":"Anuj Jain","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Which best describes the relationship between the protagonists?","57":"62569","58":"0.2","59":"3","60":"0.2000000","61":"3.000000","62":"FALSE","63":"2023-06-22 18:58:39.177","64":"2023-06-22 18:58:39.177","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"338"},{"1":"Julian Michael","2":"the-spicy-sound-of-success-","3":"the-spicy-sound-of-success-4","4":"1679607458871","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"4","15":"NaN","16":"NaN","17":"1","18":"2","19":"NaN","20":"NaN","21":"4","22":"A seemed to have misused a quote pretty badly, and B had some strong evidence of the circumstance (unrefuted by A) of Gavin changing his outlook over the course of the story. (It's also just a more plausible story arc regardless).","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"4","32":"NA","33":"NaN","34":"0","35":"0","36":"2","37":"4","38":"NA","39":"NA","40":"NA","41":"2","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Jessica Li","49":"Anuj Jain","50":"Anuj Jain","51":"Jessica Li","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is the relationship between Gavin and the First Officer like?","57":"51351","58":"0.2","59":"3","60":"0.1666667","61":"2.800000","62":"FALSE","63":"2023-06-26 15:43:46.098","64":"2023-06-26 15:57:14.970","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"342"},{"1":"Julien Dirani","2":"manners-and-customs-","3":"manners-and-customs-1","4":"1676043334730","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.85","10":"NaN","11":"NaN","12":"NA","13":"4","14":"4","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"A mix of evidence coming from the honest debater vs. absence of evidence from dishonest debater + the dishonest debater was arguing over the semantics of the Q","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"3","35":"1","36":"4","37":"4","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sean Wang","49":"Jessica Li","50":"Jessica Li","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is the definition of truth to the Thrid?","57":"61430","58":"0","59":"2","60":"0.0000000","61":"1.600000","62":"FALSE","63":"2023-02-24 11:44:11.756","64":"2023-04-28 16:45:16.966","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.85","81":"0.850","_rn_":"348"},{"1":"Noor Mirza-Rashid","2":"doctor-universe-","3":"doctor-universe-5","4":"1680206097221","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.85","10":"NaN","11":"NaN","12":"NA","13":"2","14":"1","15":"NaN","16":"NaN","17":"1","18":"1","19":"NaN","20":"NaN","21":"4","22":"rereading the evidence provided in quotes tab a lot","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"1","32":"NA","33":"NaN","34":"1","35":"2","36":"1","37":"1","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"2","46":"NA","47":"NaN","48":"Reeya Kansra","49":"Shreeram Modi","50":"Reeya Kansra","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why is Billy so drawn to Grannie Annie?","57":"63109","58":"0.2","59":"3","60":"0.2000000","61":"2.666667","62":"FALSE","63":"2023-04-21 16:49:20.226","64":"2023-04-21 16:49:20.226","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"1.0","74":"0.5000000","75":"1.0","76":"1.0","77":"1","78":"0.5000000","79":"NA","80":"0.85","81":"0.850","_rn_":"356"},{"1":"Noor Mirza-Rashid","2":"volpla-","3":"volpla-2","4":"1680205817615","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"1","14":"2","15":"NaN","16":"NaN","17":"2","18":"2","19":"NaN","20":"NaN","21":"3","22":"Eventually got through all evidence and reconsidered quotes.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"3","32":"NA","33":"NaN","34":"2","35":"1","36":"2","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"2","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Salsabila Mahdi","50":"Salsabila Mahdi","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What does the narrator consider an imminent fun game?","57":"51201","58":"0","59":"3","60":"0.0000000","61":"2.600000","62":"FALSE","63":"2023-05-12 10:15:53.003","64":"2023-05-12 10:15:53.003","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2500000","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.95","81":"0.475","_rn_":"366"},{"1":"Reeya Kansra","2":"how-to-make-friends-","3":"how-to-make-friends-0","4":"1681724583153","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.98","10":"NaN","11":"NaN","12":"NA","13":"4","14":"4","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"I think I continued the debate for an extra round just to see if anything would be revealed to me. Sometimes that's risky cause longer debates can make me more confused. However B also had more quotes and was able to produce evidence that expressed that Tom's relationship to manet was at best agreeable and I used a little bit of a logic because if this guy just sells him the plot device for the rest of the story then I'm guessing the rest of the story revolves around what he does with the device and Victor seems like a bigger character overall.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"4","32":"NA","33":"NaN","34":"3","35":"0","36":"4","37":"4","38":"NA","39":"Jessica Li","40":"Adelle Fernando","41":"4","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Salsabila Mahdi","49":"Ethan Rosen","50":"Ethan Rosen","51":"Salsabila Mahdi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Who did Manet like the best?","57":"50818","58":"0.4","59":"4","60":"0.4000000","61":"3.600000","62":"FALSE","63":"2023-05-12 11:42:59.999","64":"2023-06-12 16:33:57.349","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"1","78":"0.5000000","79":"NA","80":"0.98","81":"0.490","_rn_":"378"},{"1":"Reeya Kansra","2":"muck-man-","3":"muck-man-7","4":"1687546765239","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.88","10":"NaN","11":"NaN","12":"NA","13":"3","14":"4","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"I notived that A started to have shorter and less relevant speeches which made me more confident that I was picking the right answer. The only reason I wasn't fully confident at the end was because I made my own leaps and bounds as a judge in order to connect dots which I don't like to do because it should be up to the debater to convince me not my self. That being said B started off with more compelling ev in the beginning which already made me prefer them.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"4","35":"4","36":"4","37":"4","38":"NA","39":"Julien Dirani","40":"Ethan Rosen","41":"4","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Sam Jin","49":"Shlomo Kofman","50":"Shlomo Kofman","51":"Sam Jin","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What happens to a changeling after their sentence is served?","57":"61467","58":"0.4","59":"2","60":"0.4000000","61":"2.000000","62":"FALSE","63":"2023-07-07 17:37:10.357","64":"2023-07-07 17:37:10.357","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.88","81":"0.440","_rn_":"387"},{"1":"Reeya Kansra","2":"the-monster-maker-","3":"the-monster-maker-1","4":"1681159292566","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.96","10":"NaN","11":"NaN","12":"NA","13":"4","14":"4","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"Accidentally voted for the wrong team during the debate. I think I had to take a little direction from A just because B's final speech started to confuse me (as it should). When they brought the debate back to the question at hand B's argumentation started to make sense. However A had a lot more convincing and logical evidence which is why I ended up voting for them. I generally vote with a full 99/1 confidence for the winning team however a little bit of sway from B made me lower my percentage.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"4","32":"NA","33":"NaN","34":"1","35":"0","36":"4","37":"4","38":"NA","39":"Emmanuel Makinde","40":"Adelle Fernando","41":"4","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Anuj Jain","49":"Noor Mirza-Rashid","50":"Anuj Jain","51":"Noor Mirza-Rashid","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What makes the protagonists become less concerned about being trapped by the beasts?","57":"62569","58":"0","59":"2","60":"0.0000000","61":"2.000000","62":"FALSE","63":"2023-04-21 16:27:51.982","64":"2023-04-21 16:27:51.982","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.96","81":"0.480","_rn_":"401"},{"1":"Salsabila Mahdi","2":"break-a-leg-","3":"break-a-leg-5","4":"1682110823449","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"A was being semantic-y, B's answer was more direct","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"3","32":"NA","33":"NaN","34":"3","35":"2","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sean Wang","49":"Anuj Jain","50":"Anuj Jain","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was the approach that Charlie took to engage with the aliens unsuccessful?","57":"51320","58":"0.2","59":"2","60":"0.1666667","61":"2.400000","62":"FALSE","63":"2023-04-28 13:51:32.411","64":"2023-05-12 10:49:32.467","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"411"},{"1":"Salsabila Mahdi","2":"cosmic-yoyo-","3":"cosmic-yoyo-2","4":"1681159027164","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"Clear text evidence","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"2","32":"NA","33":"NaN","34":"1","35":"2","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"2","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sean Wang","49":"Adelle Fernando","50":"Adelle Fernando","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why do Bob and Quezy haul asteroids in the first place?","57":"63527","58":"0.2","59":"2","60":"0.2000000","61":"1.666667","62":"FALSE","63":"2023-04-14 16:42:51.792","64":"2023-06-12 16:48:26.216","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"414"},{"1":"Salsabila Mahdi","2":"manners-and-customs-","3":"manners-and-customs-0","4":"1676043281654","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"1","14":"3","15":"NaN","16":"NaN","17":"2","18":"3","19":"NaN","20":"NaN","21":"NaN","22":"Debater A didn't respond well and stopped providing evidence or mind-changing reasoning.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"?","29":"NaN","30":"1","31":"3","32":"NA","33":"NaN","34":"1","35":"1","36":"2","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"4","43":"NaN","44":"NaN","45":"3","46":"Yes, I asked for more textual quotes & expanding evidence. I also asked them to clarify parts of their reasoning or what's going on in the story","47":"NaN","48":"Shreeram Modi","49":"Julian Michael","50":"Julian Michael","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why is Jorgenson allowed to speak to Ganti?","57":"61430","58":"0.4","59":"2","60":"0.4000000","61":"2.200000","62":"FALSE","63":"2023-02-17 11:51:02.058","64":"2023-05-15 17:10:36.536","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.990","_rn_":"421"},{"1":"Salsabila Mahdi","2":"muck-man-","3":"muck-man-4","4":"1687546720669","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"Understanding the story, checking what facts lined up","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"3","32":"NA","33":"NaN","34":"1","35":"1","36":"3","37":"3","38":"NA","39":"Shlomo Kofman","40":"Sam Jin","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Shlomo Kofman","49":"Sam Jin","50":"Sam Jin","51":"Shlomo Kofman","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What would best describe Asa's motive for working as a muck man?","57":"61467","58":"0.4","59":"2","60":"0.4000000","61":"2.333333","62":"FALSE","63":"2023-06-26 18:59:34.055","64":"2023-06-26 18:59:34.055","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"424"},{"1":"Salsabila Mahdi","2":"planet-of-dread-","3":"planet-of-dread-1","4":"1680829456935","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"B couldn't back that up with more, and A just obviously having that killed evidence","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"3","32":"NA","33":"NaN","34":"2","35":"2","36":"3","37":"3","38":"NA","39":"Jessica Li","40":"Anuj Jain","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Jessica Li","49":"Shreeram Modi","50":"Jessica Li","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why didn't Moran kill Harper?","57":"43046","58":"0.4","59":"3","60":"0.4000000","61":"3.200000","62":"FALSE","63":"2023-04-14 17:20:04.217","64":"2023-04-28 10:10:59.249","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"1","78":"0.5000000","79":"NA","80":"0.99","81":"0.495","_rn_":"425"},{"1":"Salsabila Mahdi","2":"silence-isdeadly-","3":"silence-isdeadly-6","4":"1688157095546","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"2","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"Kept pushing for the story & evidence, dishonest debater runs out","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"3","32":"NA","33":"NaN","34":"1","35":"1","36":"3","37":"2","38":"NA","39":"Jessica Li","40":"Shreeram Modi","41":"3","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sam Jin","49":"Adelle Fernando","50":"Sam Jin","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is Androka’s motivation for using the zone of silence? \\n","57":"61481","58":"0","59":"3","60":"0.0000000","61":"3.333333","62":"FALSE","63":"2023-07-06 17:58:47.461","64":"2023-07-06 17:58:47.461","65":"TRUE","66":"FALSE","67":"FALSE","68":"FALSE","69":"FALSE","70":"FALSE","71":"FALSE","72":"0.2000000","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"0","78":"0.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"429"},{"1":"Salsabila Mahdi","2":"stranger-from-space-","3":"stranger-from-space-2","4":"1683298716462","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"Evidence is clear, honest debater is responsive, dishonest debater has a shifty narrative","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"3","32":"NA","33":"NaN","34":"1","35":"2","36":"3","37":"2","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Adelle Fernando","50":"Shreeram Modi","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Which of the following is not a reason why Koroby is impressed by the stranger who lands in a spaceship?","57":"62314","58":"0.2","59":"2","60":"0.2000000","61":"2.200000","62":"FALSE","63":"2023-05-12 11:47:45.266","64":"2023-06-12 16:01:09.312","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.990","_rn_":"431"},{"1":"Salsabila Mahdi","2":"the-happy-castaway-","3":"the-happy-castaway-2","4":"1679606564549","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"Pushing for convincing evidence and/or reasoning","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"2","32":"NA","33":"NaN","34":"1","35":"1","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Aliyaah Toussaint","49":"Adelle Fernando","50":"Aliyaah Toussaint","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Johnathan doesn't tell the Interstellar Cosmography Society about the twenty-seven women who are waiting to be rescued because...","57":"63401","58":"0.2","59":"2","60":"0.2000000","61":"2.200000","62":"FALSE","63":"2023-04-07 16:34:58.352","64":"2023-04-07 16:34:58.352","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"1.0","74":"0.5000000","75":"1.0","76":"1.0","77":"1","78":"0.5000000","79":"NA","80":"0.99","81":"0.990","_rn_":"433"},{"1":"Salsabila Mahdi","2":"the-reluctant-heroes-","3":"the-reluctant-heroes-2","4":"1682965111772","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"4","22":"Evidence, okay steering of the debate, debater responsiveness/not consistent/not","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"3","32":"NA","33":"NaN","34":"2","35":"2","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"4","42":"3","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Vishakh Padmakumar","49":"Shreeram Modi","50":"Vishakh Padmakumar","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How many people live on the moon at any one time?","57":"51483","58":"0.2","59":"2","60":"0.2000000","61":"2.200000","62":"FALSE","63":"2023-05-11 14:57:46.216","64":"2023-05-11 14:57:46.216","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.990","_rn_":"436"},{"1":"Salsabila Mahdi","2":"the-starsent-knaves-","3":"the-starsent-knaves-0","4":"1688757372245","5":"Judge","6":"FALSE","7":"TRUE","8":"6","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"this took a long time, i think the honest debater and i misunderstood each other. but i took more rounds. and eventually dishonest debater couldn't back up what i wanted with quotes - rereading the debate to realize this was also helpful","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"3","32":"NA","33":"NaN","34":"2","35":"1","36":"2","37":"2","38":"NA","39":"Sean Wang","40":"Reeya Kansra","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sam Jin","49":"Adelle Fernando","50":"Adelle Fernando","51":"Sam Jin","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What was the blue spectral vehicle Dan acquired?","57":"52855","58":"0.2","59":"3","60":"0.2000000","61":"2.600000","62":"FALSE","63":"2023-07-13 13:02:18.154","64":"2023-07-13 13:02:18.154","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"1","78":"0.3333333","79":"NA","80":"0.95","81":"0.475","_rn_":"439"},{"1":"Sam Jin","2":"coming-of-the-gods-","3":"coming-of-the-gods-2","4":"1689020073883","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"NaN","14":"NaN","15":"NaN","16":"NaN","17":"NaN","18":"NaN","19":"NaN","20":"NaN","21":"NaN","22":"NA","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"NaN","31":"NaN","32":"NA","33":"NaN","34":"NaN","35":"NaN","36":"NaN","37":"NaN","38":"NA","39":"NA","40":"NA","41":"NaN","42":"NaN","43":"NaN","44":"NaN","45":"NaN","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Jessica Li","50":"Adelle Fernando","51":"Jessica Li","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What became of Ro's mother?","57":"63523","58":"0.2","59":"3","60":"0.2000000","61":"3.400000","62":"FALSE","63":"2023-07-14 16:51:09.134","64":"2023-07-14 16:51:09.134","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2000000","73":"1.0","74":"0.3333333","75":"1.0","76":"1.0","77":"1","78":"0.3333333","79":"NA","80":"0.99","81":"0.990","_rn_":"448"},{"1":"Sam Jin","2":"venus-is-a-mans-world-","3":"venus-is-a-mans-world-0","4":"1691058680973","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"NaN","14":"NaN","15":"NaN","16":"NaN","17":"NaN","18":"NaN","19":"NaN","20":"NaN","21":"NaN","22":"NA","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"NaN","31":"NaN","32":"NA","33":"NaN","34":"NaN","35":"NaN","36":"NaN","37":"NaN","38":"NA","39":"NA","40":"NA","41":"NaN","42":"NaN","43":"NaN","44":"NaN","45":"NaN","46":"NA","47":"NaN","48":"Anuj Jain","49":"Shlomo Kofman","50":"Anuj Jain","51":"Shlomo Kofman","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What was the relationship like between Ferdinand and the man from Venus?","57":"51150","58":"0.2","59":"3","60":"0.2000000","61":"3.000000","62":"FALSE","63":"2023-08-04 16:36:03.740","64":"2023-08-04 16:36:03.740","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.1666667","73":"1.0","74":"0.2000000","75":"1.0","76":"1.0","77":"1","78":"0.2500000","79":"NA","80":"0.99","81":"0.990","_rn_":"510"},{"1":"Sean Wang","2":"lost-in-translation-","3":"lost-in-translation-3","4":"1678404069200","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.98","10":"NaN","11":"NaN","12":"NA","13":"3","14":"2","15":"NaN","16":"NaN","17":"2","18":"3","19":"NaN","20":"NaN","21":"3","22":"The evidence was just way more in B's favor.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"1","32":"NA","33":"NaN","34":"2","35":"1","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"2","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Salsabila Mahdi","50":"Salsabila Mahdi","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why did Korvin have to word his questions to the guard carefully?","57":"30029","58":"0.4","59":"2","60":"0.4000000","61":"1.800000","62":"FALSE","63":"2023-03-10 11:53:42.380","64":"2023-04-13 16:46:04.954","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"1.0","74":"0.5000000","75":"1.0","76":"1.0","77":"1","78":"0.5000000","79":"NA","80":"0.98","81":"0.980","_rn_":"533"},{"1":"Sean Wang","2":"peggy-finds-the-theatre-","3":"peggy-finds-the-theatre-0","4":"1682090000149","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.90","10":"NaN","11":"NaN","12":"NA","13":"4","14":"4","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"Both debaters agreed on the overall story, it was kind of hard to argue that a fairly mundane experience of a girl bargaining w her parents was \"highly excited\" after that.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"4","32":"NA","33":"NaN","34":"3","35":"3","36":"4","37":"2","38":"NA","39":"NA","40":"NA","41":"4","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Salsabila Mahdi","49":"Vishakh Padmakumar","50":"Vishakh Padmakumar","51":"Salsabila Mahdi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How would you describe the tone throughout the passage?","57":"55933","58":"0","59":"4","60":"0.0000000","61":"4.000000","62":"FALSE","63":"2023-04-28 10:13:44.101","64":"2023-06-12 16:24:31.756","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.90","81":"0.450","_rn_":"538"},{"1":"Sean Wang","2":"survival-type-","3":"survival-type-0","4":"1681159356736","5":"Judge","6":"FALSE","7":"TRUE","8":"1","9":"0.98","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"Quality of evidence","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"0","31":"3","32":"NA","33":"NaN","34":"3","35":"0","36":"0","37":"0","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"0","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Jackson Petty","50":"Jackson Petty","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was Earth exploring Niobe?","57":"51395","58":"0.2","59":"2","60":"0.2000000","61":"2.250000","62":"FALSE","63":"2023-04-17 17:06:13.467","64":"2023-04-18 13:42:45.338","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.98","81":"0.980","_rn_":"544"},{"1":"Sean Wang","2":"the-cool-war-","3":"the-cool-war-0","4":"1689949097911","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"4","18":"4","19":"NaN","20":"NaN","21":"4","22":"I feel like the end twist is that Pashkov is using the cubans as scapegoats and also all of A's ev postdates B's and B hasn't contested any of it","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"3","32":"NA","33":"NaN","34":"2","35":"1","36":"4","37":"2","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Jessica Li","49":"Shlomo Kofman","50":"Jessica Li","51":"Shlomo Kofman","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why did Pashkov sell small arms to the Cubans?","57":"51256","58":"0.4","59":"3","60":"0.4000000","61":"3.000000","62":"FALSE","63":"2023-08-03 16:36:15.082","64":"2023-08-03 16:36:15.082","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2500000","73":"1.0","74":"0.2500000","75":"1.0","76":"1.0","77":"1","78":"0.2500000","79":"NA","80":"0.99","81":"0.990","_rn_":"550"},{"1":"Sean Wang","2":"volpla-","3":"volpla-3","4":"1680205817615","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"4","22":"Quality of evidence","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"2","35":"0","36":"4","37":"4","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Aliyaah Toussaint","50":"Aliyaah Toussaint","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What does the narrator consider an imminent fun game?","57":"51201","58":"0","59":"3","60":"0.0000000","61":"2.600000","62":"FALSE","63":"2023-04-17 17:45:31.796","64":"2023-04-29 22:45:31.171","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2500000","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"1","78":"0.5000000","79":"NA","80":"0.95","81":"0.475","_rn_":"561"},{"1":"Shlomo Kofman","2":"out-of-the-iron-womb-","3":"out-of-the-iron-womb-1","4":"1689876275999","5":"Judge","6":"FALSE","7":"TRUE","8":"1","9":"0.94","10":"NaN","11":"NaN","12":"NA","13":"4","14":"2","15":"NaN","16":"NaN","17":"1","18":"4","19":"NaN","20":"NaN","21":"4","22":"A had zero context or EV for the story; B was super clear on proof, context and including the name of the story in thier argument","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"2","32":"NA","33":"NaN","34":"2","35":"1","36":"2","37":"2","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Shreeram Modi","49":"Adelle Fernando","50":"Adelle Fernando","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was the murderer trying to kill Bo?","57":"63633","58":"0.2","59":"4","60":"0.2000000","61":"4.000000","62":"FALSE","63":"2023-07-24 17:40:02.914","64":"2023-07-24 17:40:02.914","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.1428571","73":"0.5","74":"0.1666667","75":"0.5","76":"0.5","77":"1","78":"0.2500000","79":"NA","80":"0.94","81":"0.470","_rn_":"598"},{"1":"Shlomo Kofman","2":"pied-piper-of-mars-","3":"pied-piper-of-mars-8","4":"1689278492513","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.91","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"3","18":"2","19":"NaN","20":"NaN","21":"3","22":"A had a strong last round and provided the twist at the end of the story","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"2","32":"NA","33":"NaN","34":"2","35":"2","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Jessica Li","49":"Sean Wang","50":"Jessica Li","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What would be the main reason Mr. Ranson wants to find the creator of the hypnotic music?","57":"62085","58":"0.2","59":"2","60":"0.2000000","61":"2.333333","62":"FALSE","63":"2023-07-17 19:39:59.954","64":"2023-07-17 19:39:59.954","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"1.0","74":"0.5000000","75":"1.0","76":"1.0","77":"1","78":"0.5000000","79":"NA","80":"0.91","81":"0.910","_rn_":"602"},{"1":"Shlomo Kofman","2":"rx-","3":"rx-5","4":"1683298141840","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.86","10":"NaN","11":"NaN","12":"NA","13":"2","14":"3","15":"NaN","16":"NaN","17":"2","18":"3","19":"NaN","20":"NaN","21":"4","22":"B had more ev, was concise and clear and had quotes to support it.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"4","32":"NA","33":"NaN","34":"2","35":"2","36":"3","37":"2","38":"NA","39":"NA","40":"NA","41":"2","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Adelle Fernando","49":"Reeya Kansra","50":"Reeya Kansra","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why did the Earth doctor use the mortar and pestle?","57":"60412","58":"0.2","59":"3","60":"0.2000000","61":"2.600000","62":"FALSE","63":"2023-07-07 18:12:21.375","64":"2023-07-07 21:30:24.456","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.86","81":"0.430","_rn_":"606"},{"1":"Shlomo Kofman","2":"the-starbusters-","3":"the-starbusters-3","4":"1689371609880","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.97","10":"NaN","11":"NaN","12":"NA","13":"2","14":"4","15":"NaN","16":"NaN","17":"1","18":"4","19":"NaN","20":"NaN","21":"4","22":"B had way more EV and A didn't provide me with plot points like I asked them too","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"4","32":"NA","33":"NaN","34":"0","35":"0","36":"0","37":"4","38":"NA","39":"NA","40":"NA","41":"0","42":"4","43":"NaN","44":"NaN","45":"4","46":"NA","47":"NaN","48":"Sam Jin","49":"Adelle Fernando","50":"Adelle Fernando","51":"Sam Jin","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"How did Hendricks outfit the ship for war?","57":"63855","58":"0","59":"2","60":"0.0000000","61":"2.000000","62":"FALSE","63":"2023-07-17 19:00:09.980","64":"2023-07-17 19:00:09.980","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"1","78":"0.3333333","79":"NA","80":"0.97","81":"0.485","_rn_":"626"},{"1":"Shreeram Modi","2":"cosmic-yoyo-","3":"cosmic-yoyo-1","4":"1681159027164","5":"Judge","6":"FALSE","7":"TRUE","8":"4","9":"0.95","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"2","18":"2","19":"NaN","20":"NaN","21":"3","22":"B lost steam and didn't use the whole argument length.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"2","32":"NA","33":"NaN","34":"1","35":"3","36":"3","37":"3","38":"NA","39":"NA","40":"NA","41":"3","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sean Wang","49":"Adelle Fernando","50":"Sean Wang","51":"Adelle Fernando","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is likely the next step in the story?","57":"63527","58":"0","59":"3","60":"0.0000000","61":"3.000000","62":"FALSE","63":"2023-04-17 18:48:16.625","64":"2023-04-18 14:26:39.448","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"1","78":"0.5000000","79":"NA","80":"0.95","81":"0.475","_rn_":"637"},{"1":"Shreeram Modi","2":"in-the-garden-","3":"in-the-garden-6","4":"1680206043370","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"1","15":"NaN","16":"NaN","17":"2","18":"1","19":"NaN","20":"NaN","21":"3","22":"I made an educated guess based on what behaviors are likely with honest and dishonest debaters.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"3","31":"1","32":"NA","33":"NaN","34":"1","35":"3","36":"2","37":"0","38":"NA","39":"NA","40":"NA","41":"2","42":"1","43":"NaN","44":"NaN","45":"2","46":"NA","47":"NaN","48":"David Rein","49":"Jessica Li","50":"David Rein","51":"Jessica Li","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is likely to happen to the crew when they return to the planet?","57":"61007","58":"0.2","59":"2","60":"0.2000000","61":"1.666667","62":"FALSE","63":"2023-05-12 10:16:04.732","64":"2023-05-12 10:16:04.732","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"0.5","74":"0.3333333","75":"0.5","76":"0.5","77":"1","78":"0.5000000","79":"NA","80":"0.99","81":"0.495","_rn_":"641"},{"1":"Shreeram Modi","2":"peggy-finds-the-theatre-","3":"peggy-finds-the-theatre-2","4":"1682090000149","5":"Judge","6":"FALSE","7":"TRUE","8":"1","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"3","14":"3","15":"NaN","16":"NaN","17":"3","18":"3","19":"NaN","20":"NaN","21":"3","22":"The question was worded in a weird way.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"1","31":"3","32":"NA","33":"NaN","34":"3","35":"2","36":"2","37":"3","38":"NA","39":"NA","40":"NA","41":"2","42":"2","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Salsabila Mahdi","49":"Vishakh Padmakumar","50":"Vishakh Padmakumar","51":"Salsabila Mahdi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was Socks a part of this story?","57":"55933","58":"0.2","59":"2","60":"0.2000000","61":"2.000000","62":"FALSE","63":"2023-04-24 17:33:24.717","64":"2023-05-24 16:28:55.141","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.99","81":"0.495","_rn_":"647"},{"1":"Shreeram Modi","2":"phone-me-in-central-park-","3":"phone-me-in-central-park-5","4":"1678684819928","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.99","10":"1682713008576","11":"1682713141741","12":"NA","13":"1","14":"3","15":"NaN","16":"NaN","17":"2","18":"3","19":"NaN","20":"NaN","21":"3","22":"There was clear evidence in B's favor and A couldn't provide evidence.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"4","32":"NA","33":"NaN","34":"2","35":"1","36":"2","37":"4","38":"NA","39":"NA","40":"NA","41":"1","42":"4","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Sean Wang","49":"Ethan Rosen","50":"Ethan Rosen","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is the true explanation for Charles being the last man on Earth? \\n\\n","57":"63631","58":"0.2","59":"3","60":"0.2000000","61":"2.666667","62":"FALSE","63":"2023-03-20 17:06:51.331","64":"2023-04-28 16:39:55.296","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2000000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"1","78":"0.3333333","79":"NA","80":"0.99","81":"0.495","_rn_":"648"},{"1":"Shreeram Modi","2":"the-man-who-was-six-","3":"the-man-who-was-six-5","4":"1676645924826","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.99","10":"NaN","11":"NaN","12":"NA","13":"2","14":"3","15":"NaN","16":"NaN","17":"2","18":"2","19":"NaN","20":"NaN","21":"2","22":"This debate was incredibly confusing. However, in the end B directly responded to the points A made more while A kept just repeating the same arguments over and over again, which led me to side with B.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"2","31":"2","32":"NA","33":"NaN","34":"3","35":"3","36":"1","37":"3","38":"NA","39":"NA","40":"NA","41":"1","42":"3","43":"NaN","44":"NaN","45":"3","46":"Yes. I indicated particular pieces of evidence that both were missing and that would help me greatly in evaluating the debate. I told A to find quotes of the clothes being mentioned somewhere and also a direct comparison of the two's heights. I told B to try to find a quote that would show both Erica and Dan together before the accident.","47":"NaN","48":"Sean Wang","49":"Julian Michael","50":"Julian Michael","51":"Sean Wang","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"If Dan and Erica had been seen together before the accident, what would people have likely thought?","57":"51295","58":"0.4","59":"4","60":"0.4000000","61":"3.666667","62":"FALSE","63":"2023-02-22 17:30:45.461","64":"2023-02-22 17:30:45.461","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"1.0","74":"0.5000000","75":"1.0","76":"1.0","77":"1","78":"0.5000000","79":"NA","80":"0.99","81":"0.990","_rn_":"658"},{"1":"Vishakh Padmakumar","2":"stalemate-in-space-","3":"stalemate-in-space-2","4":"1677792427135","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.80","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"3","18":"2","19":"NaN","20":"NaN","21":"3","22":"The debate reached a single contradiction which was resolved and conveyed to me that the dishonest debater was being dishonest. I didn't really think I understood the rest of the story but it helped me answer the question.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"1","32":"Quote limits seemed to hamper both debaters? Unclear if they agree","33":"NaN","34":"1","35":"3","36":"4","37":"2","38":"NA","39":"NA","40":"NA","41":"4","42":"1","43":"NaN","44":"NaN","45":"1","46":"Mainly I identified what seemed like an important contradiction between debaters and resolving that meant that I knew the answer. B tried to deflect without being clear.","47":"NaN","48":"Julian Michael","49":"Jessica Li","50":"Julian Michael","51":"Jessica Li","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Of the following situations, what was the toughest for Evelyn to handle?","57":"63862","58":"0.4","59":"3","60":"0.4000000","61":"3.400000","62":"FALSE","63":"2023-03-07 21:04:25.130","64":"2023-04-28 17:01:26.086","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.3333333","73":"1.0","74":"0.5000000","75":"1.0","76":"1.0","77":"1","78":"0.5000000","79":"NA","80":"0.80","81":"0.800","_rn_":"677"},{"1":"Vishakh Padmakumar","2":"the-air-of-castor-oil-","3":"the-air-of-castor-oil-4","4":"1680552962919","5":"Judge","6":"FALSE","7":"TRUE","8":"2","9":"0.75","10":"NaN","11":"NaN","12":"NA","13":"2","14":"2","15":"NaN","16":"NaN","17":"3","18":"2","19":"NaN","20":"NaN","21":"2","22":"It fit a common pattern where the incorrect answer is kind of a dumbed down version of the more complex but correct answer. I had earlier asked the dishonest debater to clap back against what would've been an extraordinary lie and they failed to do so, which made my decision easier.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"I definitely dropped the ball here and got back to judging the debate after a few weeks. I think my reasoning was fine but I would maybe have asked for another turn if I was doing this in sync","29":"NaN","30":"3","31":"1","32":"NA","33":"NaN","34":"2","35":"3","36":"3","37":"2","38":"NA","39":"NA","40":"NA","41":"3","42":"0","43":"NaN","44":"NaN","45":"2","46":"NA","47":"NaN","48":"Jessica Li","49":"Salsabila Mahdi","50":"Salsabila Mahdi","51":"Jessica Li","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"Why was the main character daydreaming about being a war-time pilot?","57":"51688","58":"0.2","59":"2","60":"0.2000000","61":"2.333333","62":"FALSE","63":"2023-06-22 21:37:32.757","64":"2023-06-22 21:37:32.757","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.2500000","73":"0.5","74":"0.2500000","75":"0.5","76":"0.5","77":"1","78":"0.3333333","79":"NA","80":"0.75","81":"0.375","_rn_":"679"},{"1":"Vishakh Padmakumar","2":"the-desert-and-the-stars-","3":"the-desert-and-the-stars-2","4":"1677792315334","5":"Judge","6":"FALSE","7":"TRUE","8":"3","9":"0.75","10":"NaN","11":"NaN","12":"NA","13":"2","14":"1","15":"NaN","16":"NaN","17":"3","18":"1","19":"NaN","20":"NaN","21":"4","22":"It was pretty clear after 3 rounds that the dishonest debater was clutching at strings.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"I sensed towards the end that the dishonest debater was getting a bit desperate, it influenced me to finish the debate and not take another turn.","29":"NaN","30":"3","31":"1","32":"NA","33":"NaN","34":"2","35":"3","36":"4","37":"2","38":"NA","39":"NA","40":"NA","41":"4","42":"2","43":"NaN","44":"NaN","45":"3","46":"Mostly understanding the semantics and evidence from both sides and confirming that I've understood them correctly.","47":"NaN","48":"Julian Michael","49":"Salsabila Mahdi","50":"Julian Michael","51":"Salsabila Mahdi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is the style of the Corps' note to the Aga Kaga?","57":"61285","58":"0.4","59":"2","60":"0.4000000","61":"2.000000","62":"FALSE","63":"2023-03-07 17:00:26.966","64":"2023-04-28 17:38:19.697","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"1.0000000","73":"1.0","74":"1.0000000","75":"1.0","76":"1.0","77":"1","78":"1.0000000","79":"NA","80":"0.75","81":"0.750","_rn_":"680"},{"1":"Vishakh Padmakumar","2":"the-monster-maker-","3":"the-monster-maker-5","4":"1681159292566","5":"Judge","6":"FALSE","7":"TRUE","8":"5","9":"0.80","10":"NaN","11":"NaN","12":"NA","13":"0","14":"3","15":"NaN","16":"NaN","17":"0","18":"3","19":"NaN","20":"NaN","21":"3","22":"I think the factor which convinces me is that the evidence presented seems compelling that the monsters just could not be captured on film. B told me in the recap that the monsters were projections created by Gunther. That itself seems like distorting technology. I don't think there is much evidence that the camera 'malfunctioned' whereas c.3692 is quite clear.\\nI'm honestly unsure about where to go with the guns, but the debate just seems to be frustrating me more at this point.\\nI'm going with A, but I think A did not do a good job presenting a coherent argument at all.","23":"NA","24":"NaN","25":"NaN","26":"NaN","27":"NaN","28":"NA","29":"NaN","30":"4","31":"2","32":"NA","33":"NaN","34":"1","35":"3","36":"1","37":"3","38":"NA","39":"NA","40":"NA","41":"1","42":"3","43":"NaN","44":"NaN","45":"3","46":"NA","47":"NaN","48":"Anuj Jain","49":"Shreeram Modi","50":"Anuj Jain","51":"Shreeram Modi","52":"FALSE","53":"TRUE","54":"Human Debate","55":"Human Debate","56":"What is not a type technology that is used in this story?","57":"62569","58":"0.4","59":"3","60":"0.4000000","61":"3.000000","62":"FALSE","63":"2023-04-21 11:01:01.503","64":"2023-06-12 16:05:11.888","65":"TRUE","66":"FALSE","67":"FALSE","68":"TRUE","69":"FALSE","70":"TRUE","71":"TRUE","72":"0.5000000","73":"0.5","74":"0.5000000","75":"0.5","76":"0.5","77":"1","78":"1.0000000","79":"NA","80":"0.80","81":"0.400","_rn_":"683"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code># Fit the random intercept model and only remove missing values for &#39;Dishonest debater&#39;
random_intercept_model &lt;- lmer(`Final probability correct` ~ (1|`Dishonest debater`), 
                                data = dishonest, 
                                REML = TRUE)

# Summary of the model
summary(random_intercept_model)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: `Final probability correct` ~ (1 | `Dishonest debater`)
##    Data: dishonest
## 
## REML criterion at convergence: 302.1
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5213 -0.1985  0.5027  0.6588  0.8225 
## 
## Random effects:
##  Groups            Name        Variance Std.Dev.
##  Dishonest debater (Intercept) 0.001765 0.04201 
##  Residual                      0.096628 0.31085 
## Number of obs: 577, groups:  Dishonest debater, 20
## 
## Fixed effects:
##             Estimate Std. Error      df t value       Pr(&gt;|t|)    
## (Intercept)  0.78325    0.01719 7.54926   45.58 0.000000000172 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>dishonest$random.intercept.preds = predict(random_intercept_model)
plot(dishonest$random.intercept.preds, dishonest$`Final probability correct`)</code></pre>
<p><img src="debate-2309_files/figure-html/unnamed-chunk-3-9.png" width="672" /></p>
<div id="debater-experience-ratings---how-many-wins"
class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Debater
“Experience”, ratings - how many wins?</h3>
</div>
<div id="ai-vs-humans" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> AI vs Humans</h3>
</div>
<div id="old-vs-new" class="section level3" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Old vs New</h3>
</div>
<div id="possibly-unnessary" class="section level3" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> possibly
unnessary</h3>
<p>Finally, these are how many we get correct in each setting</p>
<pre class="r"><code>judgments_online &lt;- py$judgments_online
table(judgments_online$Final_Accuracy, judgments_online$Final_Setting)</code></pre>
<pre><code>##        
##         AI Consultancy AI Debate Human Consultancy Human Debate
##   FALSE             18        19                32           25
##   TRUE              75        68                75          130</code></pre>
<pre class="r"><code>table(judgments_online$Final_Accuracy, judgments_online$Setting)</code></pre>
<pre><code>##        
##         AI Consultancy Dishonest AI Consultancy Honest AI Debate
##   FALSE                        5                    13        19
##   TRUE                        33                    42        68
##        
##         Human Consultancy Dishonest Human Consultancy Honest Human Debate
##   FALSE                          26                        6           25
##   TRUE                           33                       42          130</code></pre>
<pre class="r"><code>ggplot(judgments_online, aes(x = Final_Setting, fill = Final_Accuracy)) +
  geom_bar(position = &quot;fill&quot;) +
  scale_fill_manual(values = c(&quot;TRUE&quot; = &quot;green&quot;, &quot;FALSE&quot; = &quot;red&quot;)) +
  labs(title = &quot;Judgments by Setting, overall&quot;, x = &quot;Setting&quot;, y = &quot;Proportion&quot;, fill = &quot;Final_Accuracy&quot;) +
  theme_minimal() +
  theme(axis.text.x = element_text())</code></pre>
<p><img src="debate-2309_files/figure-html/quick%20ori%20acc%20stats-1.png" width="100%" /></p>
<p>Sneak peak of accuracy differences between judges, but we won’t get
to that again until models</p>
<pre class="r"><code>ggplot(judgments_online, aes(x = Final_Setting, fill = Final_Accuracy)) +
  geom_bar(position = &quot;fill&quot;) +
  scale_fill_manual(values = c(&quot;TRUE&quot; = &quot;green&quot;, &quot;FALSE&quot; = &quot;red&quot;)) +
  labs(title = &quot;Judgments by Setting, per judge&quot;, x = &quot;Setting&quot;, y = &quot;Proportion&quot;, fill = &quot;Final_Accuracy&quot;) +
  theme_minimal() +
  theme(axis.text.x = element_text(),#angle = 90, hjust = 1),
        axis.text.y = element_blank(),
        strip.text.y.right = element_text(angle = 0)) +
  facet_grid(rows = &quot;Participant&quot;)</code></pre>
<p><img src="debate-2309_files/figure-html/quick%20ori%20stats%20cont-1.png" width="100%" /></p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
